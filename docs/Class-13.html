<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Course home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Course information
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Course home</a>
    </li>
    <li>
      <a href="syllabus.html">Course Syllabus</a>
    </li>
    <li>
      <a href="course-overview.html">Course Overview</a>
    </li>
    <li>
      <a href="final-project.html">About final project</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Classes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Class-01.html">Class 1: Introduction to decision making</a>
    </li>
    <li>
      <a href="Class-02.html">Class 2: The PrOACT Process</a>
    </li>
    <li>
      <a href="Class-03.html">Class 3: Uncertainty and decision making</a>
    </li>
    <li>
      <a href="Class-04.html">Class 4: Decision trees and nets</a>
    </li>
    <li>
      <a href="Class-05.html">Class 5: Intro to SDM and ARM</a>
    </li>
    <li>
      <a href="Class-06.html">Class 6: Structuring and quantifying objectives</a>
    </li>
    <li>
      <a href="Class-07.html">Class 7: Structuring objectives</a>
    </li>
    <li>
      <a href="Class-08.html">Class 8: Intro to R</a>
    </li>
    <li>
      <a href="Class-09.html">Class 9: Linear Models</a>
    </li>
    <li>
      <a href="Class-10.html">Class 10: LMs and GLMs</a>
    </li>
    <li>
      <a href="Class-11.html">Class 11: Prediction and GLMs</a>
    </li>
    <li>
      <a href="Class-12.html">Class 12: GLMs continued</a>
    </li>
    <li>
      <a href="Class-13.html">Class 13: Poissons</a>
    </li>
    <li>
      <a href="Class-14.html">Class 14: HLMs</a>
    </li>
    <li>
      <a href="Class-15.html">Class 15: HLMs and occupancy</a>
    </li>
    <li>
      <a href="Class-16.html">Class 16: Occupancy continued</a>
    </li>
    <li>
      <a href="Class-17.html">Class 17: Influence diagrams, Sensitivity analyses &amp; N-Mixtures</a>
    </li>
    <li>
      <a href="Class-18.html">Class 18: N-Mixtures &amp; Estimating abundance</a>
    </li>
    <li>
      <a href="Class-19.html">Class 19: Population dynamics and decisions</a>
    </li>
    <li>
      <a href="Class-20.html">Class 20</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Assignments
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="hw-01.html">Homework 1</a>
    </li>
    <li>
      <a href="hw-02.html">Homework 2</a>
    </li>
    <li>
      <a href="hw-03.html">Homework 3</a>
    </li>
    <li>
      <a href="hw-04.html">Homework 4</a>
    </li>
    <li>
      <a href="hw-05.html">Homework 5</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Additional Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="R-tutorials.html">R tutorials</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<p><!--

library(knitr)
rmarkdown::render_site("Class-13.Rmd")# build website
# rmarkdown::render_site()# build webpage
# COPY FILES TO DOCS FOR GITHUB.IO
system(paste("xcopy",'"C:/Users/mcolvin/Documents/Teaching/WFA8433-Natural-Resource-Decision-Making/Course-Materials/_site"',     '"C:/Users/mcolvin/Documents/Teaching/WFA8433-Natural-Resource-Decision-Making/Docs"',     "/E /C /H /R /K /O /Y")) 
q(save="no") 

rmarkdown::render_site()# build webpage
## PURL R CODE FROM CLASS NOTES
p<- knitr::purl("Class-13.Rmd")
knitr::read_chunk(p)
chunks <- knitr:::knit_code$get()
chunkss<- lapply(1:length(chunks),function(x){if(!(names(chunks[x]) %in% c("echo=FALSE" ,"eval=FALSE"))){c(paste0("## ----", names(chunks)[x] ,"---- ##"),chunks[[x]]," "," "," ")}})
xxx<- unlist(chunkss)
writeLines(xxx,"./scripts/Class-13.R")
system(paste("xcopy",'"C:/Users/mcolvin/Documents/Teaching/WFA8433-Natural-Resource-Decision-Making/Course-Materials/_site"',     '"C:/Users/mcolvin/Documents/Teaching/WFA8433-Natural-Resource-Decision-Making/Docs"',     "/E /C /H /R /K /O /Y")) 

--></p>
<p><img src="media/banner-05.jpg" width="95%" /> <!--
Homework 1:  Introduction to basic computing- R
List of preliminary problems to instructor for review
--></p>
<div id="class-13.-glms-in-decision-contexts-part-iv" class="section level1">
<h1>Class 13. GLMs in Decision Contexts Part IV</h1>
<ul>
<li>Supplemental background reading(s):
<ul>
<li>Bolker, B. M., M. E. Brooks, C. J. Clark, S. W. Geange, J. R. Poulsen, M. H. H. Stevens, and J.-S. S. White. 2009. Generalized linear mixed models: a practical guide for ecology and evolution. Trends in Ecology &amp; Evolution 24:127-135. <a href="pdfs/B267.pdf">pdf</a></li>
<li>Oâ€™Hara, R. B., and D. J. Kotze. 2010. Do not log-transform count data. Methods in Ecology and Evolution 1:118-122. <a href="pdfs/O44.pdf">pdf</a></li>
</ul></li>
<li>Assignment due: HW2 is due by 5pm!</li>
<li>Link to class recording <a href="">YouTube</a></li>
<li>Today’s R script <a href="scripts/Class-13.R">Class-13.R</a></li>
</ul>
<div id="objectives" class="section level2">
<h2>Objectives</h2>
<p>By the end of this tutorial you should be able to:</p>
<ol style="list-style-type: decimal">
<li>Understand generalized linear models (GLMs)</li>
<li>Understand log link function</li>
<li>Predicting outcomes from a GLM assuming a Poisson distribution</li>
<li>Understand offsets and overdispersion</li>
<li>Using analysis in decision contexts to predict counts</li>
</ol>
</div>
<div id="preliminaries" class="section level2">
<h2>Preliminaries</h2>
<ul>
<li>If you want to play along in class download th
<ul>
<li><a href="fishCounts.csv">fishCounts</a></li>
<li><a href="stemCounts.csv">stemCounts</a></li>
<li><a href="scripts/Class-13.R">R script</a></li>
</ul></li>
<li>Once you have the files where you want them, open the R script and be sure to check the working directory <code>getwd()</code> and make sure it is where your folder is.</li>
<li>If your working directory is not correct, you can set it in Rstudio: “Session –&gt; Set Working Directory –&gt; To source file location”. Or you can use the <code>setwd()</code> in the console.</li>
</ul>
</div>
<div id="where-are-we" class="section level2">
<h2>Where are we?</h2>
<p>By this point you should recognize that the science and subsequent analyses we perform to support our claims of understanding can be used to make support a formal decision making process. Contrast this with an informal decision process where likely outcomes are confined in mental models. Additionally, using models and associated uncertainty to predict outcomes allows us to move beyond vague management recommendations to providing a decision support tool. In the context of a decision model like the Bayesian Decision Networks (BDN) we have been using these predictions provide the means to link parent and child nodes, in other words, our analyses provide the conditional probabilities of the possible outcomes. This class will complete our tour of GLMs with a common distribution for counts in natural resources, the Poisson.</p>
</div>
<div id="background" class="section level2">
<h2>Background</h2>
<p>Count data is common in natural resources. Examples of counts include:</p>
<ul>
<li>Fecundity-capacity to produce offspring</li>
<li>Catch-the number of critters captured</li>
<li>Abundance-number of critters</li>
<li>Counts-Redds, nests, clutches, mortalities</li>
</ul>
<p>In general the Poisson distribution works well for counts because it predicts a discrete outcome, an integer, constrained to values of 0 or greater. This property lends to its common use as a distribution in analysis of natural resource data. Maybe those cool kids from class 10 were cooler than we thought. Historically, the Poisson distribution was developed as a discrete frequency distribution that calculated the probability of a number of independent events occurring in a fixed time. This sort of sounds like the binomial distribution we learned about before but there is no binomial coefficient (i.e., the number of trials). For example, it is common to use the Poisson to calculate the expected outcomes of a survival process where the population abundance is multiplied by the survival rate (i.e., <span class="math inline">\(\text{Survivors}\sim Poisson(\text{Abundance}\cdot Survival\)</span>). This could alternatively be done using a binomial as <span class="math inline">\(\text{Survivors}\sim Binomial(\text{Abundance},Survival\)</span>. As long as <span class="math inline">\(\text{Abundance}\)</span> is high and <span class="math inline">\(Survival\)</span> is low the Poisson and Binomial give similar expectations. Let’s explore this and learn some new and refine our <code>R</code> skills along the way.</p>
</div>
<div id="poisson-versus-binomial" class="section level2">
<h2>Poisson versus Binomial</h2>
<p>We can compare the expected outcomes of the Poisson and the binomial using simulation from the <code>rpois()</code> and <code>rbinom()</code> functions.</p>
<p>Let’s evaluate how the 2 distributions behave for a survival rate <code>S</code> equal to 0.2. We will simulate the expected number of survivors for varying <code>N</code> values, specifically, 10, 50, 100, 1000, and 10000. First let’s make our objects <code>S</code> and <code>N</code>.</p>
<pre class="r"><code>S&lt;-seq(from=0.1,to=1,by=0.05) # SET SURVIVAL
N&lt;- c(10,50,100,500,1000)</code></pre>
<p>Now let’s look at what happens if we generate 50,000 stochastic replicates from a Poisson and a binomial given our <code>S</code> and <code>N</code> equal to 10. Recall that 10 was the first element in our vector of <code>N</code> so we can use the syntax <code>N[1]</code> to get the first value of our vector of abundances. You can allways use <code>?rpois</code> and <code>?rbinom</code> to find out about the functions.</p>
<pre class="r"><code>survivors_pois&lt;-rpois(50000,S*N[1])
survivors_bin&lt;-rbinom(50000,N[1],S)</code></pre>
<p>We can use the <code>hist()</code> function to visualize the expected outcomes.</p>
<pre class="r"><code>hist(survivors_pois)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>hist(survivors_bin)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<p>Hmmm, not super convenient to compare, let’s use the <code>par()</code> function to plot the histograms in a single plot so we can visualize them together. Recall the <code>mfrow</code> input allowed us to change how each plot is added to the main plot area. The default is <code>c(1,1)</code> which plots a single plot. We can change this by <code>mfrow=c(2,1)</code> which plots a 2 rows by 1 column (i.e., 2 plots on top of each other). We will also want to make sure to set the x-axes to the same values to facilitate comparison.</p>
<pre class="r"><code>par(mfrow=c(2,1))
hist(survivors_pois,
    xlim=c(0,10))
hist(survivors_bin,
    xlim=c(0,10))</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Finer point of stochastic simulation</p>
<pre class="r"><code>sims&lt;- expand.grid(N=N,S=S,reps=c(1:500))
sims$surv_pois&lt;-rpois(n=nrow(sims),lambda=sims$S*sims$N)
sims$surv_bin&lt;- rbinom(n=nrow(sims),size=sims$N,prob=sims$S)</code></pre>
<pre class="r"><code>boxplot(surv_pois~N,data=sims)
boxplot(surv_bin~N,data=sims,add=TRUE,col=&#39;grey&#39;)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Ok that is not very useful, the boxplots cover each other up. We need to move them over a bit. The <code>at</code> argument allows us to shift the boxplots.</p>
<pre class="r"><code>boxplot(surv_pois~S,data=sims,
    at=1:length(S)-0.25)
boxplot(surv_bin~S,data=sims,add=TRUE,col=&#39;grey&#39;,
    at=1:length(S)+0.25)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Now we need to tackle a couple more issues, first we need to make the boxplots narrower and then clean up the axes. The arguments <code>boxwex</code> and <code>xaxt</code> will help.</p>
<pre class="r"><code>boxplot(surv_pois~S,data=sims,
    at=1:1:length(S)-0.25,
    subset=N==10,
    boxwex=0.25, # make boxplot narrower
    xaxt=&#39;n&#39;) # suppress x-axis label plotting
boxplot(surv_bin~S,data=sims,add=TRUE,col=&#39;grey&#39;,
    at=1:1:length(S)+0.25,
    subset=N==10,
    boxwex=0.25,
    xaxt=&#39;n&#39;)
axis(side=1,at=1:length(S),labels=S)
legend(&quot;topleft&quot;,legend=c(&quot;Poisson&quot;,&quot;Binomial&quot;),
    fill=c(&quot;white&quot;,&quot;grey&quot;))</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>The plot of above shows that values are similar to at low <code>S</code> values, but as it increases, survivors exceeds abundance. This is spontaneous generation!</p>
<p>Lets look at the other extreme where abundance was 1000. The values at lower <code>S</code> values are similar between the binomial and the Poisson and similarity decreases as <code>S</code> increases.</p>
<pre class="r"><code>boxplot(surv_pois~S,data=sims,
    at=1:length(S)-0.25,
    subset=N==1000,
    boxwex=0.25, # make boxplot narrower
    xaxt=&#39;n&#39;) # suppress x-axis label plotting
boxplot(surv_bin~S,data=sims,add=TRUE,col=&#39;grey&#39;,
    at=1:length(S)+0.25,
    subset=N==1000,
    boxwex=0.25,
    xaxt=&#39;n&#39;)
axis(side=1,at=1:length(S),labels=S)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>One thing you will notice is that the range for the Poisson increases with survival. Recall that <code>lambda</code> was <code>S*N</code> so as <code>S</code> increases so does lambda. In this case <code>lambda</code> is the mean.</p>
<p>One of the properties of the Poisson distributional is that the mean and the variance are the same! Let’s confirm. First we need to create lambda as <code>N*S</code></p>
<pre class="r"><code>sims$lambda&lt;- sims$N*sims$S
vars&lt;- aggregate(surv_pois~lambda,sims,var)
plot(surv_pois~lambda,data=vars,   
    xlab=&quot;Lambda&quot;,
    ylab=&quot;Variance&quot;)
abline(0,1)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>There is a bit of noise around the 1:1 line, but that is to be expected because we only did 500 stochastic replicates. If many more were done they would fall exactly on the 1:1 line. Don’t believe me? Try it yourself. Challenge accepted?</p>
<p>So one of the major differences between the binomial and the Poisson is that the Poisson can exceed the population abundance if survival is high. This is because the Poisson calculates the number of outcomes without constraining by the number of trials. The binomial constrains outcomes such that the successes cannot exceed the number of trials. Regardless the Poisson is very useful.</p>
</div>
<div id="the-models" class="section level2">
<h2>The models</h2>
<p>For a generalized linear model we can use the same linear model as we have before but we use the log function to link predictions of the linear model to the statistical model.</p>
<p><span class="math display">\[\log(\lambda_{i}) = \beta_{0}+\beta_{j}\cdot X_{i,j}\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\beta_{0}\)</span> is the intercept of the linear model,<br />
</li>
<li><span class="math inline">\(\beta_{1}\)</span> is the effect of covariate X,</li>
<li><span class="math inline">\(j\)</span> indexes each covariate,</li>
<li><span class="math inline">\(i\)</span> indexes each observation, and</li>
<li><span class="math inline">\(\mu_{i}\)</span> is the predicted count for the ith observation.</li>
</ul>
<p>And the statistical model linking the observed data to the linear model predictions is:</p>
<p><span class="math display">\[ Y_{i} \sim Poisson(\lambda_{i})\]</span></p>
<p>where,</p>
<ul>
<li><span class="math inline">\(Y_{i}\)</span> is the ith observation,</li>
<li><span class="math inline">\(i\)</span> indexes each observation, and</li>
<li><span class="math inline">\(\mu_{i}\)</span> is the predicted count for the ith observation.</li>
</ul>
<p>Let’s look at some common natural resource data where the expected outcomes are Poisson distributed, fit a model to the data, and generate expected outcomes.</p>
</div>
<div id="example-fish-counts" class="section level2">
<h2>Example-Fish counts</h2>
<div id="the-data" class="section level3">
<h3>The data</h3>
<p>In fisheries and wildlife we commonly calculate catch per unit effort by dividing counts by the effort. For example, in backpack electrofishing, the number of a fish species captured and the number of seconds of shocking is used to calculate catch per unit effort as <span class="math inline">\(\frac{\text{Catch}}{\text{Effort}}\)</span>. This value can be related to covariates as</p>
<p><span class="math display">\[\frac{\text{Catch}_i}{\text{Effort}_i} = beta_{0}+\beta_{j}\cdot X_{i,j}\]</span></p>
<p>where the parameters are as defined above. With some fun with logarithms we can actually model counts using a Poisson distribution.</p>
<p>Why would we want to do this? Well, glad you asked, catch per unit effort is not normally distributed, it is constrained to be greater than or equal to 0. The other issue is that there are commonly catch per unit efforts of 0 which can wreak havoc with log transformations commonly used to meet assumptions. But check this out, if we take the log of the left hand side we can do some nifty things.</p>
<p><span class="math display">\[log(\frac{\text{Catch}_i}{\text{Effort}_i})= beta_{0}+\beta_{j}\cdot X_{i,j}\]</span></p>
<p>Which with some law of logarithms we get (i.e., <span class="math inline">\(log\frac{a}{b} = log(a)-log(b)\)</span>:</p>
<p><span class="math display">\[log(\text{Catch}_i) = beta_{0}+\beta_{j}\cdot X_{i,j}+log({\text{Effort}_i})\]</span></p>
<p>and with converting this model to a linear predictor and linking that prediction to a statistical model as:</p>
<p><span class="math display">\[log(\lambda_i) = beta_{0}+\beta_{j}\cdot X_{i,j}+log({\text{Effort}_i})\]</span></p>
<p>and</p>
<p><span class="math display">\[\text{Catch}_i \sim  Poisson(\lambda_i)\]</span>.</p>
<p>Now we are predicting the number of critters captured but accounting for the known effect of effort (i.e., more effort, more critters captured). Notice there is no <span class="math inline">\(\beta\)</span> associated with <code>Effort</code>, this is what is known as an offset. An offset is when there is a known relation with the response variable, effort in this case. Other examples might be area or some other measurement of size. Think about this aspect the next time you divide a count to normalize. Let’s see how to use this in R.</p>
<p>Let’s read in some data to get a better feel for what I am talking about.</p>
<pre class="r"><code>fishCounts&lt;- read.csv(&quot;fishCounts.csv&quot;)
fishCounts</code></pre>
<pre><code>##    width habitat streamLength counts
## 1    0.8      ag           40      2
## 2    1.0      ag           50      3
## 3    1.0  forest           50     74
## 4    0.5      ag           25      0
## 5    0.6  forest           30     16
## 6    0.7   urban           35     11
## 7    0.5      ag           25      1
## 8    0.7   urban           35     14
## 9    0.6  forest           30     21
## 10   0.6   urban           30      9
## 11   0.6  forest           30     17
## 12   0.7  forest           35     27
## 13   0.9   urban           45     20
## 14   0.8   urban           40     16
## 15   1.0   urban           50     34
## 16   1.1  forest           55    110
## 17   0.8   urban           40     23
## 18   0.7  forest           35     22
## 19   0.6      ag           30      0
## 20   1.0      ag           50      4
## 21   1.0   urban           50     33
## 22   1.0      ag           50      3
## 23   0.7      ag           35      2
## 24   0.8      ag           40      3
## 25   0.8  forest           40     45
## 26   1.2   urban           60     53
## 27   0.6      ag           30      0
## 28   0.7      ag           35      2
## 29   0.5   urban           25      4
## 30   0.9      ag           45      2
## 31   1.3  forest           65    191
## 32   1.2      ag           60     10
## 33   0.8   urban           40     12
## 34   1.0  forest           50     78
## 35   0.5  forest           25     20
## 36   0.9  forest           45     49
## 37   1.2   urban           60     68
## 38   0.6  forest           30     14
## 39   1.1  forest           55     98
## 40   0.5  forest           25     16
## 41   0.9  forest           45     55
## 42   0.9  forest           45     52
## 43   0.8  forest           40     31
## 44   0.7  forest           35     21
## 45   1.2      ag           60     12
## 46   0.8   urban           40     12
## 47   0.7   urban           35     10
## 48   0.6  forest           30     12
## 49   0.7      ag           35      0
## 50   0.9   urban           45     23
## 51   0.6      ag           30      2
## 52   0.5      ag           25      1
## 53   0.9  forest           45     46
## 54   0.9   urban           45     21
## 55   0.6  forest           30     20
## 56   0.9  forest           45     54
## 57   0.7  forest           35     27
## 58   1.0      ag           50      2
## 59   1.0   urban           50     31
## 60   1.3  forest           65    201
## 61   1.2      ag           60     17
## 62   1.0  forest           50     94
## 63   0.6      ag           30      0
## 64   1.2  forest           60    143
## 65   0.7      ag           35      3
## 66   1.0   urban           50     31
## 67   1.2  forest           60    135
## 68   0.5   urban           25      5
## 69   0.9  forest           45     36
## 70   0.6      ag           30      2
## 71   0.8  forest           40     32
## 72   0.8      ag           40      3
## 73   0.8      ag           40      3
## 74   0.5  forest           25      7
## 75   1.3   urban           65     80
## 76   0.9  forest           45     64
## 77   0.8  forest           40     41
## 78   1.0  forest           50     72
## 79   0.6  forest           30     19
## 80   0.7  forest           35     23
## 81   1.0   urban           50     32
## 82   0.5  forest           25     13
## 83   1.0   urban           50     25
## 84   0.9      ag           45      3
## 85   1.2      ag           60      7
## 86   0.5   urban           25      5
## 87   1.2      ag           60     17</code></pre>
<p>The dataset has 4 columns and 87 observations. Typically in stream surveys we allocate effort proportional to the width of the stream, in this case the stream length surveyed was 50 times the stream width. Now the stream lengths won’t exactly be 50 times the width there is some rounding involved so you don’t stop in the middle of a habitat unit. The expectation is that if you should get more fish if you sample 100 relative to 10 meters of stream. This is a known relationship, hence we commonly convert counts to densities by dividing the count by the length of stream sampled. We will fit a glm model to the data assuming the data are Poisson distributed and with an offset.</p>
<p>As we should, we plot the data to get a feel for what is going on. Recall we can think about <code>R</code> plots like a canvas where we can layer information on top of the plot. We have seen this before but the code below uses the tools we have learned to plot counts versus width by habitat type.</p>
<pre class="r"><code>plot(counts~width,
    data=fishCounts,
    xlab=&quot;Width (m)&quot;,
    ylab=&quot;Catch&quot;,
    type=&#39;n&#39;,
    las=1)
points(counts~width, data=fishCounts,
    subset=habitat==&quot;ag&quot;,col=&quot;red&quot;,pch=1)
points(counts~width, data=fishCounts,
    subset=habitat==&quot;forest&quot;,col=&quot;blue&quot;,pch=2)
points(counts~width, data=fishCounts,
    subset=habitat==&quot;urban&quot;,col=&quot;black&quot;,pch=3)
legend(&quot;topleft&quot;,legend=c(&quot;Agriculture&quot;,&quot;Forested&quot;,&quot;Urban&quot;),
    col=c(&quot;red&quot;,&quot;blue&quot;,&quot;black&quot;),pch=c(1,2,3))</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Looks pretty clear that forested streams have higher fish counts.</p>
<p>Now we can fit the the model using the <code>glm()</code> function using a Poisson family and we are going to… wait for it… add an offset.</p>
</div>
<div id="fitting-the-model-to-the-data" class="section level3">
<h3>Fitting the model to the data</h3>
<p>Now that we have looked over the data we can fit a model to the data. We will use the <code>glm()</code> function as we have before, but this time we will use the poisson family by including the argument <code>family=&quot;poisson&quot;</code>. The model below predicts counts from steam width and depth and includes an offset of stream length to account for more critters being captured because more stream was sampled. One thing to know is that including stream length as an offset required a log transformation. Recall the law of logs demonstrated above?</p>
<pre class="r"><code>fit&lt;- glm(counts~width+habitat,
    data=fishCounts,
    offset=log(fishCounts$streamLength),# recall it is log 
    family=&quot;poisson&quot;)</code></pre>
<p>Now that the model is fit we can do all the goodies we usually do. First let’s look at the summary of the model.</p>
<pre class="r"><code>summary(fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = counts ~ width + habitat, family = &quot;poisson&quot;, data = fishCounts, 
##     offset = log(fishCounts$streamLength))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.45819  -0.78351   0.00079   0.40666   2.29291  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   -4.62573    0.13278  -34.84   &lt;2e-16 ***
## width          2.36015    0.08833   26.72   &lt;2e-16 ***
## habitatforest  2.66198    0.10058   26.47   &lt;2e-16 ***
## habitaturban   1.79340    0.10660   16.82   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 2419.170  on 86  degrees of freedom
## Residual deviance:   75.053  on 83  degrees of freedom
## AIC: 464.21
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>We can extract the model coefficients and profile the 95% confidence intervals.</p>
<pre class="r"><code>betas&lt;- coef(fit)
confint(fit)</code></pre>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                   2.5 %    97.5 %
## (Intercept)   -4.889968 -4.369226
## width          2.187440  2.533701
## habitatforest  2.470491  2.865167
## habitaturban   1.589290  2.007599</code></pre>
</div>
<div id="evaluating-the-model" class="section level3">
<h3>Evaluating the model</h3>
<p>Couple of things we will want to check out.</p>
<ol style="list-style-type: decimal">
<li>The model structure was correctly specified with a plot of observed versus predicted</li>
<li>The variance is the same as the mean</li>
</ol>
<pre class="r"><code>fishCounts$pred&lt;- fitted(fit) 
fishCounts$res&lt;- resid(fit) 
plot(counts~pred,data=fishCounts)
abline(0,1) </code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-18-1.png" width="672" /> Now we can look at the residuals versus the fitted values.</p>
<pre class="r"><code>plot(res~pred,data=fishCounts)
abline(h=0) </code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-19-1.png" width="672" /> They look ok but since the variance increases with the mean we would expect fanning, we just happen to have few values that exceed 100 so it is difficult to diagnose.</p>
</div>
<div id="getting-predictions-and-outcomes-from-the-model" class="section level3">
<h3>Getting predictions and outcomes from the model</h3>
<p>For management purposes we are most interested in getting predictions of the expected outcomes.</p>
<pre class="r"><code># do 4 streams with varying depths and land cover

preddat&lt;-data.frame(
    width=c(1.3,1.05,0.65,0.7,0.65,0.95),
    habitat=c(&quot;forest&quot;,&quot;forest&quot;,&quot;urban&quot;,&quot;urban&quot;,&quot;ag&quot;,&quot;ag&quot;),
    streamLength=c(123,324,75,84,68,98))

# preddat$lambda&lt;- predict(fit,newdata=preddat,
  #   type=&quot;response&quot;)  # does not work </code></pre>
<p>Well that did not work. Unfortunately the <code>predict()</code> function does not use the offset. Lemons to lemonade. We have all the skills to make predictions on our own, all we need to do is extract the betas which we have already done and then multiply them and add them up.</p>
<pre class="r"><code>preddat$lambda&lt;- NA # prep vector to fill

preddat[preddat$habitat==&quot;ag&quot;,]$lambda&lt;- exp(betas[1]+
    preddat[preddat$habitat==&quot;ag&quot;,]$width*betas[2]+
    log(preddat[preddat$habitat==&quot;ag&quot;,]$streamLength))
preddat[preddat$habitat==&quot;forest&quot;,]$lambda&lt;- exp(betas[1]+
    preddat[preddat$habitat==&quot;forest&quot;,]$width*betas[2]+
    betas[3]+
    log(preddat[preddat$habitat==&quot;forest&quot;,]$streamLength))   
preddat[preddat$habitat==&quot;urban&quot;,]$lambda&lt;- exp(betas[1]+
    preddat[preddat$habitat==&quot;urban&quot;,]$width*betas[2]+
    betas[4]+
    log(preddat[preddat$habitat==&quot;urban&quot;,]$streamLength))   
preddat   </code></pre>
<pre><code>##   width habitat streamLength     lambda
## 1  1.30  forest          123 371.160048
## 2  1.05  forest          324 541.939756
## 3  0.65   urban           75  20.475988
## 4  0.70   urban           84  25.805538
## 5  0.65      ag           68   3.089091
## 6  0.95      ag           98   9.037493</code></pre>
</div>
<div id="accounting-for-uncertainty" class="section level3">
<h3>Accounting for uncertainty</h3>
<p>It is always good to account for uncertainty and generate expected outcomes. We have gone over simulation as a way to figure out those outcomes. Suppose I want to get the 95% prediction interval for a <code>lamba</code> of 10. We can generation many stochastic replicates and either sort and figure out the what values falls is the 250th and which one is 9750th if you simulated 10,000 replicates.</p>
<pre class="r"><code>xx&lt;-rpois(10000,10)
xx&lt;- sort(xx)
xx[250]</code></pre>
<pre><code>## [1] 4</code></pre>
<pre class="r"><code>xx[9750]</code></pre>
<pre><code>## [1] 17</code></pre>
<p>Or we can use the <code>quantile()</code> function. This function returns user specifed values.</p>
<pre class="r"><code>vals&lt;-quantile(x=xx,probs=c(0.025,0.975))
vals</code></pre>
<pre><code>##  2.5% 97.5% 
##     4    17</code></pre>
<p>Neat they are the same as above.</p>
<p>We can also ue some more flexibility and use the <code>qpois()</code> function. This function returns the value for quantile you specify given the required distribuation inputs, <code>lamba</code> in the case of the Poisson.</p>
<pre class="r"><code>vals2&lt;- qpois(c(0.025,0.975),lambda=10)
vals2</code></pre>
<pre><code>## [1]  4 17</code></pre>
<p>Cool beans <a href="https://youtu.be/vc7VBVpl1SY">1</a>, same as the other 2 methods. Usind the <code>qpois()</code> we can generate the 95% prediction intervals pretty easily for our predicted values in <code>preddat</code>.</p>
<pre class="r"><code>preddat$uci&lt;-qpois(0.975, preddat$lambda)
preddat$lci&lt;-qpois(0.025, preddat$lambda)</code></pre>
<p>Boomtown, now things are working.</p>
</div>
<div id="calculating-the-probability-of-an-outcome" class="section level3">
<h3>Calculating the probability of an outcome</h3>
<p>In management decisions we need to calculate the probability of all the possible outcomes. We have found that this can be a real challenge to do when working with continuous outcomes that require discretization. However for discrete outcomes like the poisson things get a bit easier and we can predict the probability of a range of outcomes.</p>
<p>Using <code>preddat</code> we can calculate the probability of 0 to 1000 fish. I chose those numbers to sufficiently cover all possible outcomes. The larges 95% prediction interval was 497, so maxxing out at 1000 should cover it.</p>
<pre class="r"><code># MAKE A MATRIX TO STORE OUR PRECIOUS PROBABILITIES
outcomes&lt;- matrix(0,nrow=1001,ncol=nrow(preddat))</code></pre>
<p>Now instead of using the <code>qpois()</code> function that returns a value, I am going to use the <code>cpois()</code> function that returns the probability of an outcome. For example the code belows returns the probability of a 3, 10 or 17 given a <code>lambda</code> equal to 10.</p>
<pre class="r"><code>dpois(x=3,lambda=10) # should be pretty low</code></pre>
<pre><code>## [1] 0.007566655</code></pre>
<pre class="r"><code>dpois(x=10,lambda=10) # about mid of the road</code></pre>
<pre><code>## [1] 0.12511</code></pre>
<pre class="r"><code>dpois(x=17,lambda=10) # close to 1</code></pre>
<pre><code>## [1] 0.012764</code></pre>
<p>We can use a <code>for()</code> loop to get the cumlative probabilities for the predicted values.</p>
<pre class="r"><code>for(i in 1:nrow(preddat))# loop over each row of predat
    {
    outcomes[,i]&lt;-dpois(c(0:1000),lambda=preddat$lambda[i])
    }</code></pre>
<p>Now if we did this right the columns should sum to 1. Let’s check.</p>
<pre class="r"><code>colSums(outcomes)</code></pre>
<pre><code>## [1] 1 1 1 1 1 1</code></pre>
<p>Yep they do. That is a nice property of a discrete outcome that results from a poisson.</p>
<p>We can take a look at the expected outcomes. We are more curious here so let’s not get too fancy an simply use the <code>matlines()</code> function.</p>
<pre class="r"><code>matplot(y=outcomes,type=&#39;l&#39;,lwd=3)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>Couple of things to notice, as <code>lamba</code> increases the spread of outcomes increases.</p>
<p>With our new found skills let’s circle back and add prediction intervals to our model of fish counts. First we need to make an other dataset to predict from.</p>
<pre class="r"><code>preddat&lt;-expand.grid( # MAKE DATASET
    width=c(1.3,1.05,0.65,0.7,0.65,0.95),
    habitat=c(&quot;forest&quot;,&quot;urban&quot;,&quot;ag&quot;),
    streamLength=c(25:65))

preddat$lambda&lt;- NA # prep vector to fill

# PREDICT LAMBDA
preddat[preddat$habitat==&quot;ag&quot;,]$lambda&lt;- exp(betas[1]+
    preddat[preddat$habitat==&quot;ag&quot;,]$width*betas[2]+
    log(preddat[preddat$habitat==&quot;ag&quot;,]$streamLength))
preddat[preddat$habitat==&quot;forest&quot;,]$lambda&lt;- exp(betas[1]+
    preddat[preddat$habitat==&quot;forest&quot;,]$width*betas[2]+
    betas[3]+
    log(preddat[preddat$habitat==&quot;forest&quot;,]$streamLength))   
preddat[preddat$habitat==&quot;urban&quot;,]$lambda&lt;- exp(betas[1]+
    preddat[preddat$habitat==&quot;urban&quot;,]$width*betas[2]+
    betas[4]+
    log(preddat[preddat$habitat==&quot;urban&quot;,]$streamLength))   </code></pre>
<p>Now we can use the <code>qpois()</code> function to get our 95% prediction intervals.</p>
<pre class="r"><code>preddat$uci&lt;-qpois(0.975, preddat$lambda)
preddat$lci&lt;-qpois(0.025, preddat$lambda)</code></pre>
<p>And we can make a pretty plot to go with it. But recall we need to account for stream length.</p>
<pre class="r"><code>plot(uci~width,data=preddat,
    xlab=&quot;Stream width&quot;,
    ylab=&quot;Fish count&quot;,
    subset=streamLength==25,
    type=&#39;n&#39;)
points(lambda~width,data=preddat,
    subset=streamLength==25 &amp; habitat==&quot;forest&quot;, 
    lty=1,type=&#39;l&#39;)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-33-1.png" width="672" /> Boo, that looks terrible. Ok what is going on here is that R plots things sequentially so when we subset the order was not quite right. We can fix it by sorting our dataset by multiple variables using the <code>order()</code> function.</p>
<pre class="r"><code>preddat&lt;- preddat[order(preddat$streamLength,preddat$width),]</code></pre>
<p>Now let’s try that plot again.</p>
<pre class="r"><code>plot(uci~width,data=preddat,
    xlab=&quot;Stream width&quot;,
    ylab=&quot;Fish count&quot;,
    subset=streamLength==25,
    type=&#39;n&#39;,
    las=1)
points(lambda~width,data=preddat,
    subset=streamLength==25 &amp; habitat==&quot;forest&quot;, 
    lty=1,type=&#39;l&#39;)
points(lci~width,data=preddat,
    subset=streamLength==25 &amp; habitat==&quot;forest&quot;, 
    lty=2,type=&#39;l&#39;)
points(uci~width,data=preddat,
    subset=streamLength==25 &amp; habitat==&quot;forest&quot;, 
    lty=2,type=&#39;l&#39;)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
</div>
</div>
<div id="example-stem-counts" class="section level2">
<h2>Example-stem counts</h2>
<div id="the-data-1" class="section level3">
<h3>The data</h3>
<p>Here is an example of stem counts following a treatment of no, partial, or full burns in varying habitats. Additionally, there was an effect of elevation.</p>
<pre class="r"><code>stemCounts&lt;- read.csv(&quot;stemCounts.csv&quot;)
head(stemCounts)</code></pre>
<pre><code>##      treatment        habitat elevation counts
## 1 partial burn mixed hardwood        52    387
## 2    full burn       riparian         9    135
## 3 partial burn          field        66     36
## 4    full burn           pine       110    306
## 5      no burn           pine        31    107
## 6 partial burn           pine       128    151</code></pre>
<pre class="r"><code>plot(counts~elevation,data=stemCounts,
    xlab=&quot;Elevation&quot;,
    ylab=&quot;Stem counts&quot;,
    las=1,
    type=&#39;n&#39;)
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;field&quot;,
    pch=1,col=&quot;red&quot;)
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;riparian&quot;,
    pch=2,col=&quot;red&quot;)   
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    pch=3,col=&quot;red&quot;)     
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;pine&quot;,
    pch=4,col=&quot;red&quot;)   
    
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;partial burn&quot; &amp; habitat==&quot;field&quot;,
    pch=1,col=&quot;blue&quot;)
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;partial burn&quot; &amp; habitat==&quot;riparian&quot;,
    pch=2,col=&quot;blue&quot;)   
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;partial burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    pch=3,col=&quot;blue&quot;)     
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;partial burn&quot; &amp; habitat==&quot;pine&quot;,
    pch=4,col=&quot;blue&quot;) 

points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;full burn&quot; &amp; habitat==&quot;field&quot;,
    pch=1,col=&quot;green&quot;)
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;full burn&quot; &amp; habitat==&quot;riparian&quot;,
    pch=2,col=&quot;green&quot;)   
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;full burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    pch=3,col=&quot;green&quot;)     
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;full burn&quot; &amp; habitat==&quot;pine&quot;,
    pch=4,col=&quot;green&quot;)  
legend(&quot;topleft&quot;,legend=c(&quot;No burn&quot;, &quot;Partial burn&quot;, &quot;Full burn&quot;,
    &quot;Field&quot;,&quot;Riparian&quot;,&quot;Mixed hardwood&quot;, &quot;Pines&quot;),
    pch=c(1,1,1,1,1,2,3,4),col=c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;,&quot;black&quot;,&quot;black&quot;,
        &quot;black&quot;,&quot;black&quot;),ncol=2)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>Thinks look like fun. Let’s fit our model!</p>
<pre class="r"><code>fit&lt;- glm(counts~treatment+habitat+elevation,
    data=stemCounts,
    family=&quot;poisson&quot;)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = counts ~ treatment + habitat + elevation, family = &quot;poisson&quot;, 
##     data = stemCounts)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.0996  -1.4645  -0.0701   1.3419   5.3218  
## 
## Coefficients:
##                         Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)            4.483e+00  1.657e-02  270.62   &lt;2e-16 ***
## treatmentno burn      -1.013e+00  1.109e-02  -91.34   &lt;2e-16 ***
## treatmentpartial burn -4.964e-01  8.929e-03  -55.59   &lt;2e-16 ***
## habitatmixed hardwood  2.002e+00  1.532e-02  130.70   &lt;2e-16 ***
## habitatpine            1.016e+00  1.673e-02   60.72   &lt;2e-16 ***
## habitatriparian        5.532e-01  1.829e-02   30.25   &lt;2e-16 ***
## elevation              1.490e-03  4.394e-05   33.91   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 48221.1  on 266  degrees of freedom
## Residual deviance:  1090.1  on 260  degrees of freedom
## AIC: 2952
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>We can do all the things we did before.</p>
<pre class="r"><code>betas&lt;- coef(fit)
confint(fit)</code></pre>
<pre><code>## Waiting for profiling to be done...</code></pre>
<pre><code>##                             2.5 %       97.5 %
## (Intercept)            4.45071774  4.515659291
## treatmentno burn      -1.03500035 -0.991518902
## treatmentpartial burn -0.51389142 -0.478891142
## habitatmixed hardwood  1.97228881  2.032341043
## habitatpine            0.98321718  1.048804941
## habitatriparian        0.51737743  0.589065891
## elevation              0.00140401  0.001576263</code></pre>
<p>We can extract the fitted to look at model specification.</p>
<pre class="r"><code>stemCounts$fitted&lt;-fitted(fit)
plot(counts~fitted, data= stemCounts,
    xlab=&quot;Predicted values&quot;,
    ylab=&quot;Counts&quot;,
    las=1)
abline(0,1)</code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>That seems ok, although it looks a bit funny near 1000, it fans a bit, which is something we have not seen. Lets carry on and get some predictions out of this beasts. First we need to make a new <code>data.frame()</code> that contains the possible combinations of elevation, habitat, and treatment we want to evaluate.</p>
<pre class="r"><code>preddat&lt;- expand.grid(
    treatment=levels(stemCounts$treatment),
    habitat=levels(stemCounts$habitat),
    elevation=c(min(stemCounts$elevation):max(stemCounts$elevation)))</code></pre>
<p>Fortunately we do not have an offset so it is easy peasy to predict the counts for our new <code>data.frame()</code>.</p>
<pre class="r"><code>preddat$lambda&lt;- predict(fit, newdata=preddat,
    type=&#39;response&#39;)</code></pre>
<p>And we can get the 95% prediction interval.</p>
<pre class="r"><code>preddat$lci&lt;-qpois(0.025,preddat$lambda)
preddat$uci&lt;-qpois(0.975,preddat$lambda)</code></pre>
<p>And now the fun begins. Because we do not have an offset we can simply plot the data and the prediction intervals. Let’s look at the no burn treatment.</p>
<pre class="r"><code>plot(counts~elevation,data=stemCounts,
    xlab=&quot;Elevation&quot;,
    ylab=&quot;Stem counts&quot;,
    las=1,
    type=&#39;n&#39;,subset=treatment==&quot;no burn&quot;)
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;field&quot;,
    pch=1,col=&quot;black&quot;)
## PLOT 95% PREDICTION INTERVALS    
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;field&quot;,
    type=&#39;l&#39;,col=&quot;black&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;field&quot;,
    type=&#39;l&#39;,col=&quot;black&quot;,lty=2)     
 
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;riparian&quot;,
    pch=2,col=&quot;green&quot;)  
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;riparian&quot;,
    type=&#39;l&#39;,col=&quot;green&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;riparian&quot;,
    type=&#39;l&#39;,col=&quot;green&quot;,lty=2) 
    
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    pch=3,col=&quot;red&quot;)    
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    type=&#39;l&#39;,col=&quot;red&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    type=&#39;l&#39;,col=&quot;red&quot;,lty=2) 
   
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;pine&quot;,
    pch=4,col=&quot;blue&quot;) 
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;pine&quot;,
    type=&#39;l&#39;,col=&quot;blue&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;pine&quot;,
    type=&#39;l&#39;,col=&quot;blue&quot;,lty=2) </code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p>Ok, it might just be me but I was not expecting there to be a bunch of points outside of the the 95% prediction intervals. What is going on here, not that epic 90s song <a href="https://youtu.be/6NXnxTNIWkc">2</a>.</p>
</div>
<div id="accounting-for-overdispersion" class="section level3">
<h3>Accounting for overdispersion</h3>
<p>What we have going on here is what is called over dispersion. Recall that for the Poisson the variance is equal to the mean? Well, if there is extra variation, as there must be in this case because the observed data exceeds the 95% prediction intervals, there is over dispersion. Fortunately it is easy to remedy. There is another family that can be used with <code>glm()</code> the <code>quasipoisson</code> family. The quasipoisson estimates a dispersion parameter, values greater than 1 indicate over dispersion and values less than 1 indicate under dispersion. The <code>poisson</code> family used in <code>glm()</code> assumes the dispersion parameter is 1.</p>
<p>Let’s fit the same data but this time assuming a <code>quasipoisson</code> distribution.</p>
<pre class="r"><code>fit&lt;- glm(counts~treatment+habitat+elevation,
    data=stemCounts,
    family=&quot;quasipoisson&quot;)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = counts ~ treatment + habitat + elevation, family = &quot;quasipoisson&quot;, 
##     data = stemCounts)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.0996  -1.4645  -0.0701   1.3419   5.3218  
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            4.483e+00  3.382e-02  132.55   &lt;2e-16 ***
## treatmentno burn      -1.013e+00  2.265e-02  -44.74   &lt;2e-16 ***
## treatmentpartial burn -4.964e-01  1.823e-02  -27.23   &lt;2e-16 ***
## habitatmixed hardwood  2.002e+00  3.128e-02   64.02   &lt;2e-16 ***
## habitatpine            1.016e+00  3.416e-02   29.74   &lt;2e-16 ***
## habitatriparian        5.532e-01  3.734e-02   14.81   &lt;2e-16 ***
## elevation              1.490e-03  8.972e-05   16.61   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 4.168425)
## 
##     Null deviance: 48221.1  on 266  degrees of freedom
## Residual deviance:  1090.1  on 260  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Ohh a dispersion parameter of 7.5 that is pretty high and supports our inclination that there was some overdispersion. Now let’s calculate the 95% prediction intervals. This is done using the negative binomial distribution where the size is $/(dispersion-1) and <span class="math inline">\(\mu = \lambda\)</span>.</p>
<pre class="r"><code>preddat&lt;- expand.grid(
    treatment=levels(stemCounts$treatment),
    habitat=levels(stemCounts$habitat),
    elevation=c(min(stemCounts$elevation):max(stemCounts$elevation)))
preddat$lambda&lt;- predict(fit, newdata=preddat,
    type=&#39;response&#39;)</code></pre>
<p>And we can get the 95% prediction interval.</p>
<pre class="r"><code>dispersion&lt;- summary(fit)$dispersion # GET DISPERSION

preddat$lci&lt;-qnbinom(0.025, size=(preddat$lambda/(dispersion-1)),    
    mu=preddat$lambda)
preddat$uci&lt;-qnbinom(0.975, size=(preddat$lambda/(dispersion-1)),    
    mu=preddat$lambda)</code></pre>
<p>Let’s plot the prediction intervals again and see if they make more sense.</p>
<pre class="r"><code>plot(counts~elevation,data=stemCounts,
    xlab=&quot;Elevation&quot;,
    ylab=&quot;Stem counts&quot;,
    las=1,
    type=&#39;n&#39;,subset=treatment==&quot;no burn&quot;)
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;field&quot;,
    pch=1,col=&quot;black&quot;)
## PLOT 95% PREDICTION INTERVALS    
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;field&quot;,
    type=&#39;l&#39;,col=&quot;black&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;field&quot;,
    type=&#39;l&#39;,col=&quot;black&quot;,lty=2)     
 
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;riparian&quot;,
    pch=2,col=&quot;green&quot;)  
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;riparian&quot;,
    type=&#39;l&#39;,col=&quot;green&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;riparian&quot;,
    type=&#39;l&#39;,col=&quot;green&quot;,lty=2) 
    
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    pch=3,col=&quot;red&quot;)    
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    type=&#39;l&#39;,col=&quot;red&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;mixed hardwood&quot;,
    type=&#39;l&#39;,col=&quot;red&quot;,lty=2) 
   
points(counts~elevation,data=stemCounts,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;pine&quot;,
    pch=4,col=&quot;blue&quot;) 
points(lci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;pine&quot;,
    type=&#39;l&#39;,col=&quot;blue&quot;,lty=2)
points(uci~elevation,data=preddat,
    subset=treatment==&quot;no burn&quot; &amp; habitat==&quot;pine&quot;,
    type=&#39;l&#39;,col=&quot;blue&quot;,lty=2) </code></pre>
<p><img src="Class-13_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>Ok, those look a ton better!</p>
<p>Now if you really wanted you could plot the rest of the prediction intervals for the remaining treatments.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
