<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
  padding-left: 10px;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Course home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Course information
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Course home</a>
    </li>
    <li>
      <a href="syllabus.html">Course Syllabus</a>
    </li>
    <li>
      <a href="course-overview.html">Course Overview</a>
    </li>
    <li>
      <a href="final-project.html">About final project</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Classes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Class-01.html">Class 1: Introduction to decision making</a>
    </li>
    <li>
      <a href="Class-02.html">Class 2: The PrOACT Process</a>
    </li>
    <li>
      <a href="Class-03.html">Class 3: Uncertainty and decision making</a>
    </li>
    <li>
      <a href="Class-04.html">Class 4: Decision trees and nets</a>
    </li>
    <li>
      <a href="Class-05.html">Class 5: Intro to SDM and ARM</a>
    </li>
    <li>
      <a href="Class-06.html">Class 6: Structuring and quantifying objectives</a>
    </li>
    <li>
      <a href="Class-07.html">Class 7: Structuring objectives</a>
    </li>
    <li>
      <a href="Class-08.html">Class 8: Intro to R</a>
    </li>
    <li>
      <a href="Class-09.html">Class 9: Linear Models</a>
    </li>
    <li>
      <a href="Class-10.html">Class 10: LMs and GLMs</a>
    </li>
    <li>
      <a href="Class-11.html">Class 11: Prediction and GLMs</a>
    </li>
    <li>
      <a href="Class-12.html">Class 12: GLMs continued</a>
    </li>
    <li>
      <a href="Class-13.html">Class 13: Poissons</a>
    </li>
    <li>
      <a href="Class-14.html">Class 14: HLMs</a>
    </li>
    <li>
      <a href="Class-15.html">Class 15: HLMs and occupancy</a>
    </li>
    <li>
      <a href="Class-16.html">Class 16: Occupancy continued</a>
    </li>
    <li>
      <a href="Class-17.html">Class 17: Influence diagrams, Sensitivity analyses &amp; N-Mixtures</a>
    </li>
    <li>
      <a href="Class-18.html">Class 18: N-Mixtures &amp; Estimating abundance</a>
    </li>
    <li>
      <a href="Class-19.html">Class 19: Population dynamics and decisions</a>
    </li>
    <li>
      <a href="Class-20.html">Class 20</a>
    </li>
    <li>
      <a href="Class-21.html">Class 21</a>
    </li>
    <li>
      <a href="Class-22.html">Class 22: ARM</a>
    </li>
    <li>
      <a href="Class-23.html">Class 23: ARM continued</a>
    </li>
    <li>
      <a href="Class-24.html">Class 24: Expert elicitation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Assignments
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="hw-01.html">Homework 1</a>
    </li>
    <li>
      <a href="hw-02.html">Homework 2</a>
    </li>
    <li>
      <a href="hw-03.html">Homework 3</a>
    </li>
    <li>
      <a href="hw-04.html">Homework 4</a>
    </li>
    <li>
      <a href="hw-05.html">Homework 5</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Additional Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="R-tutorials.html">R tutorials</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<!--


rmarkdown::render_site("Class-24.Rmd")# build website
library(knitr)
rmarkdown::render_site()# build website

source("_build.R")
build("Class-24",bld="PAGE",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

# PURL THIS SHIT & MOVE FILES TO DOCS
build("Class-24",bld="SCRIPT",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

source("_build.R");build("Class-24",bld="PAGE",docs=TRUE)# bld = PAGE,ENTIRE,SCRIPT

-->
<p><img src="media/banner-07.jpg" width="100%" /></p>
<div id="class-24-expert-elicitation" class="section level1 unnumbered">
<h1>Class 24: Expert elicitation</h1>
</div>
<div id="class-preliminaries" class="section level1">
<h1>Class preliminaries</h1>
<ul>
<li>Supplemental background reading:
<ul>
<li>Conroy and Peterson Chapter 6 p 165-191</li>
</ul></li>
<li>Class project presentation during final exam period-April 28th at 3pm.</li>
<li>Link to class recording <a href="">YouTube</a></li>
<li>Today’s R script <a href="scripts/Class-24.R">Class-24.R</a></li>
<li>Today’s Class deck <a href="pdfs/class-24.pdf">PDF</a></li>
<li>A couple of <code>R</code> packages we will be using</li>
</ul>
<pre class="r"><code># install.packages(&quot;fitdistrplus&quot;)
# install.packages(&quot;Hmisc&quot;)</code></pre>
<div id="class-overview-objectives" class="section level2">
<h2>Class overview &amp; objectives</h2>
<p>The objectives of this class are to:</p>
<ol style="list-style-type: decimal">
<li>Provide background on the use of elicitation to parameterized decision models</li>
<li>Wrap up class… Where have we been, where did we go?</li>
</ol>
</div>
</div>
<div id="vox-populi-and-elicitation" class="section level1">
<h1>Vox Populi and elicitation</h1>
<p>Let’s take a quick look at a recent elicitation exercise I had you do a week ago. Recall I had you guess the most likely maximum temperature for the following day. Below are the results of that elicitation entered in the <code>data.frame()</code> below.</p>
<pre class="r"><code>temp_elic&lt;- data.frame(
    id=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),
    low=c(68,80,70,79,78,80,76,82,87,50,80,79,77,78,79,85,84,79),
    high=c(81,84,90,84,93,86,88,88,78,100,90,92,85,85,85,88,91,89),
    likely=c(77,82,85,83,86,83,83,86,83,85,85,86,82,81,81,87,87,85),
    confidence=c(75,79,50,40,95,75,80,90,90,25,70,80,80,80,80,5,80,60))
temp_elic</code></pre>
<pre><code>##    id low high likely confidence
## 1   1  68   81     77         75
## 2   2  80   84     82         79
## 3   3  70   90     85         50
## 4   4  79   84     83         40
## 5   5  78   93     86         95
## 6   6  80   86     83         75
## 7   7  76   88     83         80
## 8   8  82   88     86         90
## 9   9  87   78     83         90
## 10 10  50  100     85         25
## 11 11  80   90     85         70
## 12 12  79   92     86         80
## 13 13  77   85     82         80
## 14 14  78   85     81         80
## 15 15  79   85     81         80
## 16 16  85   88     87          5
## 17 17  84   91     87         80
## 18 18  79   89     85         60</code></pre>
<p>Well there was a bit of variability among students in terms of the most likely value. Let’s look at the distribution of likely vales and the true value.</p>
<pre class="r"><code>hist(temp_elic$likely,
    main=&quot;Elicted likely max. temperatures&quot;,
    xlab=&quot;Temperature&quot;)
abline(v=mean(temp_elic$likely),col=&#39;green&#39;,lwd=8)</code></pre>
<p><img src="Class-24_files/figure-html/unnamed-chunk-4-1.png" width="672" /> The true value was a whopping 87.</p>
<p><img src="media/Class-24-Screenshot_2017-04-20-22-20-42.png" width="50%" style="display: block; margin: auto;" /></p>
<div id="elicitation-and-collective-wisdom" class="section level2">
<h2>Elicitation and Collective wisdom?</h2>
<p>This elicitation is reminiscent of the idea of collective wisdom. This is known as Vox Populi <a href="pdfs/galton-1907-vox-populi.pdf">(PDF)</a>, where the belief of the majority (i.e., most likely, middle estimate) is a good approximation of reality. The story goes that 787 people voted on the weight of a fat ox in a weight judging competition at the West of England Fat Stock and Poultry Exhibition</p>
<p>In 2015 NPR Planet Money replicated the experiment on the line and got some surprisingly good results for estimating the weight of a dairy cow <a href="pdfs/cow-weight.pdf">(PDF)</a>. Turns out, experts underestimated by about 6% for a cow. There may be some variation in estimate bias based off of animal size, some suggest that smaller animals like sheep or <a href="https://youtu.be/c2glOppqBRg">llamas</a> may be overestimated.</p>
<p>Well that is not too bad, off by a couple of degrees. A sensitivity analysis can help inform the consequences of using elicited data. Eliciting useful expert information can be a difficult task and several approaches have been developed to help analysts elicit information. Let’s look at some ways to use expert elicitation in natural resource decision making contexts.</p>
</div>
</div>
<div id="eliciting-and-quantifying-expert-judgment" class="section level1">
<h1>Eliciting and quantifying expert judgment</h1>
<p>Expert information can be used to parameterize decision models. If you have not completed those lessons, please review them before taking this lesson. The use of expert judgment involves asking one or more experts that are familiar with the phenomenon being modeled (e.g., the effects of disease on wildlife populations) to parameterize the relationship between two or more model components. There are two approaches that are categorized by the means of elicitation: 1) direct elicitation and 2) indirect elicitation, and the type of measure provided by the experts: 1) quantitative or 2) qualitative. This class will demonstrate how to quantify and use expert judgment and conduct the analysis using quantitative direct elicitation and indirect elicitation methods. Specifically, we will cover</p>
<ol style="list-style-type: decimal">
<li>Probability elicitation</li>
<li>Frequency elicitation</li>
<li>Value elicitation</li>
<li>Function elicitation</li>
</ol>
<div id="probability-elicitation" class="section level2">
<h2>Probability elicitation</h2>
<p>Probability elicitation is a direct, quantitative method that requires experts that are familiar and comfortable with statistical concepts, such as probability. Typical type of question used for probability elicitation is:</p>
<p><em>“Given that the maximum summer water temperature is 33C or greater, what is the probability that an amphibian species will survive?”</em></p>
<p>Suppose we asked 6 experts this question and received the following, values 0.5, 0.6, 0.45, 0.65, 0.45, 0.7. We could combine the values across experts by treating these values as data and calculating a mean. Uncertainty among experts can be estimated by calculating the variance.</p>
<pre class="r"><code>surv&lt;- c(0.5, 0.6, 0.45, 0.65, 0.45, 0.7)
surv_mean&lt;-mean(surv)
surv_var&lt;- var(surv)</code></pre>
<p>That gets us a mean and a variance but if we used that to come up with a distribution assuming normality, survival values can exceed 1 or be less than 0.</p>
<p>Uncertainty in a probabilities like survival can be modeled using a beta distribution which is constrained between 0 and 1 <a href="https://en.wikipedia.org/wiki/Beta_distribution">(more info)</a>. Thus, we could use the method of moments to estimate the parameters of the beta (a, b) from the mean and the standard deviation.</p>
<p>Specifically, the shape parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> of a beta distribution can be estimated as:</p>
<p><span class="math display">\[a = \mu\cdot \frac{\mu\cdot(1-\mu)}{\sigma^2-1}\]</span></p>
<p>and</p>
<p><span class="math display">\[b = (1-\mu)\cdot\frac{\mu\cdot(1-\mu) }{\sigma^2-1}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the mean survival, and</li>
<li><span class="math inline">\(\sigma^2\)</span> is the variance.</li>
</ul>
<p>We can make a function to estiamte <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> given some data in <code>R</code>. Fun right?</p>
<pre class="r"><code>### beta method of moments
beta.mom&lt;-function(mean,v)
    {
    x&lt;-mean
    a&lt;-x*(x*(1-x)/v-1)
    b&lt;-(1-x)*(x*(1-x)/v-1)
    c(a,b)
    }</code></pre>
<p>Now we can feed a mean and a variance and the shape parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are returned.</p>
<pre class="r"><code>out&lt;-beta.mom(surv_mean,surv_var)
out</code></pre>
<pre><code>## [1] 11.501531  9.098226</code></pre>
<p>We could alternatively use maximum likelihood to estimate the 2 beta distribution parameters, <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
<p>This requires using a function that returns the log likelihood for each data point given the parameter estimates and the assumed distribution. The log likelihoods are then summed and that value is iterated for varying over values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> to find the values that maximize the log likelihood. Optimization behaves pretty well if you can give it a good ball park to start from in terms of estimating <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, so we might as well use the method of moments estimates for to start the optimization!</p>
<p>Fortunately there are functions built in to ‘R’ that will do this for us. We can use the <code>fitdist()</code> function to fit a beta distribution to some data and estimate the values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> that maximize the log likelihood. This function can be called using the <code>fitdistrplus</code> library.</p>
<p>Here we will fit a beta distribution to the survivals.</p>
<pre class="r"><code>library(fitdistrplus)</code></pre>
<pre><code>## Warning: package &#39;fitdistrplus&#39; was built under R version 3.1.3</code></pre>
<pre class="r"><code>fit&lt;- fitdist(data=surv,
    distr=&quot;beta&quot;,
    start=c(shape1=out[1],
        shape2=out[2]))</code></pre>
<p>Sometimes errors will be thrown but this is usually just because the liklihood is being evaluated at boundaries. Let’s look at our estimated <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> values.</p>
<pre class="r"><code>fit</code></pre>
<pre><code>## Fitting of the distribution &#39; beta &#39; by maximum likelihood 
## Parameters:
##        estimate Std. Error
## shape1 14.25455   8.170572
## shape2 11.26283   6.425610</code></pre>
<p>Let’s take a look at differences between methods of moments and maximum likelihood estimates.</p>
<p>First we need to generate some outcomes to get the likelihood for.</p>
<pre class="r"><code>x&lt;- seq(0,1,0.01) # survivals to plot</code></pre>
<p>Now we need to calculate the likilihood for the outcomes given the estimates of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> using the methods of moments.</p>
<pre class="r"><code>dmom&lt;- dbeta(x=x,
    shape1=out[1],
    shape2=out[2])</code></pre>
<p>We can also use the same process to using the maximum likelihood estimates.</p>
<pre class="r"><code>dmll&lt;- dbeta(x=x,
    shape1=fit$estimate[1],
    shape2=fit$estimate[2] )</code></pre>
<p>Now we can plot the 2 distributions to see if there is anything different.</p>
<pre class="r"><code>plot(x=x,y=dmom,
    xlab=&quot;Survival&quot;,
    ylab=&quot;Likelihood&quot;,type=&#39;l&#39;,
    ylim=c(0,4),
    las=1)
points(x=x,y=dmll, type=&#39;l&#39;, lty=2)
legend(&quot;topleft&quot;,
    legend=c(&quot;Method of moments&quot;,&quot;Max. Likelihood&quot;),
    lty=c(1,2))</code></pre>
<p><img src="Class-24_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Not too much difference, although there appears to be a bit more certainty around the distribution generated from the maximum likelihood estimates, but the expected values appear to be similar.</p>
<div id="accounting-for-experience" class="section level3">
<h3>Accounting for experience</h3>
<p>Often one or more experts have greater experience than others and we have greater faith in the values they provide. Weights are represented using positive numbers with larger numbers representing greater weight. The absolute values of the weights do not matter. Rather it is the relative differences among the weights that are used to weight the values provided by the experts. For example, the weights 1,1,2,1,2,4 are equal to 0.091,0.091,0.182,0.091,0.182,0.364 because the relative proportions are equal. To demonstrate we can use the <code>wtd.mean()</code> and <code>wtd.var()</code> function to estimate the mean and the variance incorporating the expert weights. We need the <code>Hmisc</code> library to get the <code>wtd.mean()</code> and <code>wtd.var()</code> functions.</p>
<p>Let’s make a vector of weights that match up to the vector or survivals.</p>
<pre class="r"><code>library(Hmisc)</code></pre>
<pre><code>## Warning: package &#39;Hmisc&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Warning: package &#39;lattice&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: survival</code></pre>
<pre><code>## Warning: package &#39;survival&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: Formula</code></pre>
<pre><code>## Warning: package &#39;Formula&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.1.3</code></pre>
<pre><code>## 
## Attaching package: &#39;Hmisc&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     format.pval, round.POSIXt, trunc.POSIXt, units</code></pre>
<pre class="r"><code># weights as whole numbers
wt1&lt;-c(1,1,2,1,2,4)
# weights as proportions
wt2&lt;- wt1/sum(wt1)</code></pre>
<p>Now we can use the <code>wtd.mean()</code> and <code>wtd.var()</code> function to account for expertise and experience.</p>
<pre class="r"><code>#means
wtd.mean(surv,wt1)</code></pre>
<pre><code>## [1] 0.5772727</code></pre>
<pre class="r"><code>wtd.mean(surv,wt2)</code></pre>
<pre><code>## [1] 0.5772727</code></pre>
<pre class="r"><code>#variance
wtd.var(surv,wt1)</code></pre>
<pre><code>## [1] 0.01368182</code></pre>
<pre class="r"><code>#wtd.var(surv,wt2) will not work, needs integer values!</code></pre>
<p>Now we can use those weighted values to calculate the estimates of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> for the beta distribution.</p>
<pre class="r"><code>out_w&lt;-beta.mom(mean=wtd.mean(surv,wt1),
v=wtd.var(surv,wt1))
out_w</code></pre>
<pre><code>## [1] 9.718964 7.117037</code></pre>
<p>Here we calculated weighted and unweighted means and variances of these survival values provided by experts. Using those values we then calculated the parameters of a beta distribution using either method of movements or maximum likelihood.</p>
<pre class="r"><code>S&lt;- seq(0,1,0.01)
unweighted&lt;-dbeta(S,
    shape1=out[1],
    shape2=out[2])

weighted&lt;-dbeta(S,
    shape1=out_w[1], 
    shape2= out_w[2])</code></pre>
<p>We can visualize the effect by plotting the probability density for the beta distribution estimated from the unweighted and weighted mean and variance. It should be different. Let’s take a look.</p>
<pre class="r"><code>plot(S,unweighted,
    col=&quot;black&quot;,
    type=&#39;l&#39;,
    ylab=&quot;Density&quot;,
    lwd=2,
    ylim=c(0,4),
    las=1)
points(S,weighted,
    col=&quot;red&quot;,
    type=&#39;l&#39;,
    lwd=2)
legend(&quot;topleft&quot;,
    legend=c(&quot;unweighted&quot;, &quot;weighted&quot;),
    lty=1,
    col=c(&quot;black&quot;,&quot;red&quot;))</code></pre>
<p><img src="Class-24_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Weighting the experts’ estimates moved the location to be closer to 0.6 and increased the uncertainty (spread) around the location.</p>
<p><strong>Things to consider here are that the use of expert information and weighted can be good, but it can also be bad… It may be possible to ‘game’ the system if an expert or experts are given an undue amount of weight. So it might be prudent to run analysis/simulations both ways to assess whether the effect of weighting has a dramatic effect on the decision.</strong></p>
</div>
<div id="conditional-probability-tables" class="section level3">
<h3>Conditional probability tables</h3>
<p>In some instances, you will need to ask experts to fill out conditional probability tables that are used in influence diagrams and then combine these values across experts. For example, suppose that we asked 3 experts to fill out the following tables for estimating species status:</p>
<table>
<thead>
<tr class="header">
<th>Expert</th>
<th align="center">Snag density</th>
<th align="center">Forest canopy</th>
<th align="center">Absent</th>
<th align="center">Rare</th>
<th align="center">Abundant</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>expert 1</td>
<td align="center">Many</td>
<td align="center">Open</td>
<td align="center">0.36</td>
<td align="center">0.36</td>
<td align="center">0.29</td>
</tr>
<tr class="even">
<td></td>
<td align="center">Many</td>
<td align="center">Closed</td>
<td align="center">0.15</td>
<td align="center">0.35</td>
<td align="center">0.5</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">Few</td>
<td align="center">Open</td>
<td align="center">0.67</td>
<td align="center">0.25</td>
<td align="center">0.08</td>
</tr>
<tr class="even">
<td></td>
<td align="center">Few</td>
<td align="center">Closed</td>
<td align="center">0.44</td>
<td align="center">0.38</td>
<td align="center">0.19</td>
</tr>
<tr class="odd">
<td>expert2</td>
<td align="center">Many</td>
<td align="center">Open</td>
<td align="center">0.37</td>
<td align="center">0.45</td>
<td align="center">0.18</td>
</tr>
<tr class="even">
<td></td>
<td align="center">Many</td>
<td align="center">Closed</td>
<td align="center">0.17</td>
<td align="center">0.41</td>
<td align="center">0.41</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">Few</td>
<td align="center">Open</td>
<td align="center">0.69</td>
<td align="center">0.28</td>
<td align="center">0.03</td>
</tr>
<tr class="even">
<td></td>
<td align="center">Few</td>
<td align="center">Closed</td>
<td align="center">0.51</td>
<td align="center">0.47</td>
<td align="center">0.01</td>
</tr>
<tr class="odd">
<td>expert3</td>
<td align="center">Many</td>
<td align="center">Open</td>
<td align="center">0.36</td>
<td align="center">0.38</td>
<td align="center">0.26</td>
</tr>
<tr class="even">
<td></td>
<td align="center">Many</td>
<td align="center">Closed</td>
<td align="center">0.17</td>
<td align="center">0.43</td>
<td align="center">0.41</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">Few</td>
<td align="center">Open</td>
<td align="center">0.66</td>
<td align="center">0.3</td>
<td align="center">0.03</td>
</tr>
<tr class="even">
<td></td>
<td align="center">Few</td>
<td align="center">Closed</td>
<td align="center">0.56</td>
<td align="center">0.42</td>
<td align="center">0.03</td>
</tr>
</tbody>
</table>
<p>As before, we can calculate the means and weighted means of the probabilities in corresponding cells. However, be careful that the correct cells are selected as below or that you read each expert table as a matrix and you manipulate it that way.</p>
<p>Here are the probabilities for absent.</p>
<pre class="r"><code># Absent
Many.Open&lt;-c(0.36,0.37,0.36)
Many.Closed&lt;-c(0.15,0.17,0.17)
Few.Open&lt;-c(0.67,0.69,0.66)
Few.Closed&lt;-c(0.44,0.51,0.56)</code></pre>
<p>The Means are calculated as:</p>
<pre class="r"><code>#means
mean(Many.Open)</code></pre>
<pre><code>## [1] 0.3633333</code></pre>
<pre class="r"><code>mean(Many.Closed)</code></pre>
<pre><code>## [1] 0.1633333</code></pre>
<pre class="r"><code>mean(Few.Open)</code></pre>
<pre><code>## [1] 0.6733333</code></pre>
<pre class="r"><code>mean(Few.Closed)</code></pre>
<pre><code>## [1] 0.5033333</code></pre>
<p>Let’s try weighting like we did before. Here Expert 3 carries a lot of weight.</p>
<pre class="r"><code>#expert weights
wt&lt;-c(5,10,100)</code></pre>
<p>Here we use the <code>wtd.mean()</code> function to calculate the weighted means.</p>
<pre class="r"><code>#weighted means
wtd.mean(Many.Open,wt)</code></pre>
<pre><code>## [1] 0.3608696</code></pre>
<pre class="r"><code>wtd.mean(Many.Closed,wt)</code></pre>
<pre><code>## [1] 0.1691304</code></pre>
<pre class="r"><code>wtd.mean(Few.Open,wt)</code></pre>
<pre><code>## [1] 0.6630435</code></pre>
<pre class="r"><code>wtd.mean(Few.Closed,wt)</code></pre>
<pre><code>## [1] 0.5504348</code></pre>
<p>Now you can work through all the values and calculate a single conditional probability table.</p>
<!--
do whole table if possible. circle back
-->
</div>
</div>
<div id="frequency-elicitation" class="section level2">
<h2>Frequency elicitation</h2>
<p>Frequency elicitation is an indirect, quantitative method that does not require experts that are familiar and comfortable with statistical concepts. Typical type of question for frequency elicitation is:</p>
<p><em>“100 individuals from an amphibian species are exposed to temperatures &gt; 33C, how many will survive?”</em></p>
<p>These values can be used to calculate probabilities and average across experts. For example assume, that 4 experts answered the above question by providing the following values: 50, 30, 25, and 40. We can calculate the probability of survival as the number surviving divided by 100.</p>
<pre class="r"><code>number_surv&lt;-c(50, 30, 25, 40)
#remember 100 individuals
probability_surv&lt;-number_surv/100</code></pre>
<p>Now we can calculate the mean and the variance.</p>
<pre class="r"><code>mean(probability_surv)</code></pre>
<pre><code>## [1] 0.3625</code></pre>
<pre class="r"><code>var(probability_surv)</code></pre>
<pre><code>## [1] 0.01229167</code></pre>
<p>Here we also could use weighting scheme and use the method of moments or maximum likelihood approach to estimate the parameters of a beta distribution, if we desired. Alternatively, we could use the values directly to estimate the parameters of a beta distribution. Remember that the parameters of a beta distribution represent: a = number of successes (e.g., survivors) and b = the number of losses (e.g. deaths), so we have</p>
<pre class="r"><code>number_surv&lt;-c(50, 30, 25, 40)
number_die&lt;- 100-number_surv
#let&#39;s see what that gets us in terms of means and variance for probability
p_s&lt;-rbeta(1000,number_surv,number_die)
mean(p_s)</code></pre>
<pre><code>## [1] 0.3607249</code></pre>
<pre class="r"><code>var(p_s)</code></pre>
<pre><code>## [1] 0.01133936</code></pre>
<p>The mean value was fairly close as was the variance. If we wanted to weight experts differently, we could rescale the values. For example, assume that expert 1 and 2, should receive half the weight of experts 3 and 4. We could do the following so the denominators are now 50, 50, 100, and 100 and therefore the number of survivors and number that die change.</p>
<pre class="r"><code>number_surv&lt;-c(25, 15, 25, 40)
number_die&lt;-c(25, 35, 75, 60)
totals&lt;-number_surv+number_die
totals ## notice that the sum of survive and die for expert 1 and 2 is 50</code></pre>
<pre><code>## [1]  50  50 100 100</code></pre>
<pre class="r"><code>p_s&lt;-rbeta(1000,number_surv,number_die)
mean(p_s)</code></pre>
<pre><code>## [1] 0.3627654</code></pre>
<pre class="r"><code>var(p_s)</code></pre>
<pre><code>## [1] 0.01234249</code></pre>
<p>We need to keep in mind that the variance on the beta is influenced by the size of the parameters.</p>
<p>For example, here is what happens when we increase the sample size to 100 from 1.</p>
<pre class="r"><code>p_s&lt;-rbeta(1000,1,1)
mean(p_s)</code></pre>
<pre><code>## [1] 0.5014522</code></pre>
<pre class="r"><code>var(p_s)</code></pre>
<pre><code>## [1] 0.08331411</code></pre>
<pre class="r"><code>#expected value the same, variance different
p_s&lt;-rbeta(1000,100,100)
mean(p_s)</code></pre>
<pre><code>## [1] 0.4998658</code></pre>
<pre class="r"><code>var(p_s)</code></pre>
<pre><code>## [1] 0.001200295</code></pre>
<p>The variance is much smaller when <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are larger. So some caution is appropriate to not unduly minimize uncertainty.</p>
</div>
<div id="value-elicitation" class="section level2">
<h2>Value elicitation</h2>
<p>Value elicitation is a direct, quantitative method that does not require experts that are familiar and comfortable with statistical concepts. Typical type of question for value elicitation is:</p>
<p><em>“What is the LD50 temperature for an amphibian species? (LD50 is the temperature where 50% of animals die).”</em></p>
<p>Assume that we received the following answers from 6 experts: 30, 31, 35, 37, 32, 34.5. We can calculate the mean and the standard deviation. We are using standard deviation here because we are going to assume normality.</p>
<pre class="r"><code>temp&lt;-c(30, 31, 35, 37, 32, 34.5)
mean(temp)</code></pre>
<pre><code>## [1] 33.25</code></pre>
<pre class="r"><code>sd(temp)</code></pre>
<pre><code>## [1] 2.678619</code></pre>
<p>These parameters can then be used to parameterize relations among model components. For example, what is the probability that 50% of the amphibians will die as temperatures reach 34 degrees:</p>
<pre class="r"><code>pnorm(34,mean(temp),sd(temp))</code></pre>
<pre><code>## [1] 0.6102593</code></pre>
<p>In other words there is a 60% chance that 50% of the amphibians will die given the expert opinion and a temperature of 34 degrees.</p>
</div>
<div id="function-elicitation" class="section level2">
<h2>Function elicitation</h2>
<p>Function elicitation is an indirect, quantitative method that does not require experts that are familiar and comfortable with statistical concepts. Here, experts define the functional relationship between two or more model components using a graphical representation. For example, an expert is asked to define the relation between amphibian survival and summer temperatures by drawing a line on paper or in a spreadsheet <a href="dat/Chinook-elicitation.xlsx">(Example)</a>.</p>
<p>For a simpler example, let’s look at the figure below that was drawn by an expert:</p>
<p><img src="Class-24_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>This drawn relationship needs to be turned into a function. The first step is to estimate the survival values where the cross the summer temperatures. Doing so would get you the data contained in the <code>expertDat</code> below.</p>
<pre class="r"><code>expertDat&lt;- data.frame(
    ave_summer_temp = c(25,26,27,28,
        29,30,31,32,33,34,35,36,
        37,38,39,40),
    est_survival = c(0.85,0.825,
        0.8,0.75,0.725,0.7,0.65,0.6,
        0.55,0.5,0.45,
        0.4,0.35,0.3,
        0.275,0.225))
expertDat</code></pre>
<pre><code>##    ave_summer_temp est_survival
## 1               25        0.850
## 2               26        0.825
## 3               27        0.800
## 4               28        0.750
## 5               29        0.725
## 6               30        0.700
## 7               31        0.650
## 8               32        0.600
## 9               33        0.550
## 10              34        0.500
## 11              35        0.450
## 12              36        0.400
## 13              37        0.350
## 14              38        0.300
## 15              39        0.275
## 16              40        0.225</code></pre>
<p>Because we are modeling a probability, logit-linear regression model seems appropriate. However, R requires the response to be binary and in live, dead format. For convenience, let’s assume that we began with 100 individuals and calculate the number surviving and dying based on the probabilities estimates from the figure drawn by the expert. We then have:</p>
<pre class="r"><code>surv&lt;-round(expertDat$est_survival*100)
died&lt;-100-surv
response&lt;-cbind(surv,died)
glm(response ~ expertDat$ave_summer_temp, 
    fam=binomial)</code></pre>
<pre><code>## 
## Call:  glm(formula = response ~ expertDat$ave_summer_temp, family = binomial)
## 
## Coefficients:
##               (Intercept)  expertDat$ave_summer_temp  
##                    6.6889                    -0.1971  
## 
## Degrees of Freedom: 15 Total (i.e. Null);  14 Residual
## Null Deviance:       275.6 
## Residual Deviance: 0.5251    AIC: 82.16</code></pre>
<p>The function for defining this relationship is a logit linear model <span class="math inline">\(6.689 - 0.197 \cdot temperature\)</span>. To incorporate the variability among experts, the slopes and intercepts could be averaged and the averages used to parameterize the model, or maybe a hierarchical model used.</p>
<p>Let’s use the graph below created from <code>musselDat</code> to estimate a function that will closely approximate the expertâ€™s belief of the relationship between mussel growth and temperature.</p>
<p>We can use the graph below to estimate a function that will close approximate the expert’s belief of the relationship between mussel growth and temperature.</p>
<pre class="r"><code>musselDat&lt;- data.frame(ave_summer_temp=c(14,15,16,17,18,19,
        20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35),
    mussel_growth=c(23.314,24.115,24.716,25.317,25.718,
        25.919,26.120,26.121,26.122,25.923,25.524,25.125,24.526,
        23.927,23.128,22.129,21.130,19.931,18.732,17.333,15.734,
        14.135))

plot(mussel_growth~ave_summer_temp,
    data=musselDat,
    xlab= &quot;Average summer temperature&quot;,
    ylab=&quot;Mussel growth&quot;,
    las=1,
    type=&#39;l&#39;)</code></pre>
<p><img src="Class-24_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>The relationship looks nonlinear maybe need a quadratic term</p>
<pre class="r"><code>musselDat$ave_summer_tempsq&lt;-musselDat$ave_summer_temp^2
mod&lt;-lm(mussel_growth ~ ave_summer_temp + ave_summer_tempsq, musselDat)</code></pre>
<p>Plot the function to make sure it represents the expert figure</p>
<pre class="r"><code>temp&lt;-c(14:35)
pred&lt;-predict(mod,ave_summer_temp = temp)
plot(pred~temp,
    lty=1,
    type = &quot;l&quot;,
    lwd=1,
    ylab=&quot;Mussel growth&quot;,
    xlab=&quot;Average temperature&quot;,
    las=1)
points(mussel_growth~ave_summer_temp,musselDat)
    legend(&quot;topright&quot;,c(&quot;Predicted&quot;,&quot;Elicited&quot;),pch=c(NA,1),lty=c(1,NA))</code></pre>
<p>Looks good, we can now use that function to make predictions of things like a change in temperature on growth.</p>
</div>
<div id="quantifying-uncertainty-in-expert-judgment" class="section level2">
<h2>Quantifying uncertainty in expert judgment</h2>
<p>To minimize the effect of overconfidence, it is recommended to use the four step process to uncertainty elicitation proposed by Speirs-Bridge et al. (2010). In the 4 step process, experts are asked the following 4 questions:</p>
<ol style="list-style-type: decimal">
<li>What do you think the lowest value could be? ____</li>
<li>What do you think the highest value could be? ____</li>
<li>What is your most likely estimate?___</li>
<li>How confident (%) are you that the interval you created, from lowest highest, will capture the true value? ___</li>
</ol>
<p>For example, 100 individuals from an amphibian species are exposed 33C temperatures.</p>
<ol style="list-style-type: decimal">
<li>What are the fewest number that would survive? ____</li>
<li>What are the most that would survive? ____</li>
<li>What is your most likely estimate of the number surviving?___</li>
<li>How confident (%) are you that the interval you created, from lowest highest, will capture the true value? ___</li>
</ol>
<p>Let’s assume that we asked an expert the first question above: Given that the maximum summer water temperature is 33C or greater, what is the probability that an amphibian species will survive</p>
<ol style="list-style-type: decimal">
<li>What do you think the lowest value could be? <strong>0.25</strong></li>
<li>What do you think the highest value could be? <strong>0.9</strong></li>
<li>What is your most likely estimate? <strong>0.55</strong></li>
<li>How confident (%) are you that the interval you created, from lowest highest,will capture the true value? <strong>0.9</strong></li>
</ol>
<p>To estimate the parameters, we need to find the beta distribution that best fits those conditions, i.e., a median value of 0.5 and upper and lower 90% confidence limits of 0.25 to 0.9. WE can fit these parameters in <code>R</code> using teh <code>qmeddist()</code> fuction in the <code>fitdistplus</code> package. We can do this with the following code:</p>
<p>First we need to make a vector of values from the expert.</p>
<pre class="r"><code>## lower, median, and upper survival values
w&lt;-c(0.25, 0.55, 0.9)</code></pre>
<p>Now we can set up the fitting given 90% confidence by the expert. Since our confidence is 2 sided it the minimum and maximum end up being the 5 and 95 percentile.</p>
<pre class="r"><code>### load library first
library(fitdistrplus)
# 90% confidence so specify lower 5 and upper 95 percentiles
est&lt;-qmedist(data=w,
    distr=&quot;beta&quot;,
    probs=c(0.05,0.95))
parms&lt;-est$estimate
parms</code></pre>
<pre><code>##   shape1   shape2 
## 3.906427 2.729426</code></pre>
<p>Letâ€™s see how close we got</p>
<pre class="r"><code>test&lt;-rbeta(1000,parms[1],parms[2])
quantile(test,c(0.05,0.5,0.95))</code></pre>
<pre><code>##        5%       50%       95% 
## 0.2772954 0.6038069 0.8738369</code></pre>
<p>Not too bad considering expert’s judgments don’t always follow the laws of probability. Note that shape1 is alpha and shape2 is beta for the beta distribution. We could combine these across experts using the Bayesian methods we used earlier.</p>
<p>Let’s try the same thing, but this time asking: What is the LD50 temperature for an amphibian species?</p>
<ol style="list-style-type: decimal">
<li>What do you think the lowest value could be? <strong>33</strong></li>
<li>What do you think the highest value could be? <strong>39</strong></li>
<li>What is your most likely estimate?<strong>35</strong></li>
<li>How confident (%) are you that the interval you created, from lowest highest, will capture the true value? <strong>0.8</strong></li>
</ol>
<p>The corresponding R code and output are:</p>
<pre class="r"><code>## lower, mean, and upper values
w&lt;-c(33, 35, 39)
library(fitdistrplus)
# 80% confidence so specify lower 10 and upper 90 percentiles
est&lt;-qmedist(w, &quot;norm&quot;, probs=c(0.10, 0.90))</code></pre>
<p>Don’t worry about the warnings if it throws them, the functions is just being evaluated at some boundary locations</p>
<pre class="r"><code>parms&lt;-est$estimate
parms</code></pre>
<pre><code>##      mean        sd 
## 35.799954  1.872723</code></pre>
<pre class="r"><code>## lets see how close we got
test&lt;-rnorm(1000,parms[1],parms[2])
quantile(test,c(0.10,0.5,0.90))</code></pre>
<pre><code>##      10%      50%      90% 
## 33.52439 35.85813 38.27675</code></pre>
<p>As before, the estimates are not too bad and they can be combined across experts using prior and posterior techniques we learned in lab 6.</p>
</div>
<div id="eliciting-maximum-temperature" class="section level2">
<h2>Eliciting maximum temperature</h2>
<p>A week ago we asked the question:</p>
<p>_“What will be the maximum temperature tomorrow?”)</p>
<p>I use dthe 4 step process to obtain your estimates and levels of confidence.</p>
<p>Now we can estimate the parameters for a normal distribution using the above process in R. Combine the estimates for the two experts using the Bayesian prior and posterior approach detailed in Lab 6.</p>
<p>For this example our data is as follows:</p>
<table>
<thead>
<tr class="header">
<th>Value</th>
<th align="center">Expert 1</th>
<th align="center">Expert 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Lowest value</td>
<td align="center">68</td>
<td align="center">82</td>
</tr>
<tr class="even">
<td>Highest value</td>
<td align="center">81</td>
<td align="center">88</td>
</tr>
<tr class="odd">
<td>Most likely value</td>
<td align="center">77</td>
<td align="center">86</td>
</tr>
<tr class="even">
<td>Confidence level (%)</td>
<td align="center">75</td>
<td align="center">90</td>
</tr>
</tbody>
</table>
<pre class="r"><code>w&lt;-c(68,77,81)
c&lt;-0.75 # CONFIDENCE
CI&lt;-c((1-c)/2,1-(1-c)/2) # CONFIDENCE INTERVAL
est&lt;-qmedist(w,&quot;norm&quot;,probs=CI) 
parms1&lt;-est$estimate
parms1</code></pre>
<pre><code>##      mean        sd 
## 75.125029  4.237909</code></pre>
<p>Note: The NAs produced are just part of the optimization. We can use simulation to evaluate our estimates.</p>
<pre class="r"><code>test&lt;-rnorm(1000,parms1[1],parms1[2])
quantile(test,c(0.005,0.5,0.995))</code></pre>
<pre><code>##     0.5%      50%    99.5% 
## 63.69695 74.92230 84.55403</code></pre>
<p>Now we can look at expert 2 and repeat the process.</p>
<pre class="r"><code>#lower, median, and upper values from Expert 2
w&lt;-c(82,86,88)
c&lt;-0.9
CI&lt;-c((1-c)/2,1-(1-c)/2)
est&lt;-qmedist(w,&quot;norm&quot;,probs=CI)
#Estimates
parms2&lt;-est$estimate
parms2</code></pre>
<pre><code>##      mean        sd 
## 85.100141  1.641456</code></pre>
<pre class="r"><code>test&lt;-rnorm(1000,parms2[1],parms2[2])
quantile(test,c(0.01,0.5,0.99))</code></pre>
<pre><code>##       1%      50%      99% 
## 81.22705 85.13921 88.88598</code></pre>
<p>We can combine the estimates for the two experts using the Bayesian prior and posterior approach. Here we will use the estimates for expert 1 as the prior. All we need to do is calculate the probability for each outcome, in this case <span class="math inline">\(\mu\)</span> is between 20 and 90 given the parameter estimates for expert 1.</p>
<pre class="r"><code>mu&lt;-seq(50,100,0.1) # possible outcomes
expert1_lik&lt;-dnorm(x=mu,
    mean=parms1[1],
    sd=parms1[2])
expert1_lik&lt;- expert1_lik/sum(expert1_lik) # integrate to 1</code></pre>
<p>Now we add the data from expert 2 and update the posterior.</p>
<pre class="r"><code>#Addition of second expert
expert2_lik&lt;-dnorm(mu,parms2[1],parms2[2])
expert2_lik&lt;- expert2_lik/sum(expert2_lik)
prior&lt;- expert1_lik/sum(expert1_lik) # integrate to 1
plot(x=mu,
    y=prior,
    col=&quot;black&quot;,
    lty=1,
    lwd=3,
    type=&#39;l&#39;,
    ylim=c(0,0.025),
    ylab=&quot;Probability&quot;,
    xlab=&quot;Temperature&quot;)
lines(x=mu,
    y=expert2_lik,
    col=&quot;black&quot;,
    lty=2,
    lwd=3,
    type=&#39;l&#39;)
legend(&quot;topleft&quot;,c(&quot;Expert 1 (prior)&quot;,
    &quot;Expert 2 (new)&quot;),
    lty=c(1,2),
    col=c(&quot;black&quot;,&quot;black&quot;))</code></pre>
<p><img src="Class-24_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>Now we can combine the information from both experts by multiplying the likelihood of each outcome assuming expert 1 is the prior and expert 2 is new information and then we divide by the sum of the prior times the new likelihood for each outcome.</p>
<pre class="r"><code>post&lt;-(prior*expert2_lik)/sum(prior*expert2_lik)</code></pre>
<p>Lets look at this and see what the prior (expert 1 data only) and posterior (expert 1 and expert 2’s data).</p>
<pre class="r"><code>plot(x=mu,
    y=prior,
    col=&quot;black&quot;,
    lty=1,
    lwd=3,
    type=&#39;l&#39;,
    ylim=c(0,0.025),
    ylab=&quot;Probability&quot;,
    xlab=&quot;Temperature&quot;)
lines(x=mu,
    y=expert2_lik,
    col=&quot;black&quot;,
    lty=2,
    lwd=3,
    type=&#39;l&#39;)
lines(mu,post,
    col=&quot;red&quot;,
    lty=1,
    lwd=3)
legend(&quot;topleft&quot;,c(&quot;Expert 1 (prior)&quot;,
    &quot;Expert 2 (new)&quot;,
    &quot;Posterior&quot;),
    lty=c(1,2,1),
    lwd=2,
    col=c(&quot;black&quot;,&quot;black&quot;,&quot;red&quot;))</code></pre>
<p><img src="Class-24_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>In the red line we can see the incorporation of expert 2’s information which decreases the uncertainty (spread) and moves the mean in between the prior and the new information. Overall you iterate over multiple experts using Bayes rule to incorporate everybodies information.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
