<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Course home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Course information
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Course home</a>
    </li>
    <li>
      <a href="syllabus.html">Course Syllabus</a>
    </li>
    <li>
      <a href="course-overview.html">Course Overview</a>
    </li>
    <li>
      <a href="final-project.html">About final project</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Classes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Class-01.html">Class 1: Introduction to decision making</a>
    </li>
    <li>
      <a href="Class-02.html">Class 2: The PrOACT Process</a>
    </li>
    <li>
      <a href="Class-03.html">Class 3: Uncertainty and decision making</a>
    </li>
    <li>
      <a href="Class-04.html">Class 4: Decision trees and nets</a>
    </li>
    <li>
      <a href="Class-05.html">Class 5: Intro to SDM and ARM</a>
    </li>
    <li>
      <a href="Class-06.html">Class 6: Structuring and quantifying objectives</a>
    </li>
    <li>
      <a href="Class-07.html">Class 7: Structuring objectives</a>
    </li>
    <li>
      <a href="Class-08.html">Class 8: Intro to R</a>
    </li>
    <li>
      <a href="Class-09.html">Class 9: Linear Models</a>
    </li>
    <li>
      <a href="Class-10.html">Class 10: LMs and GLMs</a>
    </li>
    <li>
      <a href="Class-11.html">Class 11: Prediction and GLMs</a>
    </li>
    <li>
      <a href="Class-12.html">Class 12: GLMs continued</a>
    </li>
    <li>
      <a href="Class-13.html">Class 13: Poissons</a>
    </li>
    <li>
      <a href="Class-14.html">Class 14: HLMs</a>
    </li>
    <li>
      <a href="Class-15.html">Class 15: HLMs and occupancy</a>
    </li>
    <li>
      <a href="Class-16.html">Class 16: Occupancy continued</a>
    </li>
    <li>
      <a href="Class-17.html">Class 17: Influence diagrams, Sensitivity analyses &amp; N-Mixtures</a>
    </li>
    <li>
      <a href="Class-18.html">Class 18: N-Mixtures &amp; Estimating abundance</a>
    </li>
    <li>
      <a href="Class-19.html">Class 19: Population dynamics and decisions</a>
    </li>
    <li>
      <a href="Class-20.html">Class 20</a>
    </li>
    <li>
      <a href="Class-21.html">Class 21</a>
    </li>
    <li>
      <a href="Class-22.html">Class 22</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Assignments
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="hw-01.html">Homework 1</a>
    </li>
    <li>
      <a href="hw-02.html">Homework 2</a>
    </li>
    <li>
      <a href="hw-03.html">Homework 3</a>
    </li>
    <li>
      <a href="hw-04.html">Homework 4</a>
    </li>
    <li>
      <a href="hw-05.html">Homework 5</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Additional Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="R-tutorials.html">R tutorials</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<!--

library(knitr)
rmarkdown::render_site("Class-09.Rmd")# build website

# rmarkdown::render_site()# build webpage
# COPY FILES TO DOCS FOR GITHUB.IO
system(paste("xcopy", 
    '"C:/Users/mcolvin/Documents/Teaching/WFA8433-Natural-Resource-Decision-Making/Course-Materials/_site"', 
    '"C:/Users/mcolvin/Documents/Teaching/WFA8433-Natural-Resource-Decision-Making/Docs"',
    "/E /C /H /R /K /O /Y")) 
  q(save="no") 
-->
<p><img src="media/banner-04.jpg" width="95%" /> <!--
Homework 1:  Introduction to basic computing- R
List of preliminary problems to instructor for review
--></p>
<div id="class-9.-linear-models-in-decision-contexts" class="section level1">
<h1>Class 9. Linear Models in Decision Contexts</h1>
<ul>
<li>Supplemental background reading for next class(es):
<ul>
<li>Breiman, L. 2001. Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author). Statistical Science 25: 199-231.<a href="pdfs/breiman-2001.pdf">PDF</a></li>
<li>Shmueli, G. 2010. To Explain or to Predict?. Statistical Science 25: 289-310. <a href="pdfs/shmueli-2010.pdf">pdf</a></li>
</ul></li>
<li><p>Assignment due: Submit a review of the objectives network randomly assigned to you. See details <a href="hw-01.html">here</a></p></li>
<li>Group work: Continue discussing potential class projects</li>
<li>Link to class recording <a href="https://youtu.be/UU7TrjD0I8Y">YouTube</a></li>
<li><p>Today’s R script <a href="scripts/Class-09.R">Class-09.R</a></p></li>
</ul>
<center>
<img src="media/cn-no-estimate-knows.png" width="35%" />
</center>
<div id="introduction-to-linear-models" class="section level2">
<h2>Introduction to linear models</h2>
<div id="some-preliminaries" class="section level3">
<h3>Some preliminaries</h3>
<ul>
<li>If you want to play along in class download this zipfile <a href="http://mec685.cfr.msstate.edu/class-09.zip">*.zip</a>.</li>
<li>Be sure to unzip it before trying to use files and such</li>
<li>The file contains the dataset used in class and an R script of all the code.</li>
<li>Once you have it where you want open the R script and be sure to check the working directory <code>getwd()</code> and make sure it is where your folder is.<br />
</li>
<li>If your working directory is not correct, you can set it in Rstudio: “Session –&gt; Set Working Directory –&gt; To source file location”. Or you can use the <code>setwd()</code> in the console.</li>
</ul>
</div>
<div id="objectives" class="section level3">
<h3>Objectives</h3>
<ol style="list-style-type: decimal">
<li>Understand the difference between predicting and evaluating effects</li>
<li>Understand prediction and quantifying uncertainty</li>
<li>Parameters of linear models</li>
</ol>
</div>
</div>
<div id="prediction-versus-effect" class="section level2">
<h2>Prediction versus effect</h2>
<p>Decisions require some prediction of an outcome and there is uncertainty surrounding the potential outcome. In order to make predictions we need some sort of estimator. This can be as simple as a calculating the mean of some data that can be used to estimate the expected outcome. However we need to account for uncertainty in the expected outcome. This can be done by incorporating a statistical model that links the data to the expectation including uncertainty.</p>
<p>Let’s get a better idea of what we mean here. Suppose we have 20 observations of weights for a critter. While we never know what the true mean and variance is, unless we perform a full census, we can easily simulate a known mean and standard deviation in R. Let’s assume that weights are normally distributed, for now.</p>
<pre class="r"><code>weight_mn&lt;- 145
weight_sd&lt;- 10
n&lt;- 150 # number of samples
weights&lt;- rnorm(n,weight_mn,weight_sd)
weights # lets look at the weights</code></pre>
<pre><code>##   [1] 146.8534 140.8239 156.9790 137.9831 146.5624 159.4970 148.9718
##   [8] 144.6731 132.8170 129.4111 144.5396 139.3867 141.0547 134.5978
##  [15] 144.2618 124.5617 145.2259 146.3573 149.7917 164.4086 149.8080
##  [22] 153.9405 148.5945 128.1777 131.0202 142.5441 128.1211 143.9570
##  [29] 149.2118 139.7285 129.2927 145.4583 125.2565 152.9082 139.2794
##  [36] 140.4336 158.7335 122.3629 131.2571 146.2125 148.0184 144.4371
##  [43] 153.3248 141.5338 161.2394 131.7189 150.4894 144.5961 136.2260
##  [50] 146.3887 121.6687 141.9772 139.0761 137.4558 137.0890 150.9400
##  [57] 149.0710 149.5173 153.9419 131.4547 139.3586 132.8737 141.8171
##  [64] 149.4819 151.1753 157.0645 139.6318 138.7533 139.0923 157.4696
##  [71] 142.2221 116.8562 138.9960 140.7563 148.2737 151.1528 149.3848
##  [78] 132.1028 135.9035 142.8178 145.0717 151.1759 158.9637 131.8393
##  [85] 143.4099 147.5105 140.9223 149.1656 138.3462 139.8819 147.7014
##  [92] 149.3229 151.0863 138.4032 147.0305 131.7070 145.1965 146.4015
##  [99] 159.0815 137.2256 142.1400 143.8121 149.0388 152.9342 158.5867
## [106] 149.2300 170.1684 140.4124 167.7040 142.7311 132.3707 140.7432
## [113] 140.2773 141.4627 150.7655 141.8342 131.6895 135.9873 140.8156
## [120] 137.7832 154.0448 128.6677 133.2663 154.0743 142.4447 135.8630
## [127] 130.0791 129.0127 152.6961 153.1464 143.1231 150.6809 146.7592
## [134] 146.8015 127.0836 141.1929 145.7246 133.1955 140.2890 146.7682
## [141] 154.8844 154.1466 144.7281 144.1029 141.3937 152.3769 148.9090
## [148] 147.3706 133.0492 142.0881</code></pre>
<p>Now we can look at the distribution of weights.</p>
<pre class="r"><code>hist(weights)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Cool, that looks normal, it should, we generated it from a normal distribution. Using those 15 observations of weight we can estimate the mean as <span class="math inline">\(\mu = \frac{1}{n}\cdot\sum_{i=1}^n Weight_i\)</span>.</p>
<p>The standard deviation is the square root of the average of the squared deviations from the mean and calculated as <span class="math inline">\(\sigma =\sqrt{\frac{1}{n} \cdot\sum_{i=1}^n (Weight_i-\mu)^2}\)</span></p>
<p>Fortunately R has some built in functions to calculate the mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>).</p>
<pre class="r"><code># the mean
mean(weights) # should be close to 145</code></pre>
<pre><code>## [1] 143.3886</code></pre>
<pre class="r"><code># the standard deviation
sd(weights) # should be close to 10</code></pre>
<pre><code>## [1] 9.286945</code></pre>
<p>Well this is great we can take several observations and calculate an expectation (<span class="math inline">\(\mu\)</span>) and the uncertainty (<span class="math inline">\(\sigma\)</span>). In most cases when we are doing science, we are interested in calculating the mean and seeing if it is different than another. But in decision making, we are more interested in estimating the expected value and the uncertainty. Arguably, we did just that by estimating the mean and the standard deviation using the formulas above. But that will only work for so long as problems get more complex.</p>
<p>Let’s reframe the mean estimate as a linear model. The linear model for a mean is</p>
<p><span class="math display">\[\mu = \beta_0\]</span></p>
<p>So in this case <span class="math inline">\(\beta_0\)</span> is the intercept of the linear model. To be clear this base linear model gives us the expected outcome. The model can be fit by ordinary least squares using the <code>lm()</code> function in R.</p>
<p>Let’s give that a shot.</p>
<pre class="r"><code>fit&lt;- lm(weights~1)

# THE SUMMARY OF THE LINEAR MODEL
# THE INTERCEPT IS VERY CLOSE TO THE MEAN WE CALCULATED PREVIOUS
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = weights ~ 1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -26.5324  -5.0282   0.2224   5.9110  26.7798 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 143.3886     0.7583   189.1   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.287 on 149 degrees of freedom</code></pre>
<p>Let’s confirm that the estimated mean is pretty darn close to the estimate of the the intercept. In order to accomplish this we need to extract the estimate of the intercept from the model output. The <code>lm()</code> function returns an object that is a list. Let’s confirm the output is a list.</p>
<pre class="r"><code>typeof(fit)</code></pre>
<pre><code>## [1] &quot;list&quot;</code></pre>
<p>Good, just as we thought it was a <code>list</code> object. Now the hassle is getting the estimate of the intercept out of the list. Why is this a hassle? Well lists are ragged, they can house vectors, data.frames, and matrices. So they are very flexible in their ability to store data, they can be a bit tricky to get data out of. In this case we need to get the coefficients estimated by the model. We can use the <code>names()</code> function to get a list of the named objects in <code>fit</code>.</p>
<pre class="r"><code>names(fit)</code></pre>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<p>There it is, I see an object named <code>coefficients</code>, let’s see if we can get it using the <code>$</code>.</p>
<pre class="r"><code># THE VECTOR OF COEFFICIENTS
fit$coefficients</code></pre>
<pre><code>## (Intercept) 
##    143.3886</code></pre>
<p>We can assign the coefficient as an object called <code>beta0</code>.</p>
<pre class="r"><code>beta0&lt;- fit$coefficients</code></pre>
<p>and we can see how different the mean and the intercept are.</p>
<pre class="r"><code>mean(weights)-beta0</code></pre>
<pre><code>##   (Intercept) 
## -2.842171e-14</code></pre>
<p>Well that is a very small number, well within rounding error.</p>
<p>So I have made the case that the linear model does the same thing as the mean equation. But in all the output I do not see any value for uncertainty? Let’s double check and make sure we didn’t miss it. We can look at the object itself or use <code>summary()</code> to have R spit out formatted output.</p>
<pre class="r"><code>fit</code></pre>
<pre><code>## 
## Call:
## lm(formula = weights ~ 1)
## 
## Coefficients:
## (Intercept)  
##       143.4</code></pre>
<pre class="r"><code>summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = weights ~ 1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -26.5324  -5.0282   0.2224   5.9110  26.7798 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 143.3886     0.7583   189.1   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.287 on 149 degrees of freedom</code></pre>
<p>Let’s check the list elements again using the <code>names()</code> function.</p>
<pre class="r"><code>names(fit)</code></pre>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<p>I don’t see anything, where the heck is the uncertainty? Well, it is hidden in the summary. To get at it, we need to create an object object of the model fit summary.</p>
<pre class="r"><code>output&lt;- summary(fit)
names(output)</code></pre>
<pre><code>##  [1] &quot;call&quot;          &quot;terms&quot;         &quot;residuals&quot;     &quot;coefficients&quot; 
##  [5] &quot;aliased&quot;       &quot;sigma&quot;         &quot;df&quot;            &quot;adj.r.squared&quot;
##  [9] &quot;r.squared&quot;     &quot;cov.unscaled&quot;</code></pre>
<p>Ohhh, there it is, I see an object named <code>sigma</code>. Let’s get a hold of that estimate. It should be close to 10, the value we generated from.</p>
<pre class="r"><code># SHOULD BE RIGHT ABOUT 10
output$sigma</code></pre>
<pre><code>## [1] 9.286945</code></pre>
<p>It was pretty close to the estimate of the standard deviation of the sample.</p>
<pre class="r"><code>sd(weights)-output$sigma</code></pre>
<pre><code>## [1] -1.776357e-15</code></pre>
<p>Again a very small number, well within rounding error.</p>
<p>Ok, now we have 2 things that we need, the expectation (i.e., <span class="math inline">\(\mu\)</span>) that was estimated by <span class="math inline">\(\beta_0\)</span> and the uncertainty (i.e., <span class="math inline">\(\sigma\)</span>).</p>
<p>There are 2 things I want to highlight here. 1) we have a model that generates an expected outcome and 2) we have quantified uncertainty in that outcome. Now, this can be formalized as the linear model below:</p>
<p><span class="math display">\[Y_i=\beta_0 + \epsilon_i \text{  (eq. 3)} \]</span></p>
<p>where * <span class="math inline">\(Y_i\)</span> are the observed values * <span class="math inline">\(\beta_0\)</span> is the mean value, and * <span class="math inline">\(\epsilon\)</span> is a normally distributed value with mean 0 and standard deviation of <span class="math inline">\(\sigma\)</span>.</p>
<p>This is likely the model you were taught in biometry or statistics. A different way to think about the linear model to to first think of it as a predictive model as:</p>
<p><span class="math display">\[\mu = \beta_0 \text{  (eq. 4)}\]</span></p>
<p>and then link the prediction to data using a statistical model to account for uncertainty as:</p>
<p><span class="math display">\[Y_i \sim Normal(\mu,\sigma). \text{ (eq. 5)}\]</span>.</p>
<p>Notice that equation 4 and 5 are linked by the prediction <span class="math inline">\(\mu\)</span> and the statistical model links the data to the expectation incorporating uncertainty.</p>
<p>Don’t quite believe me? Let’s do a quick simulation to see if we generate data from the 2 different approaches they are in fact that same.</p>
<p>First let’s generate some data using equation 3 where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are as defined above. We are going to do this for many observations as it will approximate the exact solution. So, for this demonstration we will generate 500,000 observations from each approach and compare them.</p>
<pre class="r"><code>n&lt;- 500000
weights_sim1&lt;- weight_mn + rnorm(n,0,weight_sd)
mean(weights_sim1)</code></pre>
<pre><code>## [1] 145.0048</code></pre>
<pre class="r"><code>sd(weights_sim1)</code></pre>
<pre><code>## [1] 10.01375</code></pre>
<p>Now let’s try the second approach.</p>
<pre class="r"><code>weights_sim2&lt;- rnorm(n,weight_mn,weight_sd)
mean(weights_sim2)</code></pre>
<pre><code>## [1] 144.9935</code></pre>
<pre class="r"><code>sd(weights_sim2)</code></pre>
<pre><code>## [1] 10.01165</code></pre>
<p>Both approaches return estimates of the mean and standard deviation that are very close to the <em>true</em> value of 145 and 10. And both distributions look the same, illustrated below using the <code>hist()</code> function.</p>
<pre class="r"><code>hist(weights_sim1)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre class="r"><code>hist(weights_sim2)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-19-2.png" width="672" /></p>
<p>Thinking about predictions from models and using data to estimate parameters and uncertainty makes a bit more sense using the second approach (i.e., eq. 4 and 5), especially in a decision context and when we start to deal with distributions that are not normally distributed (e.g., binomial, Poisson).</p>
</div>
<div id="furthering-linear-models" class="section level2">
<h2>Furthering linear models</h2>
<p>Linear models are the basis for many ecological analyses that can be used to predict outcomes and used in decision models. We are still working on values that are assumed to be normally distributed but we will soon see how linear model are the basis for generalized linear models. Up to now we have used the linear model to predict the most likely outcome for a sample weights (i.e., the mean) and the uncertainty around the outcome. Rarely are problems this easy, typically we have to include some other factors that we believe help reduce uncertainty. See, that was subtle right? The idea of explanation versus the idea of reducing uncertainty. That gets at the different mindset between explanation (science) and prediction (decision making).</p>
<p>Let’s work with a more concrete example. Suppose there is an invasive critter (e.g., hogs, carp) that damages habitat. Folks have gone out and quantified the amount of habitat area destroyed and related the amount destroyed to the abundance of invasive critters. But we also know that the size of the habitat area effects the area destroyed. Specifically, the critter will destroy larger habitats if there is more habitat but also with increasing critter abundance. In Netica this relationship of habitat area and abundance on area destroyed looks like this.</p>
<p><img src="media/cl09-netica.png" width="95%" /></p>
<p>Some stakeholders were nice enough to share data they had been collecting to quantify damage.</p>
<p>Let’s read in the data they provided and take a gander at it. We can read in a comma separated file (*.csv) using the <code>read.csv()</code> function.</p>
<pre class="r"><code># THIS WILL READ IN THE CSV FILE FROM YOUR WORKING
# DIRECTORY 
damage_dat&lt;- read.csv(&quot;damage-data.csv&quot;) 
damage_dat</code></pre>
<pre><code>##    habitat_area group_size area_damaged
## 1           106         12         20.5
## 2           134         35         45.9
## 3           143         31         46.2
## 4            40         49         25.5
## 5            61         43         15.4
## 6            72         35         16.0
## 7            42          6         -1.9
## 8            72         41         17.1
## 9            49         15          4.1
## 10           65         33         15.1
## 11           57         43         23.0
## 12           82          4          6.1
## 13          124         25         31.2
## 14           95          6         21.3
## 15          144         18         30.7
## 16          150         21         28.7
## 17           93         17         31.4
## 18           84          4          7.6
## 19           63         49         23.5
## 20          138         24         32.0
## 21          145         20         31.0
## 22          130         34         38.6
## 23           79         10         18.4
## 24           91         16         26.1
## 25          106         35         31.4
## 26          181          5         19.5
## 27           52         31         11.1
## 28           75         27         16.3
## 29           37         45          9.4
## 30          128          3         18.2
## 31          193         42         68.1
## 32          188         40         63.6
## 33          101         37         33.5
## 34          143         16         27.2
## 35           39         47         19.6
## 36          115         18         19.4
## 37          174         28         51.7
## 38           53         46         25.1
## 39          167         24         44.7
## 40           45          3         10.2
## 41          122         22         32.4
## 42          114          6         19.8
## 43          105         17         21.6
## 44           82         28         25.3
## 45          173         32         54.9
## 46           92         32         36.6
## 47           80          7          8.3
## 48           60         25         17.0
## 49           78         10          9.8
## 50          113         40         38.9
## 51           60         40         23.6
## 52           38         19         15.3
## 53          123         48         44.4
## 54          119         47         39.1
## 55           61         39         23.6
## 56          126          6         11.4</code></pre>
<p>Ok, we have 56 observations (rows) and 3 columns. The columns are <code>habitat_area</code>, <code>group_size</code>, and <code>area_damaged</code>. We can use R to plot the data and get a feel for what is going on. Let’s look at the relationship between the area damaged and the habitat area using the <code>plot()</code> function.</p>
<pre class="r"><code>plot(area_damaged~habitat_area, damage_dat)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Cool, we made a plot, print it and hang in on your fridge. Maybe a sweet valentines day gift? The <code>plot()</code> function takes a formula, in this case <code>area_damaged~habitat_area</code> and a <code>data.frame</code>, which we read in from a *.csv file and saved as the object <code>damage_dat</code>. The formula notation is convient is common throughout R where response values are to the left of the <code>~</code> and independent variables are to the right. But that plot looks like garbage. What is going on with the axs labels? I hate y-axis numbers that are not perpendicular to the x-axis. Let’s fix those.</p>
<pre class="r"><code>plot(area_damaged~habitat_area, damage_dat,
    xlab=&quot;Habitat area (ha)&quot;,
    ylab=&quot;Area damaged (ha)&quot;,
    las=1) # make y-axis labels perpendicular to x-axis</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Ok, that is better, there are many ways to customize <em>publication quality</em> figures in R. Note, this may make me a dinosaur but I prefer vanilla R graphics over the graphics produced by R packages like <code>ggplot</code>. Likely personal preference here but I have yet to see those type of figures published in mainstream ecology journals. The figure above looks pretty good, the relationship looks linear (i.e., a straight line with <code>habitat_area</code>.</p>
<p>Let’s check out the other variable we had <code>group_size</code>.We can modify the code above to get the plot of area damaged versus group size.</p>
<pre class="r"><code>plot(area_damaged~group_size, damage_dat,
    xlab=&quot;Group size (#)&quot;,
    ylab=&quot;Area damaged (ha)&quot;,
    las=1)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>Just for grins let’s see if we can see an interaction of group size and habitat area. This would suggest that as group size and area increases then the area damaged increases. One way to do this is to use our first plot where we plotted area damaged versus habitat area. We can then scale the points to be related to group size such that larger points represent damage by larger group sizes. Make sense?</p>
<p>We first thing we need to do is make a scale for our points. We can do this by scaling the group size using our proportional scoring equation.</p>
<pre class="r"><code>damage_dat$group_size_scl&lt;- (damage_dat$group_size-0)/(max(damage_dat$group_size)-0)</code></pre>
<p>I used a 0 in the equation above to preclude any 0 values for the scaled group sizes. We can now use these new values as the size of the points in the plot using the <code>cex</code> argument in plot.</p>
<pre class="r"><code>plot(area_damaged~habitat_area, damage_dat,
    xlab=&quot;Habitat area (ha)&quot;,
    ylab=&quot;Area damaged (ha)&quot;,
    las=1,
    cex=damage_dat$group_size_scl)# point sizes scaled to group size</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Boy those points are difficult to view. Let’s make them 2x as big.</p>
<pre class="r"><code>plot(area_damaged~habitat_area, damage_dat,
    xlab=&quot;Habitat area (ha)&quot;,
    ylab=&quot;Area damaged (ha)&quot;,
    las=1,
    cex=damage_dat$group_size_scl*2)# double the scale</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>That is better. Looks like some interaction is present. The larger points are on the top of the cloud of points. If they were randomly distributed throughout it would be suggestive of no interaction.</p>
<div id="predicting-area-damaged-from-a-linear-model" class="section level3">
<h3>Predicting area damaged from a linear model</h3>
<p>Recall from above where I made the case for thinking about models a bit differently than in equation 3. Suppose we want to fit a linear model to the data. the plot suggested there might be an interaction, so let’s go ahead and fit a model that includes the parameters:</p>
<ol style="list-style-type: decimal">
<li>Intercept ($_0}</li>
<li>Effect of habitat area (<span class="math inline">\(\beta_1\)</span>)</li>
<li>Effect of group size (<span class="math inline">\(\beta_2\)</span>)</li>
<li>Interaction of habitat area and group size (<span class="math inline">\(\beta_3\)</span>)</li>
</ol>
<p>The 4 parameters are put together as a linear model to predict the area damaaged as:</p>
<p><span class="math display">\[\mu = \beta_0 + 
    \beta_1 \cdot \text{Habitat area} +
    \beta_2 \cdot \text{Group size} +
    \beta_3 \cdot \text{Habitat area}\cdot\text{Group size. (Eq. 6)}\]</span></p>
<p>Ok, we have a model that will predict the amount of area damaged given habitat area, group size, and the interaction of the 2. Now we need to link the predictions to the observed data by a statistical model to quantify uncertainty. If we assume the observations are normally distributed around the prediction (i.e., normally distributed residuals) the statistical model is:</p>
<p><span class="math display">\[\text{Area damage}_i \sim Normal(\mu, \sigma) \text{  (Eq. 7)}\]</span></p>
<p>One of the assumptions to the linear model is that the predictor variables are not correlated. It is always go to check this and make sure. We can do this visually with a plot.</p>
<pre class="r"><code>plot(group_size~habitat_area, damage_dat,
    xlab=&quot;Habitat area (ha)&quot;,
    ylab=&quot;Group size (#)&quot;,
    las=1)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>That looks good. No clear pattern. R also has a nice built in function <code>pairs()</code> that evaluates a data.frame. Let’s try it out.</p>
<pre class="r"><code>pairs(damage_dat)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>We can fit that model using the <code>lm()</code> function again. This gets a bit more complicated because we have to specify the model unlike before where we just specified the intercept. Simlar to <code>plot()</code> we will use formula notation that has the syntax <code>Y ~ X1 + X2 + X1:X2</code>. The <code>X1:X2</code> use specifies the interaction we were looking at. Let’s give this thing a shot and fit the model.</p>
<pre class="r"><code>fit&lt;- lm(area_damaged~habitat_area+group_size+habitat_area:group_size,
    data=damage_dat)</code></pre>
<p>It is always good to look at the model diagnostics to make sure you are not violating assumptions before you peek at the results. Fortunately R has a nice built in diagnostic plot for linear models to evaluate assumptions. It spits out 4 plots: 1) residuals vs. fitted - should be centered around 0, 2) a Q-Q normal plot - should fall along a 1:1 line with some wiggle at the end, 3) a scale location plot - good for identifying outliers, and 4) a plot of the residuals vs. leverage - useful for identifying points that are overly influential on parameter estimates (i.e., outliers at the extremes).</p>
<pre class="r"><code>plot(fit)</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-32-1.png" width="672" /><img src="Class-09_files/figure-html/unnamed-chunk-32-2.png" width="672" /><img src="Class-09_files/figure-html/unnamed-chunk-32-3.png" width="672" /><img src="Class-09_files/figure-html/unnamed-chunk-32-4.png" width="672" /></p>
<p>I also like to look at a plot of observed vs. fitted to evaluate whether the model is linear - should be around a 1:1 line if it is. I can extract the fitted values using the <code>fitted()</code> function and add them to our <code>data.frame</code> damage_dat.</p>
<pre class="r"><code>damage_dat$fitted &lt;- fitted(fit)
plot(area_damaged~fitted,data=damage_dat)
abline(0,1)# add a 1:1 line for comparison</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>Well that looks legit, but not too legit to quit just yet. I also liek to look at a histogram of the residuals to see if they are normally distributed. But to do that we need to extract our residuals like we did before using the <code>fitted()</code> function but this time using the <code>resid()</code> function.</p>
<pre class="r"><code>damage_dat$resids &lt;- resid(fit)
hist(damage_dat$resids )</code></pre>
<p><img src="Class-09_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Looks good, centered around 0. We evaluated the assumptions of the linear model which were:</p>
<ol style="list-style-type: decimal">
<li>The response is linearly related to the model</li>
<li>Error had mean 0 and was normally distributed</li>
<li>The residuals were homoscedastic (constant variance, no fanning)</li>
<li>No autocorrelation</li>
</ol>
<p>Ok, now that all that is done, we can look at our results, get the model coefficients, and estimate of uncertainty.</p>
<pre class="r"><code>summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = area_damaged ~ habitat_area + group_size + habitat_area:group_size, 
##     data = damage_dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.3736 -3.9930 -0.1198  3.6223 12.0287 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             -0.134376   3.813019  -0.035  0.97202    
## habitat_area             0.108447   0.036689   2.956  0.00468 ** 
## group_size               0.022760   0.114263   0.199  0.84289    
## habitat_area:group_size  0.005714   0.001148   4.978 7.43e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.027 on 52 degrees of freedom
## Multiple R-squared:  0.8874, Adjusted R-squared:  0.8809 
## F-statistic: 136.6 on 3 and 52 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>betas&lt;- summary(fit)$coefficients
betas</code></pre>
<pre><code>##                             Estimate  Std. Error     t value     Pr(&gt;|t|)
## (Intercept)             -0.134376165 3.813019328 -0.03524141 9.720222e-01
## habitat_area             0.108446674 0.036688980  2.95583780 4.678269e-03
## group_size               0.022760150 0.114262567  0.19919165 8.428897e-01
## habitat_area:group_size  0.005713618 0.001147678  4.97841501 7.427185e-06</code></pre>
<pre class="r"><code>sigma&lt;- summary(fit)$sigma
sigma</code></pre>
<pre><code>## [1] 5.027126</code></pre>
<div id="putting-it-together" class="section level4">
<h4>Putting it together</h4>
<p>Using the values from above we have our predictive model:</p>
<p><span class="math display">\[\mu = -0.13 + 
    0.108 \cdot \text{Habitat area} +
    0.023 \cdot \text{Group size} +
    0.0057 \cdot \text{Habitat area}\cdot\text{Group size. (Eq. 8).}\]</span></p>
<p>And we have our statistical model that links the predictions to the data and quantifies uncertainty.</p>
<p><span class="math display">\[\text{Area damage}_i \sim Normal(\mu, 5.027) \text{  (Eq. 9)}\]</span></p>
<p>The whole thing can be put into Netica where you can propagate the uncertainty in the decision making process!</p>
<p><img src="media/cl09-netica2.png" width="95%" /></p>
</div>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
