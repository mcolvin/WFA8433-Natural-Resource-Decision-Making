<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Course home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Course information
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Course home</a>
    </li>
    <li>
      <a href="syllabus.html">Course Syllabus</a>
    </li>
    <li>
      <a href="course-overview.html">Course Overview</a>
    </li>
    <li>
      <a href="final-project.html">About final project</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Classes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Class-01.html">Class 1: Introduction to decision making</a>
    </li>
    <li>
      <a href="Class-02.html">Class 2: The PrOACT Process</a>
    </li>
    <li>
      <a href="Class-03.html">Class 3: Uncertainty and decision making</a>
    </li>
    <li>
      <a href="Class-04.html">Class 4: Decision trees and nets</a>
    </li>
    <li>
      <a href="Class-05.html">Class 5: Intro to SDM and ARM</a>
    </li>
    <li>
      <a href="Class-06.html">Class 6: Structuring and quantifying objectives</a>
    </li>
    <li>
      <a href="Class-07.html">Class 7: Structuring objectives</a>
    </li>
    <li>
      <a href="Class-08.html">Class 8: Intro to R</a>
    </li>
    <li>
      <a href="Class-09.html">Class 9: Linear Models</a>
    </li>
    <li>
      <a href="Class-10.html">Class 10: LMs and GLMs</a>
    </li>
    <li>
      <a href="Class-11.html">Class 11: Prediction and GLMs</a>
    </li>
    <li>
      <a href="Class-12.html">Class 12: GLMs continued</a>
    </li>
    <li>
      <a href="Class-13.html">Class 13: Poissons</a>
    </li>
    <li>
      <a href="Class-14.html">Class 14: HLMs</a>
    </li>
    <li>
      <a href="Class-15.html">Class 15: HLMs and occupancy</a>
    </li>
    <li>
      <a href="Class-16.html">Class 16: Occupancy continued</a>
    </li>
    <li>
      <a href="Class-17.html">Class 17: Influence diagrams, Sensitivity analyses &amp; N-Mixtures</a>
    </li>
    <li>
      <a href="Class-18.html">Class 18: N-Mixtures &amp; Estimating abundance</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Assignments
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="hw-01.html">Homework 1</a>
    </li>
    <li>
      <a href="hw-02.html">Homework 2</a>
    </li>
    <li>
      <a href="hw-03.html">Homework 3</a>
    </li>
    <li>
      <a href="hw-04.html">Homework 4</a>
    </li>
    <li>
      <a href="hw-05.html">Homework 5</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Additional Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="R-tutorials.html">R tutorials</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<p><!--

library(knitr)
rmarkdown::render_site("Class-18.Rmd")# build website

source("_build.R")
build("Class-18",bld="PAGE",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

# PURL THIS SHIT & MOVE FILES TO DOCS
build("Class-18",bld="SCRIPT",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

source("_build.R");build("Class-18",bld="PAGE",docs=TRUE)# bld = PAGE,ENTIRE,SCRIPT

--></p>
<p><img src="media/banner-03.jpg" width="100%" /></p>
<div id="class-18-estimating-abundance-using-n-mixture-models" class="section level1 unnumbered">
<h1>Class 18: Estimating abundance using N-Mixture models</h1>
</div>
<div id="class-preliminaries" class="section level1">
<h1><span class="header-section-number">1</span> Class preliminaries</h1>
<ul>
<li>Supplemental background reading for next class(es):
<ul>
<li>Conroy and Peterson Chapter 6 and 7.</li>
<li>Powell and Gale Chapter 17.</li>
</ul></li>
<li>Assignment due: None</li>
<li>Class project:
<ul>
<li>Be developing your decision model</li>
<li>Final exam period-April 28th at 3pm.</li>
</ul></li>
<li>Link to class recording <a href="">YouTube</a></li>
<li>Today’s R script <a href="scripts/Class-18.R">Class-18.R</a></li>
</ul>
<div id="class-overview-objectives" class="section level2">
<h2><span class="header-section-number">1.1</span> Class overview &amp; objectives</h2>
<ol style="list-style-type: decimal">
<li>Estimating abundance using unmarked animals: <em>N</em>-Mixture models</li>
<li>Informing current abundance state</li>
</ol>
</div>
<div id="getting-ready-to-go" class="section level2">
<h2><span class="header-section-number">1.2</span> Getting ready to go</h2>
<ul>
<li>The R scipt for class can be found <a href="scripts/Class-18.R">here</a></li>
<li>Once you have the script where you want it it where you want open the R script and be sure to check the working directory <code>getwd()</code> and make sure it is where your folder is.</li>
<li>If your working directory is not correct, you can set it in Rstudio: “Session –&gt; Set Working Directory –&gt; To source file location”. Or you can use the <code>setwd()</code> in the console</li>
<li>The data used today can be downloaded here <a href="study-area.Rdata">Rdata</a></li>
<li>You will want to install the following packages</li>
</ul>
<pre class="r"><code>#install.packages(&quot;reshape2&quot;)
#install.packages(&quot;unmarked&quot;)
#install.packages(&quot;fields&quot;)</code></pre>
</div>
</div>
<div id="n-mixture-models" class="section level1">
<h1><span class="header-section-number">2</span> N-Mixture models</h1>
<div id="overview" class="section level2">
<h2><span class="header-section-number">2.1</span> Overview</h2>
<p>Traditionally metrics like catch per unit effort (CPUE) would be used for comparisons (i.e., is cpue higher in one habitat relative to another). Comparing CPUE requires many assumptions as it relates to catchability (<span class="math inline">\(q\)</span>), where Catch is <span class="math inline">\(C = q\cdot f \cdot abundance\)</span>. Recent advances in <em>N</em>-mixture models relaxes this assumption by estimating capture probability for each site. One thing to note is that capture probability and catchability are not the same thing. Caveats aside the <em>N</em>-mixture provides a method to estimate density, accounting for imperfect capture. The gist of the approach is to repeatedly sample a site. The number of critters captured is a function of the underlying density and capture probability. For example if there were 100 critters at a site and your gear had a capture probability of 0.8 and then you sampled that site 5 times, you would expect to capture approximately 80 critters each time. In reality the data might look like this: 81, 74, 85, 82, 70, this is essentially a capture history but with counts instead of 0s and 1s. Because there was temporal replicates one can estimated a capture probability.</p>
<p>Remember our rice and corn experiment? The underlying density of popcorn kernels per bag was 5.</p>
<pre class="r"><code>lambda&lt;- 5</code></pre>
<p>Now, if we feed that into the <code>rpois()</code> function we can simulate the number of popcorn kernels in each bag. Note this assumes that the number of popcorn kernels comes from a Poisson distribution.</p>
<pre class="r"><code>kernalsPerBag&lt;- rpois(6,lambda)</code></pre>
<p>Our true number number of kernels in bags 1 to 6 were 4, 5, 6, 4, 11,and 1 respectively. The were drawn from a Poisson distribution, <code>rpois()</code> to be exact. Then we counted the number of popcorn kernels we could see in each bad. This ends up being the same as saying we had 6 sites and visited each site 20 times, there are 21 folks in class but one was excused that day for field work. Putting the data together we can feed it into a matrix using the <code>matrix()</code> function.</p>
<pre class="r"><code>ourData&lt;- matrix(c(0,1,0,1,2,0,
    3,2,3,2,2,0,
    2,3,4,4,4,1,
    2,3,1,1,4,1,
    1,4,3,1,5,1,
    1,2,5,1,5,0,
    2,2,3,3,6,0,
    2,4,1,4,5,0,
    0,1,5,0,5,0,
    2,1,1,1,2,0,
    2,2,1,2,6,0,
    2,2,1,2,2,1,
    3,3,3,2,6,1,
    0,1,0,2,2,0,
    2,1,2,0,2,0),ncol=6,nrow=15,byrow=TRUE)
ourData</code></pre>
<pre><code>##       [,1] [,2] [,3] [,4] [,5] [,6]
##  [1,]    0    1    0    1    2    0
##  [2,]    3    2    3    2    2    0
##  [3,]    2    3    4    4    4    1
##  [4,]    2    3    1    1    4    1
##  [5,]    1    4    3    1    5    1
##  [6,]    1    2    5    1    5    0
##  [7,]    2    2    3    3    6    0
##  [8,]    2    4    1    4    5    0
##  [9,]    0    1    5    0    5    0
## [10,]    2    1    1    1    2    0
## [11,]    2    2    1    2    6    0
## [12,]    2    2    1    2    2    1
## [13,]    3    3    3    2    6    1
## [14,]    0    1    0    2    2    0
## [15,]    2    1    2    0    2    0</code></pre>
<p>That does not quite look right, we need to have the sites as rows and visits as columns. The transpose function <code>t()</code> will fix that right up for us.</p>
<pre class="r"><code># TRANSPOSE THE DATA TO HAVE &#39;VISITS&#39; AS COLUMNS   
# AND SITES AS ROWS 
ourData&lt;-t(ourData) 
head(ourData)</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
## [1,]    0    3    2    2    1    1    2    2    0     2     2     2     3
## [2,]    1    2    3    3    4    2    2    4    1     1     2     2     3
## [3,]    0    3    4    1    3    5    3    1    5     1     1     1     3
## [4,]    1    2    4    1    1    1    3    4    0     1     2     2     2
## [5,]    2    2    4    4    5    5    6    5    5     2     6     2     6
## [6,]    0    0    1    1    1    0    0    0    0     0     0     1     1
##      [,14] [,15]
## [1,]     0     2
## [2,]     1     1
## [3,]     0     2
## [4,]     2     0
## [5,]     2     2
## [6,]     0     0</code></pre>
<p>Good that looks better. A naive abundance estimate might be to take the maximum of each row, assuming that somebody can count the number of popcorn kernels perfectly. Let’s try that.</p>
<pre class="r"><code>maxCounts&lt;- apply(ourData,1, max)
maxCounts</code></pre>
<pre><code>## [1] 3 4 5 4 6 1</code></pre>
<p>Now we can compare <code>maxCounts</code> to the true number.</p>
<pre class="r"><code>trueValues&lt;- c(4, 5, 6, 4, 11, 1)
plot(x=trueValues,y=maxCounts)
abline(0,1) # add a 1:1 line</code></pre>
<p><img src="Class-18_files/figure-html/unnamed-chunk-9-1.png" width="672" /> Well that is no good! We definitely underestimated the true density, which if you can think about it in terms of making a decision where the best decision depends on the number of critters out there, underestimating abundance or density can result in mismanagement and potentially wasting resources. Recall the state dependent decision we talked about in class 17? If you read the the literature a various blog posts about the concept of “statistical machismo” (see <a href="https://dynamicecology.wordpress.com/2012/09/11/statistical-machi%20smo/">here</a> arguing that detection probability is unimportant if you carefully control sampling to minimize bias. Well one unstated component to the debate is how we used estimates to make decisions and having unbiased estimates is important when you have state dependent decisions to make! This is the difference between estimating states and estimating effects.</p>
<p>As it relates to a study area, the <em>N</em>-mixture model may give the ability to estimate the density of hard to capture critters and the ability to compare among habitats. The design is not that different from what would occur for typical fishery or wildlife surveys, sample sites are randomly selected within an habitat and then repeated sampling is conducted to get the count history.</p>
</div>
<div id="application-to-estimating-abundance" class="section level2">
<h2><span class="header-section-number">2.2</span> Application to estimating abundance</h2>
<div id="the-study-area" class="section level3">
<h3><span class="header-section-number">2.2.1</span> The study area</h3>
<p>Suppose there is an area with a spatial domain, study area, that looks like the image below. The blue represents depth (darker = deeper).</p>
<pre class="r"><code>load(&quot;study-area.Rdata&quot;) # a study area
library(fields)
library(reshape2)
image.plot(x,y,z,xlim=c(0,7),
    xlab=&quot;X&quot;,ylab=&quot;Y&quot;,
    ylim=c(0,9), 
    col=rainbow(n=20,start=3/6,end=4/6),
    asp=1)  </code></pre>
<p><img src="Class-18_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Suppose that within the polygon above the true density of critters is 4 per square meter (i.e., <span class="math inline">\(\lambda = 4\)</span> in <em>N</em>-mixture jargon). Applying that density to the polygon, the one realization of the density of critters may look like the figure below. Recall we are using <code>rpois()</code> so this is one stochastic realization where each cells is a 1 by 1 meter square with no spatial correllation.</p>
<p><img src="Class-18_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Using the framework, a survey can sample sites within the habitat. Suppose 20 randomly selected sites were used. That would look like the image below.</p>
<p><img src="Class-18_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
</div>
<div id="estimating-abundance-from-unmarked-individuals" class="section level2">
<h2><span class="header-section-number">2.3</span> Estimating abundance from unmarked individuals</h2>
<p>Using the 20 samples, abundance can be estimated using an <em>N</em>-mixture model, given some assumptions. Variables estimated by the <em>N</em>-mixture model are:</p>
<ul>
<li><span class="math inline">\(\lambda\)</span> is population density</li>
<li><span class="math inline">\(p\)</span> is capture probability</li>
</ul>
<p>Specifically the process model is:</p>
<p><span class="math display">\[N_{i} \sim Poisson(\lambda)\]</span></p>
<p>and</p>
<p><span class="math display">\[y_{i,k}\sim binomial(N_{i},p)\]</span></p>
<p>and</p>
<p><span class="math display">\[log(\lambda) = \beta_0\]</span></p>
<p>and</p>
<p><span class="math display">\[logit(p) = \gamma_0\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(N_{i}\)</span> is the predicted count,<br />
</li>
<li><span class="math inline">\(\lambda\)</span> is the underlying density,<br />
</li>
<li><span class="math inline">\(y_{i,t}\)</span> is the number of critters observed at site <span class="math inline">\(i\)</span> at visit <span class="math inline">\(k\)</span>,<br />
</li>
<li><span class="math inline">\(p\)</span> is capture probability,<br />
</li>
<li><span class="math inline">\(i\)</span> indexes each randomly selected site,<br />
</li>
<li><span class="math inline">\(k\)</span> indexes each visit,<br />
</li>
<li><span class="math inline">\(\beta_0\)</span> is the intercept of the linear model predicting the log abundance, and<br />
</li>
<li><span class="math inline">\(\gamma_0\)</span> is the intercept of the linear model predicting the log odds of capture probability.</li>
</ul>
<p>The assumptions for the model above included:</p>
<ul>
<li>Counts are independent among site <span class="math inline">\(i\)</span> and visit <span class="math inline">\(k\)</span>,</li>
<li>Capture probability is homogenous, and</li>
<li><span class="math inline">\(N\)</span> is the true underlying count at site <span class="math inline">\(i\)</span></li>
<li>Population closed between surveys</li>
<li>Abundance of critters at each site remains the same</li>
</ul>
<div id="no-covariates-lambda-and-p-homogenous" class="section level3">
<h3><span class="header-section-number">2.3.1</span> No covariates: <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(p\)</span> homogenous</h3>
<p>The sampling design in the plot above illustrates how the design might play out in an IRC habitat. Each site would be visited 2 or more times either within a day or within a time period that is sufficiently short, such that demographic closure can be assumed. The process assumes temporal replicates, however spatial replicates have been used with occupancy models, so it is suggestive that it might work for <em>N</em>-mixture models. This first analysis assumes there is no underlying relationship with abiotic or biotic covariates such as depth on abundance or capture probability, i.e., density arises from a Poisson process.</p>
<p>The code below generates catches at 50 sites over 5 occasions given the abundance at the site and a capture probability <span class="math inline">\(p\)</span> = 0.4.</p>
<pre class="r"><code>nsamples&lt;- 50 # i = 1,2,3,...20
beta_0&lt;- 1.386 # UNDERLYING DENSITY
gamma_0&lt;- -0.405 # LOG ODDS CAPTURE PROBABILITY

# TRANSFORM TO REAL VALUES
lambda &lt;- exp(beta_0)# close to 4
lambda</code></pre>
<pre><code>## [1] 3.998823</code></pre>
<pre class="r"><code>p&lt;- exp(gamma_0)/(1+exp(gamma_0) )
p # close to 0.4</code></pre>
<pre><code>## [1] 0.4001116</code></pre>
<p>Now with <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(p\)</span> set we can simulate the Poisson process. Here we will assign an abundance of critters for each site in the study area.</p>
<pre class="r"><code># SIMULATE ABUNDANCES 
set.seed(1985)# FOR REPRODUCABILITY; LAST YEAR DLR WAS IN VAN HALEN
sa$N&lt;- rpois(nrow(sa),lambda)</code></pre>
<p>Hoo whee that was actually really easy! At this point you should be pretty fluent!</p>
<p>Now we can simulate the observation process. But first we need to select a few sites to sample, 20 to be specific.</p>
<pre class="r"><code>sample_indx&lt;- sample(1:nrow(sa),nsamples,replace=FALSE)
sampleSites&lt;- sa[sample_indx,]</code></pre>
<p>The observation process is essentially how many of the critters you will actually observe given how many are there. For this example we are using 5 visits. We can simulate this using a double for loop, double your pleasure, double the fun! The double for loop applies the <code>rbinom()</code> function for each site and each visit.</p>
<pre class="r"><code># GENERATE CAPTURE HISTORIES
visits&lt;-5 # k = 1,2,3,4,5
# MATRIX TO HOLD VALUES
y&lt;- matrix(0,nsamples,visits) # ROW FOR EAC SAMPLE SITE
for(i in 1:nsamples) # LOOP OVER EACH SAMPLE SITE
    {
    for(k in 1:visits)# LOOP OVER EACH VISIT AT EACH SITE
        {
        y[i,k]&lt;- rbinom(1,sampleSites$N[i],p)#obs count for visit k and site i
        }
    }</code></pre>
<p>The simulated counts at each of the 50 sites for 5 visits is shown below.</p>
<pre class="r"><code>head(y)</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    2    1    1    2    2
## [2,]    0    2    1    2    2
## [3,]    2    1    2    1    1
## [4,]    3    5    2    3    1
## [5,]    0    2    1    1    2
## [6,]    1    2    2    2    3</code></pre>
<p>The data in the table above is then used to estimate <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(p\)</span> using the <em>N</em>-mixture model. This is done using the <code>pcount()</code> function from the <code>unmarked</code> library. Note there was some manipulation of the data using the <code>unmarkedFramePCount()</code> function to process the input data prior to fitting the model.</p>
<pre class="r"><code># Prepare data
library(unmarked)
data &lt;- unmarkedFramePCount(y = y)

# ~DETECTION ~ ABUNDANCE
fit &lt;- pcount(~1 ~ 1, # P THEN LAMBDA
    data=data, 
    K=50) # SET THIS HIGHER THAN YOUR EXPECTED ABUNDANCE
summary(fit)</code></pre>
<pre><code>## 
## Call:
## pcount(formula = ~1 ~ 1, data = data, K = 50)
## 
## Abundance (log-scale):
##  Estimate   SE    z  P(&gt;|z|)
##      1.48 0.17 8.74 2.37e-18
## 
## Detection (logit-scale):
##  Estimate    SE     z P(&gt;|z|)
##      -0.6 0.249 -2.41   0.016
## 
## AIC: 737.2196 
## Number of sites: 50
## optim convergence code: 0
## optim iterations: 26 
## Bootstrap iterations: 0</code></pre>
<p>Once the model is fit and estimates are returned, the estimates are then back transformed from log and logit scale for abundance and capture probability respectively.</p>
<pre class="r"><code># Density
lambda</code></pre>
<pre><code>## [1] 3.998823</code></pre>
<pre class="r"><code># ESTIMATE IS ON LOG SCALE
exp(coef(fit)[1]) # should be close to lambda</code></pre>
<pre><code>## lam(Int) 
## 4.403315</code></pre>
<pre class="r"><code># Capture probability
p</code></pre>
<pre><code>## [1] 0.4001116</code></pre>
<pre class="r"><code># ESTIMATE IS ON LOG ODDS SCALE
exp(coef(fit)[2])/(1+exp(coef(fit)[2])) # should be close p</code></pre>
<pre><code>##    p(Int) 
## 0.3542789</code></pre>
<p>After fitting the <em>N</em>-mixture model the estimate of <span class="math inline">\(\lambda\)</span> was 4.4, recall that the value used to generate the data was 3.9988227 and the estimate of <span class="math inline">\(p\)</span> was 0.35, recall the that value used was 0.4001116. The estimates should be in the ballpark.</p>
<!--
need to clarify notation and notation within code
-->
</div>
<div id="covariates-for-lambda-and-p" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Covariates for <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(p\)</span></h3>
<p>The homogenous <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(p\)</span> is a rather unrealistic condition in nature. This example shows how a biologically relevant metric like depth can be used to model abundance and capture probability. Note that this example assumes there is a true underlying relationship with the abundance and capture probability of the critter and depth. Recall the figure above of the hypothesized study area with varying depths. Suppose abundance was inversely related to depth within and study area and that relationship is illustrated below. Formally we change the equation predicting <span class="math inline">\(\lambda\)</span> to</p>
<p><span class="math display">\[log(\lambda_i) = \beta_0 + \beta_1 \cdot Depth_i\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\lambda_i\)</span> is the underlying density at site <span class="math inline">\(i\)</span>,</li>
<li><span class="math inline">\(\beta_0\)</span> is the intercept of the linear model predicting the density,</li>
<li><span class="math inline">\(\beta_1\)</span> is the effect of depth on abundance, and</li>
<li><span class="math inline">\(i\)</span> indexes each site.</li>
</ul>
<p><img src="Class-18_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>The effect of depth on abundance within the study area is negative, indicating critter abundances are higher at lower depths. This underlying density relationship might look like the figure below where the expected density is</p>
<p><span class="math display">\[N \sim Poisson(exp(\beta_{0} + \beta_{1} \cdot depth))\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\beta_{0} =\)</span> 3, and</li>
<li><span class="math inline">\(\beta_{1} =\)</span> -0.5.</li>
</ul>
<p>The actual abundance for each site given the depth is simulated and illustrated below. This will simulate the Poisson process.</p>
<p>Cool, that was super easy. Let’s get a feel for the relationship.</p>
<pre class="r"><code>plot(N~depth,sa,ylab=&quot;Abundance&quot;,xlab=&quot;Depth&quot;,las=1)</code></pre>
<p><img src="Class-18_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Now we simulate the observation process for 40 sites this time. First we need to randomly select 40 sites.</p>
<pre class="r"><code>nsamples&lt;- 40
indx&lt;- sample(1:nrow(sa),nsamples)
sampleSites&lt;- sa[indx,]</code></pre>
<p>And now we can simulate the observation process given an effect of depth. Similarly, capture probability can be related to depth or some other environmental covariate. Suppose that capture probability was a function of depth, this might be the case when using a seine and it might be very difficult to sample the deep areas, just a hypothetical example here. This relationship might look like the figure below where the capture probability is</p>
<p><span class="math display">\[logit(p) = \gamma_{0} + \gamma_{1} \cdot depth\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\gamma_{0} =\)</span> 1, and</li>
<li><span class="math inline">\(\gamma_{1} =\)</span> 0.5.</li>
</ul>
<p>We can code this up as</p>
<p>Let’s get a feel for the relationship by plotting it.</p>
<p><img src="Class-18_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Using the relationship of <span class="math inline">\(p\)</span> and depth and the abundance at each site the capture histories can be generated accounting for site-specific depth and capture probability. Like we did before let’s simulate the process first.</p>
<pre class="r"><code># GENERATE CAPTURE HISTORIES
visits&lt;-5
p&lt;- exp(gamma_0+gamma_1*sampleSites$depth)/
    (1+exp(gamma_0+gamma_1*sampleSites$depth))
y&lt;- matrix(0,nsamples,visits)
for(i in 1:nsamples)
    {
    y[i,]&lt;- rbinom(visits,sampleSites$abundance[i],p[i])
    }</code></pre>
<p>The simulated catch at each of the 40 sites for 5 occasions is shown below, at least the first 6 rows.</p>
<pre><code>##      [,1] [,2] [,3] [,4] [,5]
## [1,]    2    0    0    1    2
## [2,]    3    3    0    1    4
## [3,]    3    4    3    1    0
## [4,]    4    3    5    4    4
## [5,]    1    2    2    2    4
## [6,]    3    4    2    3    2</code></pre>
<p>The model is fit as before, but with 4 estimates, 2 intercepts and 2 betas for the the relationship of depth on <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(p\)</span>.</p>
<pre class="r"><code># PREPARE DATA
data &lt;- unmarkedFramePCount(y = y,
    siteCovs=data.frame(depth=sampleSites$depth))
# FIT THE MODEL WITH DEPTH AS A COVARIATE FOR LAMBDA AND P
fit &lt;- pcount(~depth +1 ~depth+1, 
    data=data, 
    K=150)
fit</code></pre>
<pre><code>## 
## Call:
## pcount(formula = ~depth + 1 ~ depth + 1, data = data, K = 150)
## 
## Abundance:
##             Estimate    SE    z  P(&gt;|z|)
## (Intercept)    1.207 0.159 7.58 3.57e-14
## depth          0.126 0.116 1.09 2.77e-01
## 
## Detection:
##             Estimate    SE     z  P(&gt;|z|)
## (Intercept)    1.423 0.215  6.61 3.93e-11
## depth         -0.731 0.151 -4.84 1.27e-06
## 
## AIC: 586.2802</code></pre>
<p>After fitting the <em>N</em>-mixture model the estimate of <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> a was 1.21 and 0.13, recall that the value used to generate the data was 3 and -0.5 for the relationship of abundance with depth. The estimate of <span class="math inline">\(\gamma_{0}\)</span> and <span class="math inline">\(\gamma_{1}\)</span> for the function relating capture probability to depth was 1.42 and -0.73, recall the that value used was 1 and -0.5.</p>
<p>Ignoring uncertainties for the moment, we can estimate the total abundance given depth at each location in the study area as <span class="math inline">\(N = \sum_{i=1}^{I} exp(1.21 \cdot 0.13 \cdot depth_{i})\)</span>, where <span class="math inline">\(i\)</span> indexes each grid in the study area.</p>
<p>The image below illustrates the true abundances for a simulated study area and the estimated abundances.</p>
<p><img src="Class-18_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
</div>
<div id="estimating-total-abundance" class="section level2">
<h2><span class="header-section-number">2.4</span> Estimating total abundance</h2>
<p>Using the predictions the estimate of abundance in the study area is 2206 and the true abundance was 2134. There are design aspects where fine tuning can occur, such as modifying the number of replicates to take or how many sites to sample and where to put them.</p>
<p>We can use simulation to quantify some uncertainty around that estimate which is good to incorporate in a decision making process.</p>
<p>Let’s do it. We have already estimated the expected density for each site. Now if we generate many stochastic replicates we can sum over each site and plot the sums.</p>
<pre class="r"><code>n_reps&lt;- 10000
N_sim&lt;- matrix(0,nrow=nrow(sa),ncol=n_reps)

for(i in 1:n_reps)
    {
    N_sim[,i]&lt;- rpois(nrow(sa),
        lambda=sa$pred)
    
    }
    totalN&lt;- colSums(N_sim)
    hist(totalN) 
abline(v=sum(sa$N))   </code></pre>
<p><img src="Class-18_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>I suspect we are underestimating the uncertainty a bit here but arguably we are doing better that if we were trying in our head! Suppose we needed to figure out what size the population was, small (&lt;2000), medium (2000-2300), or large (&gt;2300) to make a better decision.</p>
<pre class="r"><code>brks&lt;-c(0,2000,2300,10000)#breakpoints
labs&lt;-c(&quot;Small (&lt;2000)&quot;,&quot;Medium (2000-2300)&quot;,
    &quot;Large (2300+)&quot;)

totalN_b&lt;-cut(x=totalN,
    breaks=brks,
    labels=labs,
    inlude.lowest=TRUE)
table(totalN_b)</code></pre>
<pre><code>## totalN_b
##      Small (&lt;2000) Medium (2000-2300)      Large (2300+) 
##                  0               9795                205</code></pre>
<pre class="r"><code>table(totalN_b)/n_reps</code></pre>
<pre><code>## totalN_b
##      Small (&lt;2000) Medium (2000-2300)      Large (2300+) 
##             0.0000             0.9795             0.0205</code></pre>
<p>That probabilities of the 3 states can be directly incorporated in a decision model.</p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
