<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Course home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Course information
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Course home</a>
    </li>
    <li>
      <a href="syllabus.html">Course Syllabus</a>
    </li>
    <li>
      <a href="course-overview.html">Course Overview</a>
    </li>
    <li>
      <a href="final-project.html">About final project</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Classes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Class-01.html">Class 1: Introduction to decision making</a>
    </li>
    <li>
      <a href="Class-02.html">Class 2: The PrOACT Process</a>
    </li>
    <li>
      <a href="Class-03.html">Class 3: Uncertainty and decision making</a>
    </li>
    <li>
      <a href="Class-04.html">Class 4: Decision trees and nets</a>
    </li>
    <li>
      <a href="Class-05.html">Class 5: Intro to SDM and ARM</a>
    </li>
    <li>
      <a href="Class-06.html">Class 6: Structuring and quantifying objectives</a>
    </li>
    <li>
      <a href="Class-07.html">Class 7: Structuring objectives</a>
    </li>
    <li>
      <a href="Class-08.html">Class 8: Intro to R</a>
    </li>
    <li>
      <a href="Class-09.html">Class 9: Linear Models</a>
    </li>
    <li>
      <a href="Class-10.html">Class 10: LMs and GLMs</a>
    </li>
    <li>
      <a href="Class-11.html">Class 11: Prediction and GLMs</a>
    </li>
    <li>
      <a href="Class-12.html">Class 12: GLMs continued</a>
    </li>
    <li>
      <a href="Class-13.html">Class 13: Poissons</a>
    </li>
    <li>
      <a href="Class-14.html">Class 14: HLMs</a>
    </li>
    <li>
      <a href="Class-15.html">Class 15: HLMs and occupancy</a>
    </li>
    <li>
      <a href="Class-16.html">Class 16: Occupancy continued</a>
    </li>
    <li>
      <a href="Class-17.html">Class 17: Influence diagrams, Sensitivity analyses &amp; N-Mixtures</a>
    </li>
    <li>
      <a href="Class-18.html">Class 18: N-Mixtures &amp; Estimating abundance</a>
    </li>
    <li>
      <a href="Class-19.html">Class 19: Population dynamics and decisions</a>
    </li>
    <li>
      <a href="Class-20.html">Class 20</a>
    </li>
    <li>
      <a href="Class-21.html">Class 21</a>
    </li>
    <li>
      <a href="Class-22.html">Class 22: ARM</a>
    </li>
    <li>
      <a href="Class-23.html">Class 23: ARM continued</a>
    </li>
    <li>
      <a href="Class-24.html">Class 24: Expert elicitation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Assignments
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="hw-01.html">Homework 1</a>
    </li>
    <li>
      <a href="hw-02.html">Homework 2</a>
    </li>
    <li>
      <a href="hw-03.html">Homework 3</a>
    </li>
    <li>
      <a href="hw-04.html">Homework 4</a>
    </li>
    <li>
      <a href="hw-05.html">Homework 5</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Additional Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="R-tutorials.html">R tutorials</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<p><!--


rmarkdown::render_site("Class-22.Rmd")# build website
library(knitr)
rmarkdown::render_site()# build website

source("_build.R")
build("Class-22",bld="PAGE",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

# PURL THIS SHIT & MOVE FILES TO DOCS
build("Class-22",bld="SCRIPT",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

source("_build.R");build("Class-22",bld="PAGE",docs=TRUE)# bld = PAGE,ENTIRE,SCRIPT

--></p>
<p><img src="media/banner-11.jpg" width="100%" /></p>
<div id="class-22-monitoring-information-and-arm-continued" class="section level1 unnumbered">
<h1>Class 22: Monitoring, Information, and ARM Continued</h1>
</div>
<div id="class-preliminaries" class="section level1">
<h1><span class="header-section-number">1</span> Class preliminaries</h1>
<ul>
<li>Supplemental background reading for next class(es): <!--
********** add some reading
--></li>
<li>Reading(s) for next time:
<ul>
<li>Conroy and Peterson Chapter 7</li>
<li>Conroy and Peterson Chapter 9</li>
</ul></li>
<li>Class project:
<ul>
<li>Be developing your decision model</li>
<li>Final exam period-April 28th at 3pm.</li>
</ul></li>
<li>Link to class recording <a href="">YouTube</a></li>
<li>Today’s R script <a href="scripts/Class-22.R">Class-22.R</a></li>
</ul>
<div id="class-overview-objectives" class="section level2">
<h2><span class="header-section-number">1.1</span> Class overview &amp; objectives</h2>
<p>The objectives of this class are to:</p>
<ol style="list-style-type: decimal">
<li>Further understanding of Bayes Theorem</li>
<li>Formally use monitoring to learn</li>
<li>Adapting decisions to learning in adaptive management</li>
</ol>
</div>
</div>
<div id="conditional-probability" class="section level1">
<h1><span class="header-section-number">2</span> Conditional probability</h1>
<p>The core of Bayesian inference and Bayes approaches to updating information is Bayes’ Theorem. To understand Bayes’ Theorem (BT) we first have to understand what a conditional probability is. A conditional probability (or distribution) is simply the probability of an event <span class="math inline">\(y\)</span> given that some other event <span class="math inline">\(x\)</span> occurs.</p>
<p>As a simple example, <span class="math inline">\(y\)</span> could be the event of drawing a spade from a deck and <span class="math inline">\(x\)</span> is the event of drawing a heart. Either of these events can occur by themselves with probability <span class="math inline">\(p(y=Spade)\)</span>, <span class="math inline">\(p(x=Heart)\)</span> respectively with <span class="math inline">\(p=1/4\)</span> each in this case.</p>
<pre class="r"><code>deck&lt;- expand.grid(
    suit = c(&quot;Diamond&quot;, &quot;Club&quot;, &quot;Heart&quot;, &quot;Spade&quot;),
    card = c(&quot;Ace&quot;, &quot;Deuce&quot;, &quot;Three&quot;, &quot;Four&quot;,&quot;Five&quot;, 
             &quot;Six&quot;, &quot;Seven&quot;, &quot;Eight&quot;, &quot;Nine&quot;, &quot;Ten&quot;, 
             &quot;Jack&quot;, &quot;Queen&quot;, &quot;King&quot;))
deck$id&lt;-1:nrow(deck) # for sampling later
ncards&lt;-nrow(deck)
prX&lt;- nrow(deck[deck$suit==&quot;Heart&quot;,])/ncards #p(x=Heart)
prY&lt;-  nrow(deck[deck$suit==&quot;Spade&quot;,])/ncards #p(x=Spade) </code></pre>
<p>Let’s confirm that the probability of drawing a Heart is in fact 0.25 and drawing a Spade is 0.25.</p>
<pre class="r"><code>prX</code></pre>
<pre><code>## [1] 0.25</code></pre>
<pre class="r"><code>prY</code></pre>
<pre><code>## [1] 0.25</code></pre>
<p>Good, these numbers jive.</p>
<p>Now what if we were curious what the probability of the drawing a Heart or a Spade? This is a joint probability and it specifies the probability of outcome <span class="math inline">\(y\)</span> or <span class="math inline">\(x\)</span> occurring. The rule for joint probabilities specifies that the probability of the events <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> jointly occurring is:</p>
<p><span class="math display">\[P(y \cap x) = p(y | x) p(x)\]</span></p>
<p>where <span class="math inline">\(p(y | x)\)</span> is the conditional probability of outcome <span class="math inline">\(y\)</span> given outcome <span class="math inline">\(x\)</span>. For example, <span class="math inline">\(p(y | x)\)</span> might be the probability of drawing a Spade if a Heart has already been drawn (and not replaced in the deck, in this case, <span class="math inline">\(P(y | x) = 13/51\)</span>. Thus, the joint probability of drawing a spade given a heart was drawn is</p>
<p><span class="math display">\[P(y \bigcap x) = p(y | x) p(x) = 0.064 = \frac{13}{51}\cdot \frac{1}{4}.\]</span></p>
<p>Let’s confirm this by simulation.</p>
<pre class="r"><code>reps&lt;-50000
indx&lt;-sample(nrow(deck),reps,replace=TRUE) # index for card selected
out&lt;-data.frame(firstCardSuit=deck[indx,]$suit)
prop.table(table(out)) # all close to 0.25</code></pre>
<pre><code>## out
## Diamond    Club   Heart   Spade 
## 0.25188 0.25120 0.24826 0.24866</code></pre>
<p>Now we need to simulate the second part of the process where we select a card given one card has been removed.</p>
<pre class="r"><code>out$secondCardSuite&lt;-NA
# SIMULATE THE PROCESS
for(i in 1:reps)
    {
    # SAMPLE ANOTHER CARD AND GET THE SUITE
    id&lt;- sample(deck$id[-indx[i]],1)
    out$secondCardSuit[i]&lt;- as.character(deck$suit[id])
    }</code></pre>
<pre class="r"><code>out$tmp&lt;-1
outcomes&lt;-aggregate(tmp~firstCardSuit+secondCardSuit,out,FUN=sum)
outcomes$p&lt;- outcomes$tmp/reps</code></pre>
<p>Let’s check and see if the probabilities for the first suit being a heart and the second being a Spade is close to 0.064.</p>
<pre class="r"><code>outcomes</code></pre>
<pre><code>##    firstCardSuit secondCardSuit  tmp       p
## 1        Diamond           Club 3206 0.06412
## 2           Club           Club 3007 0.06014
## 3          Heart           Club 3132 0.06264
## 4          Spade           Club 3094 0.06188
## 5        Diamond        Diamond 2997 0.05994
## 6           Club        Diamond 3157 0.06314
## 7          Heart        Diamond 3189 0.06378
## 8          Spade        Diamond 3122 0.06244
## 9        Diamond          Heart 3184 0.06368
## 10          Club          Heart 3268 0.06536
## 11         Heart          Heart 2876 0.05752
## 12         Spade          Heart 3230 0.06460
## 13       Diamond          Spade 3207 0.06414
## 14          Club          Spade 3128 0.06256
## 15         Heart          Spade 3216 0.06432
## 16         Spade          Spade 2987 0.05974</code></pre>
<p>Yes, they are pretty close, if you run for a large numbers of replicates they will converge to 0.064. The key to Bayes rule is that the conditioning can go either way, so</p>
<p><span class="math display">\[P(y \cap x) = p(y | x) p(x) = p(x | y) p(y)\]</span></p>
<p>Let’s confirm with simulation again. Here are the outcomes formally</p>
<p><span class="math display">\[P(y \cap x) = p(y=Spade | x =Heart) p(x = Heart) \]</span> and</p>
<p><span class="math display">\[P(y \cap x) = p(x = Heart | y=Spade) p(y=Spade)\]</span></p>
<pre class="r"><code>nrow(out[out$firstCardSuit==&quot;Heart&quot; &amp; out$secondCardSuit==&quot;Spade&quot;,])/reps</code></pre>
<pre><code>## [1] 0.06432</code></pre>
<pre class="r"><code>nrow(out[out$firstCardSuit==&quot;Spade&quot; &amp; out$secondCardSuit==&quot;Heart&quot;,])/reps</code></pre>
<pre><code>## [1] 0.0646</code></pre>
<p>The simulation shows this is true, within rounding error. is also true. BT follows by equating 2 expressions above</p>
<p><span class="math display">\[p(y | x ) p(x) = p(x | y) p(y)\]</span></p>
<p>Ok, so why are probabilities important? Good question, they are important because it is how we quantify our belief in something and the uncertainty in that belief. If we know something absolutely there is no uncertainty and the probability is 1. If we acknowledge our incomplete understanding, we need to put some value on our beliefs of how a system works and we have to have 2 or more explanations that are framed as hypotheses which in turn provide predictions that can be compared to monitoring.</p>
<p>BT forms a general relationship between conditional and unconditional probabilities, and has many useful applications. One very useful role for BT is in helping us to update knowledge (e.g., about a parameter value) from information (like sample data). So if we let <span class="math inline">\(\theta\)</span> stand for the value of a parameter for example and x stand for sample data, we can re-write BT as</p>
<p><span class="math display">\[p(\theta | x ) p(x) = p(x | \theta) p(\theta)\]</span></p>
<p>Viewed this way we have the following components:</p>
<ul>
<li><span class="math inline">\(p(\theta)\)</span> expresses knowledge (uncertainty) about the parameter in the absence of (before collecting) data, and is also known as the prior</li>
<li><span class="math inline">\(p(\theta | x )\)</span> expresses knowledge (uncertainty) about the parameter in the presence (after collecting) data, and is also known as the posterior.</li>
<li><span class="math inline">\(p(x | \theta)\)</span> expresses the probability or likelihood of having obtained the data result, given a particular value of the parameter, and</li>
<li><span class="math inline">\(p(x)\)</span> is the probability of the data (i.e., outcomes)</li>
</ul>
<p>Let’s put some sideboards on this flute music and see some application make some sense of it.</p>
<div id="application-of-bayesian-updating-to-model-weights" class="section level2">
<h2><span class="header-section-number">2.1</span> Application of Bayesian Updating to Model Weights</h2>
<p>Above our focus has been on using data to update information about uncertainty in a parameterâ€™s value. Another important application of BT is in updating our knowledge about which hypothesis or model is “true”, when, as often is the case, our predictions and management decisions have to be based on more than 1 model. Now let <span class="math inline">\(h_i\)</span> stand for the event “Hypothesis i is true”, while x still stands for the sample data, we can re-write BT as</p>
<p><span class="math display">\[p(H_i | x)\cdot p(x) = p(x | H_i)\cdot p(H_i)\]</span></p>
<p>The above quantities now have the following interpretations:</p>
<ul>
<li><span class="math inline">\(p(H_i)\)</span> expresses knowledge (uncertainty) about the truth of hypothesis i in the absence of (before collecting) data, and is also known as the prior probability that i H is true.</li>
<li><span class="math inline">\(p(x)\)</span> expresses the probability of the data,</li>
<li><span class="math inline">\(p(H_i | x)\)</span> expresses knowledge (uncertainty) about the truth of hypothesis i in the presence (after collecting) data, and is also known as the posterior probability that i H is true.</li>
<li><span class="math inline">\(p(x|H_i)\)</span> expresses the probability or likelihood of having obtained the data result, given that hypothesis i H is true.</li>
</ul>
<p>If we rearrange the equation above we get:</p>
<p><span class="math display">\[p(H_i | x) = \frac{p(x | H_i)\cdot p(H_i)}{p(x)}\]</span></p>
</div>
<div id="prediction-under-4-alternative-models-normal-likelihood-with-equal-and-known-variances" class="section level2">
<h2><span class="header-section-number">2.2</span> Prediction under 4 alternative models, Normal likelihood with equal and known variances</h2>
<p>To keep things simple for illustration, we will take a case in which it is quite easy to produce likelihood values under each model. Take a case where we are harvesting a population and predicting its response under 4 alternative models of harvest impact. Given an initial population size of 125, the models produce predictions for next yearâ€™s population of 100, 150, 125, and 135. We will start with equal belief in the 4 alternative models (1/4 each). We will assume a Normal likelihood and a fixed standard deviation of 10. Finally, next year comes and we observe that the population is 140.</p>
<p>First, we calculate the likelihood values under each models as</p>
<p><span class="math display">\[p(x|H_i) = Normal(140,\mu_i, 100)\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(p(x|H_i)\)</span> is the probability of observing 140 given hypothesis <span class="math inline">\(i\)</span>,</li>
<li><span class="math inline">\(\mu_i\)</span> is the predicted value under each model, and</li>
<li><span class="math inline">\(i\)</span> indexes each hypothesis.</li>
</ul>
<p>The <code>dnorm()</code> function returns this probability, for instance producing the likelihood for the third model.</p>
<pre class="r"><code>dnorm(140,125,10) #p(x|H_i), 3rd model</code></pre>
<pre><code>## [1] 0.01295176</code></pre>
<p>We can by replace 125 with the vector of predictions to get the likelihoods for all 4 models.</p>
<pre class="r"><code>dnorm(140,c(100,150,125,130),100)</code></pre>
<pre><code>## [1] 0.003682701 0.003969525 0.003944793 0.003969525</code></pre>
<p>Finally we use BT to put the model priors and likelihoods together:</p>
<pre class="r"><code>priors&lt;-rep(.25,4)# prior weights
observed&lt;-140
predicted&lt;-c(100,150,125,135)
sd&lt;-10
like&lt;-dnorm(observed,predicted,sd)  # p(x|Hi)
post&lt;-like*priors/sum(like*priors) # P(Hi): priors, p(x): sum(like*post)
summ&lt;-cbind(priors,predicted, like,post)
models&lt;-data.frame(priors=priors, pred=predicted,like=like,post=post)</code></pre>
<p>Let’s look at the summary table</p>
<pre class="r"><code>models</code></pre>
<pre><code>##   priors pred         like         post
## 1   0.25  100 1.338302e-05 0.0001849282
## 2   0.25  150 2.419707e-02 0.3343580373
## 3   0.25  125 1.295176e-02 0.1789689607
## 4   0.25  135 3.520653e-02 0.4864880737</code></pre>
<p>In this example, the posterior evidence quickly begins to favor model 4 over the other models; model 1 has practically no weight.</p>
<p>Let’s see what happens when SD is 100 and 25. First let’s assign the standard deviation in the summary table.</p>
<pre class="r"><code>models$sd&lt;- 10</code></pre>
<p>Now we set the standard deviation to something larger, 25, and repeat the process and calculate the posterior probabilities for each model.</p>
<pre class="r"><code>sd&lt;-25
like&lt;-dnorm(observed,predicted,sd)
post&lt;-like*priors/sum(like*priors)
summ&lt;-cbind(priors,predicted, like,post)
app&lt;-data.frame(priors=priors, pred=predicted,like=like,post=post,sd=sd)
models&lt;-rbind(models,app)</code></pre>
<p>Let’s try the same process with even more uncertainty, a standard deviation of 100.</p>
<pre class="r"><code>sd&lt;-100
like&lt;-dnorm(observed,predicted,sd)
post&lt;-like*priors/sum(like*priors)
summ&lt;-cbind(priors,predicted, like,post)
app&lt;-data.frame(priors=priors, pred=predicted,like=like,post=post,sd=sd)
models&lt;-rbind(models,app)</code></pre>
<p>Let’s take a look at the summary.</p>
<pre class="r"><code>models</code></pre>
<pre><code>##    priors pred         like         post  sd
## 1    0.25  100 1.338302e-05 0.0001849282  10
## 2    0.25  150 2.419707e-02 0.3343580373  10
## 3    0.25  125 1.295176e-02 0.1789689607  10
## 4    0.25  135 3.520653e-02 0.4864880737  10
## 5    0.25  100 4.436833e-03 0.0921684094  25
## 6    0.25  150 1.473081e-02 0.3060098957  25
## 7    0.25  125 1.332898e-02 0.2768892040  25
## 8    0.25  135 1.564171e-02 0.3249324909  25
## 9    0.25  100 3.682701e-03 0.2363515076 100
## 10   0.25  150 3.969525e-03 0.2547595441 100
## 11   0.25  125 3.944793e-03 0.2531722624 100
## 12   0.25  135 3.984439e-03 0.2557166859 100</code></pre>
<p>With a bit of modification we can visualize the difference in ‘learning’ associated with certainty in the prediction. A barplot will work well here. But to do a barplot, we need a matrix of values to plot.</p>
<pre class="r"><code>weights&lt;- matrix(models$post,
    ncol=4,nrow=3,
    dimnames=list(c(&quot;10&quot;,&quot;25&quot;,&quot;100&quot;),c(&quot;H1&quot;,&quot;H2&quot;,&quot;H3&quot;,&quot;H4&quot;)),
    byrow=TRUE)</code></pre>
<p>Now let’s plot the posterior probabilities using a barplot.</p>
<pre class="r"><code>barplot(weights,beside=TRUE,ylim=c(0,0.5),
    las=1,
    xlab=&quot;Hypothesis&quot;,
    ylab=&quot;Posterior probability&quot;,
    col=c(&quot;grey10&quot;,&quot;grey40&quot;,&quot;grey80&quot;))
legend(&quot;topleft&quot;,
    legend=c(&quot;SD=10&quot;,&quot;SD=25&quot;,&quot;SD=100&quot;),
    fill=c(&quot;grey10&quot;,&quot;grey40&quot;,&quot;grey80&quot;))
abline(h=0.25, col=&quot;red&quot;,lty=2)
text(x=0.75,y=0.265,
    labels=&quot;Prior probability&quot;,
    pos=4)
box()</code></pre>
<p><img src="Class-22_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>The rate of learning is very low when standard deviation is high! The posterior probabilities for each hypothesis have not deviated to far from the prior highlighted in the red dotted line when the standard deviation is high.</p>
<div id="iterating-over-time-to-learn" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Iterating over time to learn</h3>
<p>The process can repeat: if new data from a second survey year become available, we can again form likelihoods under the 4 models. But this time, the prior we should use is our current knowledgeâ€”which we just updated. So we would start with 0.25,0.25,0.25, and 0.25 as our priors and then apply BT with the new data.</p>
<p>Let’s maintain the above predictions and sd=100. Suppose in each of the next 5 years we have observe the following</p>
<ul>
<li>Year 1 = 140</li>
<li>Year 2 = 139</li>
<li>Year 3 = 143</li>
<li>Year 4 = 125</li>
<li>Year 5 = 138</li>
</ul>
<p>Let’s get started with the updating</p>
<pre class="r"><code>models&lt;-data.frame()
observed&lt;- 140
sd&lt;-100
like&lt;-dnorm(observed,predicted,sd)
priors&lt;-rep(.25,4)# prior weights
post&lt;-like*priors/sum(like*priors)
summ&lt;-cbind(priors,predicted, like,post)
app&lt;-data.frame(hypothesis=c(1:4),priors=priors, 
    pred=predicted,like=like,post=post,year=1)
models&lt;-rbind(models,app)</code></pre>
<p>Now let’s see the posteriors.</p>
<pre class="r"><code>models</code></pre>
<pre><code>##   hypothesis priors pred        like      post year
## 1          1   0.25  100 0.003682701 0.2363515    1
## 2          2   0.25  150 0.003969525 0.2547595    1
## 3          3   0.25  125 0.003944793 0.2531723    1
## 4          4   0.25  135 0.003984439 0.2557167    1</code></pre>
<p>And continue on with year 2 but using the posterior probabilities as the prior probabilities.</p>
<pre class="r"><code>observed&lt;- 139
sd&lt;-100
like&lt;-dnorm(observed,predicted,sd)
priors&lt;-post # make posterior for year 1 as priors for year 2
post&lt;-like*priors/sum(like*priors)
summ&lt;-cbind(priors,predicted, like,post)
app&lt;-data.frame(hypothesis=c(1:4),priors=priors, 
    pred=predicted,like=like,post=post,year=2)
models&lt;-rbind(models,app)</code></pre>
<p>And continue on with year 3 but using the posterior probabilities as the prior probabilities.</p>
<pre class="r"><code>observed&lt;- 143
sd&lt;-100
like&lt;-dnorm(observed,predicted,sd)
priors&lt;-post # make posterior for year 2 as priors for year 3
post&lt;-like*priors/sum(like*priors)
summ&lt;-cbind(priors,predicted, like,post)
app&lt;-data.frame(hypothesis=c(1:4),priors=priors, 
    pred=predicted,like=like,post=post,year=3)
models&lt;-rbind(models,app)</code></pre>
<p>And continue on with year 4 but using the posterior probabilities as the prior probabilities.</p>
<pre class="r"><code>observed&lt;- 125
sd&lt;-100
like&lt;-dnorm(observed,predicted,sd)
priors&lt;-post # make posterior for year 3 as priors for year 4
post&lt;-like*priors/sum(like*priors)
summ&lt;-cbind(priors,predicted, like,post)
app&lt;-data.frame(hypothesis=c(1:4),priors=priors, 
    pred=predicted,like=like,post=post,year=4)
models&lt;-rbind(models,app)</code></pre>
<p>And finally let’s finish up with year 5 but using the posterior probabilities as the prior probabilities.</p>
<pre class="r"><code>observed&lt;- 138
sd&lt;-100
like&lt;-dnorm(observed,predicted,sd)
priors&lt;-post # make posterior for year 4 as priors for year 5
post&lt;-like*priors/sum(like*priors)
summ&lt;-cbind(priors,predicted, like,post)
app&lt;-data.frame(hypothesis=c(1:4),priors=priors, 
    pred=predicted,like=like,post=post,year=5)
models&lt;-rbind(models,app)</code></pre>
<p>Let’s look at the mess we’ve put together.</p>
<pre class="r"><code>models</code></pre>
<pre><code>##    hypothesis    priors pred        like      post year
## 1           1 0.2500000  100 0.003682701 0.2363515    1
## 2           2 0.2500000  150 0.003969525 0.2547595    1
## 3           3 0.2500000  125 0.003944793 0.2531723    1
## 4           4 0.2500000  135 0.003984439 0.2557167    1
## 5           1 0.2363515  100 0.003697277 0.2238605    2
## 6           2 0.2547595  150 0.003965360 0.2587916    2
## 7           3 0.2531723  125 0.003950517 0.2562166    2
## 8           4 0.2557167  135 0.003986233 0.2611313    2
## 9           1 0.2238605  100 0.003637136 0.2094014    3
## 10          2 0.2587916  150 0.003979661 0.2648737    3
## 11          3 0.2562166  125 0.003925315 0.2586570    3
## 12          4 0.2611313  135 0.003976677 0.2670679    3
## 13          1 0.2094014  100 0.003866681 0.2062430    4
## 14          2 0.2648737  150 0.003866681 0.2608786    4
## 15          3 0.2586570  125 0.003989423 0.2628425    4
## 16          4 0.2670679  135 0.003969525 0.2700359    4
## 17          1 0.2062430  100 0.003711539 0.1955078    5
## 18          2 0.2608786  150 0.003960802 0.2639079    5
## 19          3 0.2628425  125 0.003955854 0.2655625    5
## 20          4 0.2700359  135 0.003987628 0.2750218    5</code></pre>
<p>It is nice to visualize the posterior probabilities to see what might be going on.</p>
<pre class="r"><code>plot(post~year,
    data=models,
    xlab=&quot;Year&quot;,
    ylab=&quot;Posterior probability&quot;,
    type=&#39;n&#39;)
points(post~year,
    data=models,
    subset=hypothesis==1,
    type=&#39;b&#39;,
    col=&quot;black&quot;)
 points(post~year,
    data=models,
    subset=hypothesis==2,
    type=&#39;b&#39;,
    col=&quot;red&quot;)   
points(post~year,
    data=models,
    subset=hypothesis==3,
    type=&#39;b&#39;,
    col=&quot;green&quot;)    
points(post~year,
    data=models,
    subset=hypothesis==4,
    type=&#39;b&#39;,
    col=&quot;blue&quot;)   
legend(&quot;bottomleft&quot;,
    legend=c(&quot;H1&quot;,&quot;H2&quot;,&quot;H3&quot;,&quot;H4&quot;),
    lty=1,
    pch=1,
    col=c(&quot;black&quot;,&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;))</code></pre>
<p><img src="Class-22_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Well, we are learning something… One of those hypotheses is not so good! Just imagine if you were using that hypothesis as your mental model and use it to make decisions, that could lead to problems.</p>
</div>
</div>
</div>
<div id="adaptive-resource-management" class="section level1">
<h1><span class="header-section-number">3</span> Adaptive resource management</h1>
<div id="calculating-posterior-probabilities-model-weights-using-monitoring-data" class="section level2">
<h2><span class="header-section-number">3.1</span> Calculating posterior probabilities (model weights) using monitoring data</h2>
<p>Let’s revisit the robust redhorse example from the previous class and build on using <code>r</code> to update model weights given monitoring results. the robust redhorse (<em>Moxostoma robustum</em>) that was believed extinct but was rediscovered in the Oconee River Georgia USA in 1991 by fishery biologists with the Georgia Department of Natural Resources (cite). Initially, there was scientific disagreement about the factors responsible for depressing robust redhorse populations. Some scientists believed that flathead catfish (<em>Pylodictis olivaris</em>), large non-native piscivore, were depressing redhorse populations through predation. Other scientists believed that redhorse were rare because upstream hydropower generation increased streamflow variability, negatively affecting the population. It follows then that the optimal decision for increasing redhorse populations differed based on what mechanism was responsible for the relative rarity of redhorse. If predation was responsible, then the best management alternative might be to control the nonnative catfish populations, whereas the best alternative would be to decrease power generation if the mechanism was flow variability. Here we have a large amount of uncertainty about the factors affecting redhorse populations and that uncertainty likely has a substantial effect on the optimal management decision. If decision-making was dynamic and sequential in time or space, this would be a good candidate for ARM.</p>
<p>Let’s assume that biologists developed two simple models for predicting redhorse abundance in response to two management actions:</p>
<ol style="list-style-type: decimal">
<li>decrease power generation and</li>
<li>control flathead catfish.</li>
</ol>
<p>The first model assumes that flow variability primarily controls redhorse populations. The model predicts that there will be 30 redhorse if power generation is decreased and 15 redhorse if flathead catfish are controlled. The second model assumes that redhorse populations are primarily controlled by flathead catfish. The model predicts that there will be 25 redhorse if flathead catfish are controlled and 15 redhorse if power generation is decreased. Notice that the estimated number of redhorse is greatest when the correct decision is matched with the corresponding system dynamics. This means that if decision-makers knew that flow variability was the mechanism, they would always choose to decrease power generation (i.e., the optimal decision, 30 redhorse) or if they knew that predation by flatheads was the mechanism, they would always choose to control flatheads (i.e., the optimal decision, 25 redhorse). However, decision-makers were unsure and the decision could not wait. Therefore, this structural uncertainty was incorporated using two models each with equal weight (0.5/0.5). The optimal decision then is identified by calculating the uncertainty weighted outcomes. For example, the expected number of redhorse for decreasing power generation is the top half of this decision tree: 0.5<em>30 + 0.5</em>15 = 22.5 and the controlling catfish is 0.5<em>15 + 0.5</em>25 = 20. The optimal decision alternative then is to decrease power generation. After implementing this alternative, 21 redhorse are counted during annual monitoring. Notice that this value is closer to the outcome estimated using the predation model. This suggests that there is greater evidence that predation is controlling the redhorse population. We use this evidence to update the model weights.</p>
<p>Predictions from flow modification models given the 2 management alternatives.</p>
<pre class="r"><code>est_flow_decreasePower &lt;- 30
est_flow_controlFlatheads &lt;- 15</code></pre>
<p>Predictions from the predation models given the 2 management alternatives.</p>
<pre class="r"><code>est_predation_decreasePower &lt;- 15
est_predation_controlFlatheads &lt;- 25</code></pre>
</div>
<div id="model-weights-and-decision-making" class="section level2">
<h2><span class="header-section-number">3.2</span> Model weights and decision making</h2>
<p>Initially we give model weights of 0.5 and 0.5 to the flow and the predation hypotheses. Recall these hypotheses are represented as models and therefore have associated predictions.</p>
<pre class="r"><code>Flow &lt;- 0.5 # PRIOR PROBABILITY FOR FLOW MODEL
Predation &lt;- 0.5 # PRIOR PROBABILITY FOR PREDATION MODEL</code></pre>
</div>
<div id="expected-values-given-model-uncertainty" class="section level2">
<h2><span class="header-section-number">3.3</span> Expected values given model uncertainty</h2>
<p>First thing we need to do is calculate the expected value given model uncertainty. We will use this value to figure out what the best management action will be. Let’s get the expected value if we decrease power generation.</p>
<pre class="r"><code>decreasePowerGeneration&lt;- Flow*est_flow_decreasePower + 
    Predation*est_predation_decreasePower</code></pre>
<p>And now let’s calculate the expected value, in numbers of redhorse, if we control flathead catfish.</p>
<pre class="r"><code>controlFlatheads &lt;- Flow*est_flow_controlFlatheads + 
    Predation*est_predation_controlFlatheads</code></pre>
<p>Here are the expected values.</p>
<pre class="r"><code>decreasePowerGeneration</code></pre>
<pre><code>## [1] 22.5</code></pre>
<pre class="r"><code>controlFlatheads</code></pre>
<pre><code>## [1] 20</code></pre>
<p>The optimal decision is to decrease power generation with an expected value of 22.5.</p>
<pre class="r"><code>decision&lt;-&quot;Decrease Power Generation&quot;</code></pre>
<p>Here is where the monitoring feedback comes into play. Specifically, the observed abundance after management action to control flathead catfish was 21 robust redhorse.</p>
<pre class="r"><code>obs&lt;- 21</code></pre>
<p>Now we need to calculate the probability of observing 21 robust redhorse given the model predictions. Because we have an abundance a Poisson distribution will be appropriate to figure out the likelihood of the prediction given the monitoring data. The <code>dpois()</code> function will provide the conditional likelihood.</p>
<pre class="r"><code>## conditional Likelihoods for Decrease power generation action
flow_like&lt;-dpois(obs,est_flow_decreasePower)
predation_like&lt;-dpois(obs,est_predation_decreasePower)</code></pre>
<p>The conditional probabilities are</p>
<pre class="r"><code>flow_like</code></pre>
<pre><code>## [1] 0.01915879</code></pre>
<pre class="r"><code>predation_like</code></pre>
<pre><code>## [1] 0.0298645</code></pre>
<p>for flow and predation model respectively, given the decision was to decrease power generation.</p>
<div id="calculating-posterior-probabilities" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Calculating posterior probabilities</h3>
<p>Now that we have the likelihoods for the outcome given the hypotheses and the decision we can update the model weights using BT. In this case we simply multiply the prior by the posterior and then sum the product of the prior and posterior for all the possible outcomes. We have 2 outcomes here.</p>
<pre class="r"><code>flow_post&lt;-flow_like*Flow/(flow_like*Flow + predation_like*Predation)
predation_post&lt;- predation_like*Predation/(flow_like*Flow + predation_like*Predation)
flow_wghts&lt;-flow_post
predation_weights&lt;- predation_post</code></pre>
<p>Now we can look at our new posteriors, recall they were 0.5 before.</p>
<pre class="r"><code>flow_post</code></pre>
<pre><code>## [1] 0.3908099</code></pre>
<pre class="r"><code>predation_post</code></pre>
<pre><code>## [1] 0.6091901</code></pre>
<div id="year-2" class="section level4">
<h4><span class="header-section-number">3.3.1.1</span> Year 2</h4>
<p>The posterior probabilities become the priors for the next time step which in turn influence the expected values of the decision.</p>
<pre class="r"><code>Flow &lt;- flow_post
Predation &lt;- predation_post</code></pre>
<p>And here is where we start to adapt our decisions to learning. We use the new prior probabilities, those that reflect learning, to calculate the expected values, which in turn allows us to make smarter decisions.</p>
<p>Here is the expected value of robust redhorse abundance if power generation is decreased.</p>
<pre class="r"><code>decreasePowerGeneration&lt;- Flow*est_flow_decreasePower + 
    Predation*est_predation_decreasePower</code></pre>
<p>Here is the expected value of robust redhorse abundance if flathead catfish are controlled.</p>
<pre class="r"><code>controlFlatheads &lt;- Flow*est_flow_controlFlatheads + 
    Predation*est_predation_controlFlatheads</code></pre>
<p>Below are the expected values (i.e., model predictions weighted by the prior probability of each model). The highest value ends up being the ‘best decision’.</p>
<pre class="r"><code>decreasePowerGeneration</code></pre>
<pre><code>## [1] 20.86215</code></pre>
<pre class="r"><code>controlFlatheads</code></pre>
<pre><code>## [1] 21.0919</code></pre>
<p>The optimal decision is to control flathead catfish with an expected value of 21.0919012.</p>
<pre class="r"><code>decision&lt;-c(decision , &quot;Control Flathead Catfish&quot;)</code></pre>
<p>So here we go again, after implementing the management action to control flathead catfish, 18 robust redhorse were observed.</p>
<pre class="r"><code>obs&lt;- 18</code></pre>
<p>Again here is the conditional probabilities for observing 18 robust redhorse given the predicted number of robust redhorse for the flathead control decision and flow variability and predation hypotheses.</p>
<pre class="r"><code>flow_like&lt;-dpois(obs,est_flow_controlFlatheads)
predation_like&lt;-dpois(obs,est_predation_controlFlatheads)</code></pre>
<p>We use our friend BT to calculate the posterior probability of the outcome given model predictions.</p>
<pre class="r"><code>flow_post&lt;-flow_like*Flow/(flow_like*Flow + predation_like*Predation)
predation_post&lt;- predation_like*Predation/(flow_like*Flow + predation_like*Predation)
flow_wghts&lt;-c(flow_wghts,flow_post) # keep track of to look at later
predation_weights&lt;- c(predation_weights,predation_post) # keep track of to look at later</code></pre>
<p>And we can see the new model weights.</p>
<pre class="r"><code># New model weights 
flow_post</code></pre>
<pre><code>## [1] 0.589338</code></pre>
<pre class="r"><code>predation_post</code></pre>
<pre><code>## [1] 0.410662</code></pre>
</div>
<div id="year-3" class="section level4">
<h4><span class="header-section-number">3.3.1.2</span> Year 3</h4>
<p>And now we can continue to iterate this process over time to make good management decisions given what learning has happened.</p>
<ol style="list-style-type: decimal">
<li>Set posterior probabilities as new prior probabilities</li>
</ol>
<pre class="r"><code>Flow &lt;- flow_post
Predation &lt;- predation_post</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Calculate expected values and select management action</li>
</ol>
<pre class="r"><code>decreasePowerGeneration&lt;- Flow*est_flow_decreasePower + 
    Predation*est_predation_decreasePower
controlFlatheads &lt;- Flow*est_flow_controlFlatheads + 
    Predation*est_predation_controlFlatheads
decreasePowerGeneration</code></pre>
<pre><code>## [1] 23.84007</code></pre>
<pre class="r"><code>controlFlatheads</code></pre>
<pre><code>## [1] 19.10662</code></pre>
<pre class="r"><code>decision&lt;- c(decision, &quot;Decrease Power Generation&quot;)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Set the observed outcome given the management action and update prior probabilities.</li>
</ol>
<pre class="r"><code>obs&lt;- 22
flow_like&lt;-dpois(obs,est_flow_decreasePower)
predation_like&lt;-dpois(obs,est_predation_decreasePower)
flow_post&lt;-flow_like*Flow/(flow_like*Flow + predation_like*Predation)
predation_post&lt;- predation_like*Predation/(flow_like*Flow + predation_like*Predation)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Keep track of weights over time to look at learning.</li>
</ol>
<pre class="r"><code>flow_wghts&lt;-c(flow_wghts,flow_post)
predation_weights&lt;- c(predation_weights,predation_post)</code></pre>
</div>
<div id="year-4" class="section level4">
<h4><span class="header-section-number">3.3.1.3</span> Year 4</h4>
<p>And now we can continue to iterate this process over time to make good management decisions given what learning has happened.</p>
<ol style="list-style-type: decimal">
<li>Set posterior probabilities as new prior probabilities</li>
</ol>
<pre class="r"><code>Flow &lt;- flow_post
Predation &lt;- predation_post</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Calculate expected values and select management action</li>
</ol>
<pre class="r"><code>decreasePowerGeneration&lt;- Flow*est_flow_decreasePower + 
    Predation*est_predation_decreasePower
controlFlatheads &lt;- Flow*est_flow_controlFlatheads + 
    Predation*est_predation_controlFlatheads
decreasePowerGeneration</code></pre>
<pre><code>## [1] 24.72071</code></pre>
<pre class="r"><code>controlFlatheads</code></pre>
<pre><code>## [1] 18.51953</code></pre>
<pre class="r"><code>decision&lt;- c(decision, &quot;Decrease Power Generation&quot;)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Set the observed outcome given the management action and update prior probabilities.</li>
</ol>
<pre class="r"><code>obs&lt;- 17
## conditional Likelihoods for Decrease.power.generation action
flow_like&lt;-dpois(obs,est_flow_decreasePower)
predation_like&lt;-dpois(obs,est_predation_decreasePower)
flow_post&lt;-flow_like*Flow/(flow_like*Flow + predation_like*Predation)
predation_post&lt;- predation_like*Predation/(flow_like*Flow + predation_like*Predation)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Keep track of weights over time to look at learning.</li>
</ol>
<pre class="r"><code>flow_wghts&lt;-c(flow_wghts,flow_post)
predation_weights&lt;- c(predation_weights,predation_post)</code></pre>
</div>
<div id="year-5" class="section level4">
<h4><span class="header-section-number">3.3.1.4</span> Year 5</h4>
<p>And now we can continue to iterate this process over time to make good management decisions given what learning has happened.</p>
<ol style="list-style-type: decimal">
<li>Set posterior probabilities as new prior probabilities</li>
</ol>
<pre class="r"><code>Flow &lt;- flow_post
Predation &lt;- predation_post</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Calculate expected values and select management action</li>
</ol>
<pre class="r"><code>decreasePowerGeneration&lt;- Flow*est_flow_decreasePower + 
    Predation*est_predation_decreasePower
controlFlatheads &lt;- Flow*est_flow_controlFlatheads + 
    Predation*est_predation_controlFlatheads
decreasePowerGeneration</code></pre>
<pre><code>## [1] 16.03127</code></pre>
<pre class="r"><code>controlFlatheads</code></pre>
<pre><code>## [1] 24.31249</code></pre>
<pre class="r"><code>decision&lt;- c(decision, &quot;Control Flathead Catfish&quot;)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Set the observed outcome given the management action and update prior probabilities.</li>
</ol>
<pre class="r"><code>obs&lt;- 15
## conditional Likelihoods
flow_like&lt;-dpois(obs,est_flow_controlFlatheads)
predation_like&lt;-dpois(obs,est_predation_controlFlatheads)
flow_post&lt;-flow_like*Flow/(flow_like*Flow + predation_like*Predation)
predation_post&lt;- predation_like*Predation/(flow_like*Flow + predation_like*Predation)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Keep track of weights over time to look at learning.</li>
</ol>
<pre class="r"><code>flow_wghts&lt;-c(flow_wghts,flow_post)
predation_weights&lt;- c(predation_weights,predation_post)</code></pre>
</div>
<div id="year-6" class="section level4">
<h4><span class="header-section-number">3.3.1.5</span> Year 6</h4>
<p>Now there nothing that says we need to do exactly what the expected values tell us. But as part of ARM we simply need to acknowledge the decision made and use the predictions from that model instead. So we continue as before.</p>
<ol style="list-style-type: decimal">
<li>Set posterior probabilities as new prior probabilities</li>
</ol>
<pre class="r"><code>Flow &lt;- flow_post
Predation &lt;- predation_post</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Calculate expected values and select management action</li>
</ol>
<pre class="r"><code>decreasePowerGeneration&lt;- Flow*est_flow_decreasePower + 
    Predation*est_predation_decreasePower
controlFlatheads &lt;- Flow*est_flow_controlFlatheads + 
    Predation*est_predation_controlFlatheads
decreasePowerGeneration</code></pre>
<pre><code>## [1] 21.49944</code></pre>
<pre class="r"><code>controlFlatheads</code></pre>
<pre><code>## [1] 20.66704</code></pre>
<pre class="r"><code>decision&lt;- c(decision, &quot;Control Flathead Catfish&quot;)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Set the observed outcome given the management action and update prior probabilities.</li>
</ol>
<pre class="r"><code>obs&lt;- 13
flow_like&lt;-dpois(obs,est_flow_controlFlatheads)
predation_like&lt;-dpois(obs,est_predation_controlFlatheads)
flow_post&lt;-flow_like*Flow/(flow_like*Flow + predation_like*Predation)
predation_post&lt;- predation_like*Predation/(flow_like*Flow + predation_like*Predation)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Keep track of weights over time to look at learning.</li>
</ol>
<pre class="r"><code>flow_wghts&lt;-c(flow_wghts,flow_post)
predation_weights&lt;- c(predation_weights,predation_post)</code></pre>
<p>The decisions changed, or were adaptive over time to learning. And by doing a management action we can learning about the response of the system.</p>
<pre class="r"><code>decision</code></pre>
<pre><code>## [1] &quot;Decrease Power Generation&quot; &quot;Control Flathead Catfish&quot; 
## [3] &quot;Decrease Power Generation&quot; &quot;Decrease Power Generation&quot;
## [5] &quot;Control Flathead Catfish&quot;  &quot;Control Flathead Catfish&quot;</code></pre>
<pre class="r"><code>flow_wghts</code></pre>
<pre><code>## [1] 0.39080988 0.58933804 0.64804745 0.06875132 0.43329631 0.95651382</code></pre>
<pre class="r"><code>predation_weights</code></pre>
<pre><code>## [1] 0.60919012 0.41066196 0.35195255 0.93124868 0.56670369 0.04348618</code></pre>
<p>Let’s look at any learning that might have occurred.</p>
<pre class="r"><code>plot(flow_wghts,
    xlab=&quot;Year&quot;,
    ylab=&quot;Probability&quot;,
    ylim=c(0,1),
    type=&#39;b&#39;,
    col=&#39;blue&#39;,
    las=1)
points(predation_weights,
    type=&#39;b&#39;,
    col=&#39;green&#39;)
legend(&quot;topleft&quot;, 
    legend=c(&quot;Flow variability&quot;,&quot;Predation&quot;),
    lty=1,
    col=c(&quot;blue&quot;,&quot;green&quot;),
    lwd=2)</code></pre>
<p><img src="Class-22_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>Lots of bouncing around in terms of evidence for the 2 hypotheses, might be time to reassess. Keep in mind that this process does not guarantee the perfect decision, there are things that happen that may result in less than ideal outcomes but this approach provides a way to identify when this happens and the flexibility to reassess and evaluate system understanding. But you will have a smart decision that is transparent and repeatable.</p>
<p>This process is viewed as what is called double loop learning, illustrated below. In double loop learning, the management objectives, decision alternatives, and models are reassessed and potentially revised to reflect changes in scientific knowledge and management objectives and alternatives. Learning in the outer loop occurs at a much slower rate and with slower frequency (e.g., every 10 years) compared to single loop learning. The updating we just did represents the single loop where management actions are implemented, monitoring is used to quantify outcomes, and BT is used to formalize learning by updating model weights which represent our beliefs in the hypotheses.</p>
<p><img src="media/class-22/loop-learning.png" width="100%" /></p>
<p>There is no general rule when to initiate the reassessment as it will vary from program to program and largely depends on the decision makers, stakeholders, and technical experts. For example, the US Fish and Wildlife Service conducts endangered species status assessments approximately every 5 years, so the reassessment of objectives, alternatives and models (i.e., the outer loop) may coincide with planned. However, decision-makers should try to minimize the frequency of the reassessments to allow for sufficient amount of time to accumulate information.</p>
</div>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
