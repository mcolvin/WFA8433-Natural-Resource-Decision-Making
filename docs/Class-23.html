<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>

<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Course home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Course information
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="index.html">Course home</a>
    </li>
    <li>
      <a href="syllabus.html">Course Syllabus</a>
    </li>
    <li>
      <a href="course-overview.html">Course Overview</a>
    </li>
    <li>
      <a href="final-project.html">About final project</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Classes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Class-01.html">Class 1: Introduction to decision making</a>
    </li>
    <li>
      <a href="Class-02.html">Class 2: The PrOACT Process</a>
    </li>
    <li>
      <a href="Class-03.html">Class 3: Uncertainty and decision making</a>
    </li>
    <li>
      <a href="Class-04.html">Class 4: Decision trees and nets</a>
    </li>
    <li>
      <a href="Class-05.html">Class 5: Intro to SDM and ARM</a>
    </li>
    <li>
      <a href="Class-06.html">Class 6: Structuring and quantifying objectives</a>
    </li>
    <li>
      <a href="Class-07.html">Class 7: Structuring objectives</a>
    </li>
    <li>
      <a href="Class-08.html">Class 8: Intro to R</a>
    </li>
    <li>
      <a href="Class-09.html">Class 9: Linear Models</a>
    </li>
    <li>
      <a href="Class-10.html">Class 10: LMs and GLMs</a>
    </li>
    <li>
      <a href="Class-11.html">Class 11: Prediction and GLMs</a>
    </li>
    <li>
      <a href="Class-12.html">Class 12: GLMs continued</a>
    </li>
    <li>
      <a href="Class-13.html">Class 13: Poissons</a>
    </li>
    <li>
      <a href="Class-14.html">Class 14: HLMs</a>
    </li>
    <li>
      <a href="Class-15.html">Class 15: HLMs and occupancy</a>
    </li>
    <li>
      <a href="Class-16.html">Class 16: Occupancy continued</a>
    </li>
    <li>
      <a href="Class-17.html">Class 17: Influence diagrams, Sensitivity analyses &amp; N-Mixtures</a>
    </li>
    <li>
      <a href="Class-18.html">Class 18: N-Mixtures &amp; Estimating abundance</a>
    </li>
    <li>
      <a href="Class-19.html">Class 19: Population dynamics and decisions</a>
    </li>
    <li>
      <a href="Class-20.html">Class 20</a>
    </li>
    <li>
      <a href="Class-21.html">Class 21</a>
    </li>
    <li>
      <a href="Class-22.html">Class 22</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Assignments
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="hw-01.html">Homework 1</a>
    </li>
    <li>
      <a href="hw-02.html">Homework 2</a>
    </li>
    <li>
      <a href="hw-03.html">Homework 3</a>
    </li>
    <li>
      <a href="hw-04.html">Homework 4</a>
    </li>
    <li>
      <a href="hw-05.html">Homework 5</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Additional Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="R-tutorials.html">R tutorials</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<p><!--


rmarkdown::render_site("Class-23.Rmd")# build website
library(knitr)
rmarkdown::render_site()# build website

source("_build.R")
build("Class-23",bld="PAGE",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

# PURL THIS SHIT & MOVE FILES TO DOCS
build("Class-23",bld="SCRIPT",docs=TRUE) # bld = PAGE,ENTIRE,SCRIPT

source("_build.R");build("Class-23",bld="PAGE",docs=TRUE)# bld = PAGE,ENTIRE,SCRIPT

--></p>
<p><img src="media/banner-10.jpg" width="100%" /></p>
<div id="class-23-adaptive-management-case-studies-and-expert-elicitation" class="section level1 unnumbered">
<h1>Class 23: Adaptive management case studies and expert elicitation</h1>
</div>
<div id="class-preliminaries" class="section level1">
<h1><span class="header-section-number">1</span> Class preliminaries</h1>
<ul>
<li>Supplemental background reading:
<ul>
<li>Marescot, L., G. Chapron, I. ChadÃ¨s, P. L. Fackler, C. Duchamp, E. Marboutin, and O. Gimenez. 2013. Complex decisions made simple: A primer on stochastic dynamic programming. Methods in Ecology and Evolution 4:872-884. <a href="pdfs/M292.pdf">PDF</a></li>
<li>Conroy, M. J., M. W. Miller, and J. E. Hines. 2002. Identification and Synthetic Modeling of Factors Affecting American Black Duck Populations. Wildlife Monographs:1-64. <a href="pdfs/C267.pdf">PDF</a></li>
<li>Anderson, D. R. 1975. Optimal Exploitation Strategies for an Animal Population in a Markovian Environment: A Theory and an Example. Ecology 56:1281-1297.<a href="pdfs/A192.pdf">PDF</a><br />
</li>
</ul></li>
<li>Reading(s) for next time:
<ul>
<li>Conroy and Peterson Chapter 6</li>
<li>Conroy and Peterson Chapter 9</li>
</ul></li>
<li>Class project presentation during final exam period-April 28th at 3pm.</li>
<li>Link to class recording <a href="">YouTube</a></li>
<li>Today’s R script <a href="scripts/Class-23.R">Class-23.R</a></li>
</ul>
<pre class="r"><code># install.packages(&quot;MDPtoolbox&quot;)
# install.packages(&quot;msm&quot;)
# install.packages(&quot;fitdistrplus&quot;)
# install.packages(&quot;Hmisc&quot;)</code></pre>
<div id="class-overview-objectives" class="section level2">
<h2><span class="header-section-number">1.1</span> Class overview &amp; objectives</h2>
<p>The objectives of this class are to:</p>
<ol style="list-style-type: decimal">
<li>Further understand of adaptive resource management</li>
<li>Provide background on the use of elicitation to parameterized decision models</li>
</ol>
</div>
</div>
<div id="management-and-monitoring." class="section level1">
<h1><span class="header-section-number">2</span> Management and monitoring.</h1>
<div id="overview" class="section level2">
<h2><span class="header-section-number">2.1</span> Overview</h2>
<div id="what-does-monitoring-provide-in-arm" class="section level3">
<h3><span class="header-section-number">2.1.1</span> What does monitoring provide in ARM</h3>
<p>In ARM, monitoring provides:</p>
<ol style="list-style-type: decimal">
<li>An estimate of the current state of the system before a decision is made (where we are). Remember that decisions are state dependent.</li>
<li>After a management alternative is implemented, monitoring provides information on what changes, if any, occurred to the system (where did we end up), and</li>
<li>Most importantly, the this also should provide information on the system dynamics that should reduce uncertainty and improve future decision making and returns (what did we learn).</li>
</ol>
</div>
<div id="monitoring-and-adaptive-resource-management" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Monitoring and Adaptive Resource Management</h3>
<p>It should be clear that monitoring and models are tightly linked in adaptive resource management in a formal process. The model weights are updated by comparing predictions to observed outcomes. For the process to work effectively and efficiently predicted and measured responses should be on the same unit scale and in the same units. For example, if models estimate population size then, monitoring should estimate the number of animals in the population rather than estimating some index of population size, such as relative abundance.</p>
<table>
<thead>
<tr class="header">
<th align="center">Model prediction</th>
<th align="center">Monitoring variable</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Population size</td>
<td align="center">Abundance</td>
</tr>
<tr class="even">
<td align="center">Species richness</td>
<td align="center">Number of species</td>
</tr>
<tr class="odd">
<td align="center">Species occupancy/distribution</td>
<td align="center">Number or proportion of areas occupied</td>
</tr>
<tr class="even">
<td align="center">Area burned</td>
<td align="center">Amount of area burned</td>
</tr>
</tbody>
</table>
<p>Decision makers also should take great care to avoid systematically biased measures, such as raw counts that are unadjusted for incomplete detection (e.g., population indices, catch-effort indices). Biased measures can provide misleading information that can lead to bad management decisions. Misleading information can have negative value.</p>
</div>
<div id="what-to-monitor" class="section level3">
<h3><span class="header-section-number">2.1.3</span> What to monitor?</h3>
<p><em>Monitoring other decision model components should include</em> * key drivers of outcomes * values needed to estimate expected outcome after decision * values useful for explaining unanticipated outcomes</p>
<p>Choosing what to monitoring as part of an adaptive resource management plan will vary from plan to plan and depends largely on the resources available to the decision maker (e.g., personnel, equipment, funds) and the sources and levels of uncertainty in the decision model. Of course, the most important components to monitor are the valued outcomes that are used to calculate the utility for example:</p>
<ul>
<li>population size,</li>
<li>distribution, or</li>
<li>harvest.</li>
</ul>
<p>These must be monitored. Monitoring other components of the decision model should focus on the key drivers of the of the outcomes that are identified during sensitivity analysis like</p>
<ul>
<li>habitat</li>
<li>availability,</li>
<li>annual temperature, and</li>
<li>precipitation.</li>
</ul>
<p>These data are needed to plug into the model to estimate the expected outcome after the decision and also can be useful for explaining unanticipated outcomes.</p>
</div>
<div id="single-and-double-loop-learning" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Single and double loop learning</h3>
<p><em>The ARM process is flexible and decision makers can use loop learning</em></p>
<ul>
<li>The single loop provides the iterations to make decisions</li>
<li>The double loop is the time to reassess and reevaluate</li>
<li>Caveat emptor: you need to be sure to stay in the single loop long enough to learn!</li>
</ul>
<p>We have described ARM as a special case of structured decision making that involves dynamic decision making, multiple models representing alternative hypotheses of system dynamics, and monitoring. Monitoring is used in an iterative process that provides feedback to reduce uncertainty about the dynamics of the system being modeled. This iterative process has been defined as single loop learning.</p>
<p>Single loop learning in the context of ARM begins after the initial structured decision making processes is completed. That is, objectives and decision alternatives have been identified and the alternative decision models built. Learning within the single loop occurs with respect to the given (fixed) set of objectives, alternatives, and models and learning occurs relatively frequently (e.g., annually).</p>
<p>Through time decision makers may find that their current set of models is inadequate or that management objectives or decision alternatives are insufficient and need to be changed.</p>
<p>In double loop learning, the management objectives, decision alternatives, and models are reassessed and potentially revised to reflect changes in scientific knowledge and management objectives and alternatives. Learning in the outer loop occurs at a much slower rate and with slower frequency (e.g., every 10 years) compared to single loop learning (e.g., every year).</p>
<p>There is no general rule when to initiate the reassessment as it will vary from program to program and largely depends on the decision makers, stakeholders, and technical experts. For example, the US Fish and Wildlife Service conducts endangered species status assessments approximately every 5 years, so the reassessment of objectives, alternatives and models (i.e., the outer loop) may coincide with planned. However, decision-makers should try to minimize the frequency of the reassessments to allow for sufficient amount of time to accumulate information.</p>
<p><img src="media/class-22/loop-learning.png" width="100%" /></p>
</div>
<div id="generalization-of-adaptive-resource-management" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Generalization of Adaptive Resource Management</h3>
<p>ARM is fairly flexible and can be modified to fit the decision situation.</p>
<ul>
<li>Decisions, monitoring, and feedback (i.e., updating weights) can occur at different intervals.
<ul>
<li>the decision to use controlled burns to manage vegetative structure may be revisited every 3 to 5 years but monitoring the vegetative structure can occur annually.</li>
</ul></li>
<li>Some decisions also may not be revisited as frequently as others due to slow system response or as a result of legislative mandates.
<ul>
<li>For example, the US Federal Energy Regulatory Commission licenses private, municipal, and state hydroelectric projects for periods that range from 20- 50 years. The licenses include conditions for which licensees must comply, such as dam operation restrictions designed to minimize impacts to fish and wildlife. Thus, dam operation decisions are revisited over long time intervals.</li>
</ul></li>
<li>In instances of long periods between decision…
<ul>
<li>It may be more efficient to incorporate spatial feedback where the decision is made on one project (e.g., a hydropower dam), monitoring is conducted and used to resolve uncertainty about system dynamics, and the updated beliefs used to identify the optimal decision at another location (e.g., another hydropower dam).</li>
<li>Sequential dynamic decision making in space, however, requires that the same set of decision alternatives are available to decision makers at each managed system. In addition, the systems should be sufficiently similar so that the same model set can be used to predict the outcomes of management actions.</li>
</ul></li>
</ul>
</div>
<div id="basic-forms-of-adaptive-resource-management" class="section level3">
<h3><span class="header-section-number">2.1.6</span> Basic Forms of Adaptive Resource Management</h3>
<p><strong>There are two basic forms of adaptive resource management:</strong></p>
<ol style="list-style-type: decimal">
<li>passive</li>
<li>active</li>
</ol>
<p>The ARM process is the same for both forms. Alternative models are used to identify the optimal decision and monitoring data are used to improve the understanding of system dynamics.</p>
<p><strong>Passive ARM</strong><br />
In passive ARM, decisions are chosen as if the current uncertainty about the system dynamics will not change. That is, the decision is chosen based long term gain in management objectives (utility) assuming the model weights will not change. Information gained through monitoring for passive ARM is incorporated, but not in a planned way.</p>
<p><strong>Active ARM</strong> Active ARM takes into account how reducing uncertainty can affect the long term gain. For example, a particular decision at a point in time may resolve key uncertainties quicker or more efficiently than the other decisions and resolution of the uncertainty will result in better decision making and greater long term gain in management objectives. Active ARM generally does not involve experimentation or probing of the system. Probing can, in fact, reduce the long term gain. Probing is only valued when uncertainty is very high and management loss is expected to be high if the uncertainty is not resolved. Taking into account learning to improve management is termed dual control.</p>
<table>
<colgroup>
<col width="39%" />
<col width="60%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Passive ARM</th>
<th align="center">Active ARM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Relatively simple</td>
<td align="center">Computationally more complex</td>
</tr>
<tr class="even">
<td align="center">Choose decisions as if current uncertainty will not change</td>
<td align="center">Potential information returned by each decision is given value when evaluating each decision</td>
</tr>
<tr class="odd">
<td align="center">Information gained through monitoring is incorporated, but not in a planned way</td>
<td align="center">“Probing” is valued when: 1) uncertainty is very high 2) management loss is expected,to be high if uncertainty is,unresolved</td>
</tr>
</tbody>
</table>
<p><strong>Policies under the 2 approaches can differ because passive does not anticipate learning.</strong></p>
</div>
<div id="arm-and-conflict-resolution" class="section level3">
<h3><span class="header-section-number">2.1.7</span> ARM and conflict resolution</h3>
<p>Adaptive resource management can be useful for resolving potential conflicts among stakeholders, provided the disagreement is about science. Especially if * stakeholders agree on objectives but * have different ideas about how the system works.</p>
<p>The differing ideas can be incorporated into the decision model as alternative models. Monitoring then can be used to resolve the uncertainty.</p>
<p>However, not all apparent disagreements on science are truly about the science or “your model versus my model.” Sometimes, scientific disagreement is used to mask disagreements over stakeholder objectives.</p>
<p><img src="media/class-23/conflict.png" width="50%" /></p>
<p>In these instances, ARM is not the appropriate tool, but the ARM process can be used to reveal these potential problems.</p>
</div>
<div id="myths-about-arm" class="section level3">
<h3><span class="header-section-number">2.1.8</span> Myths about ARM</h3>
<p><strong>There are some common misconceptions about ARM; chief among these is:</strong></p>
<ul>
<li>Itâ€™s research, no it is management
<ul>
<li>Adaptive Resource Management is first and foremost, management. All decisions are made to maximize management objectives. Learning occurs as a byproduct of management and it improves decision making thereby increasing the long term gain to managers.</li>
</ul></li>
<li>Itâ€™s too risky
<ul>
<li>All natural resource management decision making involves risk in one form or another (e.g., over harvesting a population vs. aggravating user groups) and uncertainty increases risk. ARM reduces uncertainty and risk.</li>
</ul></li>
<li>It distracts from management goals
<ul>
<li>ARM also does not distract from management goals because learning is focused at improving management.</li>
</ul></li>
<li>Itâ€™s too complicated and technical
<ul>
<li>Most agencies already incorporate most, if not all, of the components of ARM!
<ul>
<li>Decisions</li>
<li>Objectives</li>
<li>Models (implicit rather than explicit)</li>
<li>Monitoring</li>
</ul></li>
<li>What is needed: linking decisions to objectives with explicit model and targeted monitoring</li>
</ul></li>
</ul>
</div>
</div>
<div id="case-study-adaptive-harvest-management-for-american-black-ducks" class="section level2">
<h2><span class="header-section-number">2.2</span> Case study: Adaptive harvest management for American black ducks</h2>
<p>For more background see * Conroy and Peterson Chapter 9 * Anderson 1975 * Conroy, Nichols, and Hines</p>
<div id="black-ducks-have-issues" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Black ducks have issues</h3>
<ul>
<li>International resource</li>
<li>Populations have declined from historical levels but may be recovering</li>
<li>Controversy over causes of the decline and appropriate management
<ul>
<li>Harvest</li>
<li>Mallards</li>
</ul></li>
</ul>
</div>
<div id="reasons-for-black-duck-ahm" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Reasons for Black Duck AHM</h3>
<ul>
<li>Development a continental strategy for managing black duck harvest</li>
<li>Deal with (not resolve) issues of uncertainty in black duck dynamics
<ul>
<li>Mallards</li>
<li>Harvest</li>
</ul></li>
<li>Use predictive models and monitoring to:
<ul>
<li>Make optimal, or at least ‘good’, harvest decisions</li>
<li>Learn</li>
</ul></li>
</ul>
</div>
<div id="stakeholders-and-governance" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Stakeholders and governance</h3>
<ul>
<li>Stakeholders
<ol style="list-style-type: decimal">
<li>Black Duck Adaptive Harvest Management Working Group</li>
<li>Black Duck International Harvest Strategy Committee</li>
<li>Canadian Wildlife Service</li>
<li>U.S. Fish and Wildlife</li>
<li>US Geological Survey</li>
</ol></li>
<li>Governance Structure: Consensus decisions on
<ul>
<li>Objectives</li>
<li>Tech issues</li>
</ul></li>
</ul>
</div>
<div id="fundamental-objectives" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Fundamental Objectives</h3>
<p><strong>Maximum sustainable harvest</strong></p>
<ul>
<li>Constrained by
<ul>
<li>Population goals-penalty to harvest in N&lt;N*
<ul>
<li>Penalty applied to harvest if projected to fall below 500,000 ducks in spring surveys</li>
</ul></li>
<li>Parity goals-penalty to harvest if p&gt;p* (proportion of harvest in 1 country)
<ul>
<li>Assure that neither country gets disproportionate share of harvest</li>
<li>Penalty if US-Canada proportions of harvest outside range of 0.4 to 0.6</li>
<li>Penalty applied to harvest in country with harvest &gt; 0.6</li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="decision-situation" class="section level3">
<h3><span class="header-section-number">2.2.5</span> Decision situation</h3>
<ul>
<li>Decision context
<ul>
<li>Manage black ducks such as to maximize their harvest in the US and Canada</li>
</ul></li>
<li>Spatial dimensions
<ul>
<li>Eastern half of North America (below)</li>
</ul></li>
<li>Planning horizon
<ul>
<li>Decisions are made annually</li>
<li>evaluate dynamics over 100 year time period</li>
</ul></li>
<li>Decision alternative
<ul>
<li>Season length</li>
<li>bag limits</li>
</ul></li>
</ul>
<p><img src="media/class-23/ducks-01.png" width="75%" /></p>
</div>
<div id="structural-uncertainty" class="section level3">
<h3><span class="header-section-number">2.2.6</span> Structural uncertainty</h3>
<p><strong>Alternative models were used to represent hypotheses of reproduction and survival processes influencing population dynamics.</strong></p>
<ol style="list-style-type: decimal">
<li>Reproduction
<ol style="list-style-type: decimal">
<li>Competition effect from mallards</li>
<li>No competition effect</li>
</ol></li>
<li>Survival
<ol style="list-style-type: decimal">
<li>Density dependence (compensatory)</li>
<li>Density independence (additive)</li>
</ol></li>
</ol>
</div>
<div id="model-parameterization" class="section level3">
<h3><span class="header-section-number">2.2.7</span> Model parameterization</h3>
<p><strong>A combination of statistical and calibrated predictive models were used to predict outcomes of varying harvest rates.</strong></p>
<ol style="list-style-type: decimal">
<li>Fit of historical fall age ratio estimates
<ul>
<li>Generalized linear models</li>
<li>Black duck abundance, mallard abundance, and habitat as predictors</li>
</ul></li>
<li>Fit of historical non-harvest survival estimates</li>
</ol>
</div>
<div id="identifying-optimal-policy" class="section level3">
<h3><span class="header-section-number">2.2.8</span> Identifying optimal policy</h3>
<p>A process called stochastic dynamic programming was used to identify the optimal <strong>state dependent</strong> harvest policy illustrated below that maximizes harvest over a 100 year period.</p>
<p><img src="media/class-23/ducks-02-policies.png" width="100%" /></p>
</div>
<div id="under-the-hood-with-stochastic-dynamic-programming" class="section level3">
<h3><span class="header-section-number">2.2.9</span> Under the hood with stochastic dynamic programming</h3>
<p>Example from Conroy and Peterson 2013 Passive ARM SDP example in Appendix E</p>
<pre class="r"><code>## Stochastic dynamic programming requires this library
library(MDPtoolbox)</code></pre>
<pre><code>## Warning: package &#39;MDPtoolbox&#39; was built under R version 3.1.2</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Warning: package &#39;Matrix&#39; was built under R version 3.1.3</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     crossprod, tcrossprod</code></pre>
<pre><code>## Loading required package: linprog</code></pre>
<pre><code>## Warning: package &#39;linprog&#39; was built under R version 3.1.2</code></pre>
<pre><code>## Loading required package: lpSolve</code></pre>
<pre><code>## Warning: package &#39;lpSolve&#39; was built under R version 3.1.3</code></pre>
<pre class="r"><code>decisions&lt;- c(0.1,0.2,0.3)
abundance&lt;- c(5,10,15)
# With a decision specific transition matrices matrix
P &lt;- array(0, c(3,3,3))</code></pre>
<pre class="r"><code>#### weight of model 1
mod1.wt&lt;- 0.5</code></pre>
<pre class="r"><code>## decision 1 harvest = 0.1
Model1.1 &lt;- matrix(c(0.2, 0.5, 0.3, 0.2,.3,0.5,0.1,0.3,0.6), 3, 3, byrow=TRUE)
Model2.1 &lt;- matrix(c(0.3, 0.5, 0.2, 0.3,0.3,0.4,0.2,0.3,0.5), 3, 3, byrow=TRUE)
## model averaged transition matrix
P[,,1] &lt;- Model1.1*mod1.wt + Model2.1*(1-mod1.wt)</code></pre>
<pre class="r"><code>## decision 1 harvest = 0.2
Model1.2&lt;- matrix(c(0.5,0.3,0.2,0.2,0.5,0.3,0.2,0.4,0.4), 3, 3, byrow=TRUE)
Model2.2&lt;- matrix(c(0.7,0.3,0.0,0.4,0.5,0.1,0.5,0.4,0.1), 3, 3, byrow=TRUE)
P[,,2] &lt;-  Model1.2*mod1.wt + Model2.2*(1-mod1.wt)</code></pre>
<pre class="r"><code>## decision 1 harvest = 0.3
Model1.3&lt;- matrix(c(0.7,0.3,0.0,0.6,0.3,0.1,0.3,0.5,0.2), 3, 3, byrow=TRUE)
Model2.3&lt;- matrix(c(0.9,0.1,0.0,0.7,0.3,0.0,0.4,0.6,0.0), 3, 3, byrow=TRUE)
P[,,3] &lt;-  Model1.3*mod1.wt + Model2.3*(1-mod1.wt)</code></pre>
<p>Now if we make a reward matrix, the numbers harvested, we can use that to find the optimal policy.</p>
<pre class="r"><code>##Reward matrix
R &lt;- matrix(c(0.5,1.0,1.5,
    1,2,3,
    1.5,3.0,4.5), 
    nrow=3, 
    ncol=3, 
    byrow=TRUE)</code></pre>
<p>Without going into the details, although they can be found in Appendix E of Conroy and Peterson, the transitions and reward matrix can be iterated over to identify the policy that maximizes the reward over the long term. This allows us to move beyond the maximizing the utility in the next year to addressing sustainability. SDP is done in R using the <code>mdp_policy_iteration()</code> function from the <code>mdptoolbox</code> library. Let’s see how it works below.</p>
<pre class="r"><code>## heres the better way it automatically  iterates and stops when the policy is stable
out&lt;-mdp_policy_iteration(P=P, R=R, discount=.99999)</code></pre>
<p>The function returns the index of the optimal decision, so we can use that index to build a policy table.</p>
<pre class="r"><code>policyTable&lt;- data.frame(Abundance= abundance,
    HarvestRate=decisions[out$policy])</code></pre>
<p>Now that was a case where the transition matrices were already put together, but how do we make them? Let’s put this in context. This example is from Anderson’s 1975 duck model. In that model he proposed an additive and compensatory effect of harvest mortality on adult and juvenile survival. Let’s see how that works.</p>
<p>Here we will evaluate the optimal policy for duck abundances varying from 1 to 15 million assuming there are 2 million ponds on the landscape.</p>
<p>The decision here is the harvest rate which 5 levels are evaluated varying from 0 to 0.4.</p>
<p>The code below sets this up.</p>
<pre class="r"><code>N_t&lt;- c(1:15)
H_t&lt;- seq(0,0.4,by = 0.1)
combo&lt;-expand.grid(
    N_t=N_t,
    P_t=2,
    H_t=H_t,
    rep=1:5000)</code></pre>
<p>Now we start to produce the population dynamics. The equation below predicts the number of young production to be added to the fall population as a function of the number of ducs and ponds along with uncertainty.</p>
<pre class="r"><code>#  young production to be added to fall population (equation 2 (Anderson 1975))
combo$Y_t  = 1/((1/(12.48*combo$P_t^0.851))+
    (0.519/combo$N_t)) 
# add uncertainty
library(msm) </code></pre>
<pre><code>## Warning: package &#39;msm&#39; was built under R version 3.1.3</code></pre>
<pre class="r"><code>set.seed(8483)#for reproducability
combo$Y_t &lt;- rtnorm(length(combo$Y_t),
    combo$Y_t,
    combo$Y_t*0.3,
    lower = 1)</code></pre>
<p>Now we can calulate the fall population as a survival rate times the numbers of adults plus the number of young.</p>
<pre class="r"><code># Fall population at time t (equation 5 (Anderson 1975))
combo$F_t   = (0.92*combo$N_t) + combo$Y_t </code></pre>
<p>Now we can set up how many ducks were harvested given the harvest rate and the number of ducks. We will need to keep track of this number becuase it will be how we value different harvest rates.</p>
<pre class="r"><code># Harvest at time t (need to keep track of this)
combo$harvest&lt;-ifelse(combo$F_t &lt; combo$H_t*combo$F_t,
    combo$F_t, 
    combo$H_t*combo$F_t)</code></pre>
<p>Now we can see what the population size will be in the next year given 2 hypotheses of how harvest mortality interacts with natural mortality, in an additive or compensatory way.</p>
<p>The code below predicts survival assuming harvest mortality is additive and we can calculate what the population will be in the next year.</p>
<pre class="r"><code># AMH: ADDITIVE MORTALITY
combo$survival_adult_amh&lt;- (1-0.27*exp(2.08*combo$H_t))
combo$survival_young_amh&lt;- (1-0.40*exp(0.67*combo$H_t))
# Pop size after spring migration
# AMH: ADDITIVE MORTALITY
combo$N.t1.amh&lt;- combo$N_t*combo$survival_adult_amh + 
    combo$Y_t*combo$survival_young_amh</code></pre>
<p>We can do the same thing for the compensatory model.</p>
<pre class="r"><code># CMH: COMPENSATORY MORTALITY
combo$survival_adult_cmh&lt;- ifelse(combo$H_t&lt;0.25,
    0.57,
    (0.57-1.2*(combo$H_t-0.25)))
combo$survival_young_cmh&lt;-  ifelse(combo$H_t&lt;0.25,
    0.5,
    (0.5-1*(combo$H_t-0.25)))
# Pop size after spring migration
# CMH: COMPENSATORY MORTALITY
combo$N.t1.cmh&lt;- combo$N_t*combo$survival_adult_cmh + 
    combo$Y_t*combo$survival_young_cmh</code></pre>
<p>One of the quirks we have to deal with here is that new states can arise and that messes things up. Specifically, if we have 1 million ducks out there the future population might be less than 1 million ducks. The way we treat this is to simply make that outcome 1 million. We can also have the case when the population in the next year may be more than 15 millions. We simply round that outcome down to 15. And we also need to turn future abundance into a whole number, which the <code>floor()</code> function nicely accomplishes for us. We will see why this is important here in a sec.</p>
<pre class="r"><code># keep new states from arising
combo$N.t1.amh  &lt;- ifelse(combo$N.t1.amh&gt;15,
    15,
    combo$N.t1.amh)
combo$N.t1.amh  &lt;- floor(ifelse(combo$N.t1.amh&lt;1,
    1,
    combo$N.t1.amh))
combo$N.t1.cmh  &lt;- ifelse(combo$N.t1.cmh&gt;15,
    15,
    combo$N.t1.cmh)
combo$N.t1.cmh  &lt;- floor(ifelse(combo$N.t1.cmh&lt;1,
    1,
    combo$N.t1.cmh))</code></pre>
<p>Now that that nuisance is taken care of we can calculate the transition probabilities as a conditional probability matrix. This will be a 15 by 15 matrix if we do it right and it will have 4 matrices in the array. The table function will tally up the frequencies for us for each abundance state and harvest level.</p>
<pre class="r"><code>## create a table of transition frequencies that will be turned into 
## state transition probabilities one for each decision alternative
TM_amh&lt;- table(combo$N_t,combo$N.t1.amh,combo$H_t)
TM_cmh&lt;- table(combo$N_t,combo$N.t1.cmh,combo$H_t)</code></pre>
<p>We can use the <code>prop.table()</code> but we will use a special argument <code>margin=c(1,3)</code> which calculates the conditional probability for each row by each matrix.</p>
<pre class="r"><code># These are now transition matrices one for each  
# harvest decision alternative
TM_amh&lt;- prop.table(TM_amh,
    margin=c(1,3))
TM_cmh&lt;- prop.table(TM_cmh,
    margin=c(1,3))</code></pre>
<p>We now need to figure out the value, utility, or reward to maximize. In this case it is harvest and we simply need to figure out the probability for each harvest level given the harvest rate and intial population size. The <code>tapply()</code> function works well for this.</p>
<pre class="r"><code>## calculate the average (expected) return for each population
## state / decision alternative combination
harvest&lt;-tapply(X=combo$harvest,
    INDEX=list(combo$N_t,combo$H_t), 
    FUN=mean)</code></pre>
<p>And just like before we can combine the transition matrices into a single matrix by multiplying the values by the prior and summing the elements but we need to do it by each harvest level.</p>
<p>Assuming complete uncertainty we can assign a prior probability of 0.5 to the additive and 0.5 to the compensatory hypotheses.</p>
<pre class="r"><code>## Weight and add model specific population size estimates
prior_amh&lt;- 0.5
prior_cmh&lt;- (1-prior_amh)
TM&lt;- TM_amh*prior_amh + prior_cmh*TM_cmh</code></pre>
<p>Now we have transition matrices representing population dynamics given the varying harvest rates. And we have matrix of rewards. Now we can use SDP to identify the optimal harvest policy for each abundance state.</p>
<pre class="r"><code>### now find optimal state dependent harvest 
out&lt;- mdp_policy_iteration(P=TM, 
    R=harvest, 
    discount=.999,
    policy0=rep(4,15),
    max_iter=100)</code></pre>
<p>We can use the output to construct a policy table. This gives us the optimal harvest policy for each abundance state.</p>
<pre class="r"><code>policyTable&lt;- data.frame(Abundance= N_t,
    HarvestRate1=H_t[out$policy])
policyTable</code></pre>
<pre><code>##    Abundance HarvestRate1
## 1          1          0.0
## 2          2          0.0
## 3          3          0.1
## 4          4          0.2
## 5          5          0.2
## 6          6          0.2
## 7          7          0.2
## 8          8          0.2
## 9          9          0.2
## 10        10          0.2
## 11        11          0.3
## 12        12          0.3
## 13        13          0.3
## 14        14          0.3
## 15        15          0.3</code></pre>
<p>Now, suppose we did some monitoring and was able to update our prior probabilities for each hypotheses, we can simply rerun the SDP and see the changes in optimal harvest policy. In this case we there is more evidence for compensation then harvest rates should be higher after we learn this. Let’s see if that happens.</p>
<p>All we need to do is reweight the transition matrices to reflect this new knowledge.</p>
<pre class="r"><code>## Weight and add model specific population size estimates
prior_amh&lt;- 0.25
prior_cmh&lt;- (1-prior_amh)
TM&lt;- TM_amh*prior_amh + prior_cmh*TM_cmh</code></pre>
<p>And use that updated transition matrix in the policy iteration.</p>
<pre class="r"><code>### now find optimal state dependent harvest 
out&lt;- mdp_policy_iteration(P=TM, 
    R=harvest, 
    discount=.999,
    policy0=rep(4,15),
    max_iter=100)</code></pre>
<p>Now let’s add those new policies to the policy table and see if they adapted to the new information.</p>
<pre class="r"><code>policyTable$HarvestRate2&lt;- H_t[out$policy]
policyTable</code></pre>
<pre><code>##    Abundance HarvestRate1 HarvestRate2
## 1          1          0.0          0.0
## 2          2          0.0          0.0
## 3          3          0.1          0.2
## 4          4          0.2          0.2
## 5          5          0.2          0.2
## 6          6          0.2          0.2
## 7          7          0.2          0.2
## 8          8          0.2          0.2
## 9          9          0.2          0.3
## 10        10          0.2          0.3
## 11        11          0.3          0.3
## 12        12          0.3          0.3
## 13        13          0.3          0.3
## 14        14          0.3          0.3
## 15        15          0.3          0.3</code></pre>
</div>
<div id="monitoring" class="section level3">
<h3><span class="header-section-number">2.2.10</span> Monitoring</h3>
<ol style="list-style-type: decimal">
<li>Continent-wide surveys</li>
<li>Bird banding</li>
<li>Harvest reporting</li>
</ol>
<p><img src="media/class-23/ducks-03-monitoring-map.png" width="100%" /></p>
</div>
<div id="case-study-conclusions" class="section level3">
<h3><span class="header-section-number">2.2.11</span> Case study conclusions</h3>
<p>Current data and models sufficient to build a realistic AHM for black ducks. Objectives of black duck international harvest management can be addressed in an AHM context Monitoring programs sufficient for adaptation but rates of learning may be slow</p>
</div>
</div>
<div id="arm-summary" class="section level2">
<h2><span class="header-section-number">2.3</span> ARM Summary</h2>
<p>Adaptive resource management is a special case of structured decision making that is focused on</p>
<ol style="list-style-type: decimal">
<li>reducing uncertainty, and</li>
<li>improving decision making.</li>
</ol>
<p>ARM requires:</p>
<ul>
<li>Explicit prediction of the consequences of management actions using multiple models of system dynamics (i.e., hypotheses)</li>
<li>Sequential dynamic decisions in time and/or space, and</li>
<li>Feedback in the form of monitoring data.</li>
</ul>
<p>Monitoring plays a crucial role is ARM. It provides:</p>
<ul>
<li>An estimate of the current state of the system,</li>
<li>Information on system dynamics by comparing actual to predicted outcomes, and</li>
<li>Integration of information direct and increases the value of decisions</li>
</ul>
<!-- #######################################################-->
<!-- #######################################################-->
<!-- #######################################################-->
<!-- #######################################################-->
<!-- #######################################################-->
<!-- #######################################################-->
<!-- #######################################################-->
</div>
</div>
<div id="eliciting-and-quantifying-expert-judgment" class="section level1">
<h1><span class="header-section-number">3</span> Eliciting and quantifying expert judgment</h1>
<p>Expert information can be used to parameterize decision models. If you have not completed those lessons, please review them before taking this lesson. The use of expert judgment involves asking one or more experts that are familiar with the phenomenon being modeled (e.g., the effects of disease on wildlife populations) to parameterize the relationship between two or more model components. Eliciting useful expert information can be a difficult task and several approaches have been developed to help analysts elicit information. There are two approaches that are categorized by the means of elicitation: direct elicitation and indirect elicitation, and the type of measure provided by the experts: quantitative or qualitative. We will learn how to quantify expert judgment conduct the analysis using quantitative direct elicitation and indirect elicitation methods. Specifically, we will cover</p>
<ol style="list-style-type: decimal">
<li>Probability elicitation</li>
<li>Frequency elicitation</li>
<li>Value elicitation</li>
<li>Function elicitation</li>
</ol>
<div id="probability-elicitation" class="section level2">
<h2><span class="header-section-number">3.1</span> Probability elicitation</h2>
<p>Probability elicitation is a direct, quantitative method that requires experts that are familiar and comfortable with statistical concepts, such as probability. Typical type of question for probability elicitation is:</p>
<p>Given that the maximum summer water temperature is 33C or greater, what is the probability that an amphibian species will survive?</p>
<p>Suppose we asked 6 experts this question and received the following, values 0.5, 0.6, 0.45, 0.65, 0.45, 0.7. We could combine the values across experts by treating these values as data and calculating a mean. Uncertainty among experts can be estimated by calculating the variance.</p>
<pre class="r"><code>Surv&lt;- c(0.5, 0.6, 0.45, 0.65, 0.45, 0.7) 
s.mean&lt;-mean(Surv) 
s.var&lt;- var(Surv)</code></pre>
<p>Uncertainty in a probability can be modeled using a beta distribution. Thus, we could use the method of moments to estimate the parameters of the beta (a, b) from the mean and the standard deviation.</p>
<pre class="r"><code>### beta method of moments 
beta.mom&lt;-function(mean,v)
    { 
    x&lt;-mean 
    a&lt;-x*(x*(1-x)/v-1) 
    b&lt;-(1-x)*(x*(1-x)/v-1) 
    c(a,b) 
    } 
out&lt;-beta.mom(s.mean,s.var) 
out</code></pre>
<pre><code>## [1] 11.501531  9.098226</code></pre>
<p>We could also use maximum likelihood to estimate the 2 beta distribution parameters. We might as well use the method of moments estimates for to start the optimization!</p>
<pre class="r"><code>library(fitdistrplus) </code></pre>
<pre><code>## Warning: package &#39;fitdistrplus&#39; was built under R version 3.1.3</code></pre>
<pre class="r"><code>fit&lt;- fitdist(Surv,&quot;beta&quot;,
    start=c(shape1=out[1],
    shape2=out[2]))
fit</code></pre>
<pre><code>## Fitting of the distribution &#39; beta &#39; by maximum likelihood 
## Parameters:
##        estimate Std. Error
## shape1 14.25455   8.170572
## shape2 11.26283   6.425610</code></pre>
<p>Often one or more experts have greater experience than others and we have greater faith in the values they provide. Weights are represented using positive numbers with larger numbers representing greater weight. The absolute values of the weights do not matter. Rather it is the relative differences among the weights that are used to weight the values provided by the experts. For example, the weights 1,1,2,1,2,4 are equal to 0.091,0.091,0.182,0.091,0.182,0.364 because the relative proportions are equal. To demonstrate we can use the <code>wtd.mean()</code> and <code>wtd.var()</code> function to estimate the mean and the variance incorporating the expert weights.</p>
<pre class="r"><code>library(Hmisc)</code></pre>
<pre><code>## Warning: package &#39;Hmisc&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## Warning: package &#39;lattice&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: survival</code></pre>
<pre><code>## Warning: package &#39;survival&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: Formula</code></pre>
<pre><code>## Warning: package &#39;Formula&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.1.3</code></pre>
<pre><code>## Stackoverflow is a great place to get help:
## http://stackoverflow.com/tags/ggplot2.</code></pre>
<pre><code>## 
## Attaching package: &#39;Hmisc&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     format.pval, round.POSIXt, trunc.POSIXt, units</code></pre>
<pre class="r"><code># weights as whole numbers 
wt1&lt;-c(1,1,2,1,2,4) 
# weights as proportions 
wt2&lt;- wt1/sum(wt1) 
#means 
wtd.mean(Surv,wt1) </code></pre>
<pre><code>## [1] 0.5772727</code></pre>
<pre class="r"><code>wtd.mean(Surv,wt2) </code></pre>
<pre><code>## [1] 0.5772727</code></pre>
<pre class="r"><code>#variance 
wtd.var(Surv,wt1) </code></pre>
<pre><code>## [1] 0.01368182</code></pre>
<pre class="r"><code>wtd.var(Surv,wt2) </code></pre>
<pre><code>## [1] Inf</code></pre>
<pre class="r"><code>out_w&lt;-beta.mom(mean=wtd.mean(Surv,wt1),
    v=wtd.var(Surv,wt2)) 
out_w</code></pre>
<pre><code>## [1] -0.5772727 -0.4227273</code></pre>
<p>Here we calculate weighted and unweighted means and variances of these probability values provided by experts. Using those values we then calculate the parameters of a beta distribution using either method of movements or maximum likelihood.</p>
<p>We can visualize the effect by plotting the probability density for the beta distribution estimated from the unweighted and weighted mean and variance. Lets take a look.</p>
<pre class="r"><code>S&lt;- seq(0,1,0.01)
unweighted&lt;-dbeta(S, 
    shape1=out[1], 
    shape2=out[2])
plot(S,unweighted,
    col=&quot;black&quot;,
    type=&#39;l&#39;, 
    ylab=&quot;Density&quot;, 
    lwd=2, 
    ylim=c(0,6),
    las=1)
weighted&lt;-dbeta(S, 
    shape1=out_w[1], 
    shape2= out_w[2])</code></pre>
<pre><code>## Warning in dbeta(S, shape1 = out_w[1], shape2 = out_w[2]): NaNs produced</code></pre>
<pre class="r"><code>points(S,weighted,
    col=&quot;red&quot;,
    type=&#39;l&#39;, 
    lwd=2)
legend(&quot;topleft&quot;, 
    legend=c(&quot;unweighted&quot;, &quot;weighted&quot;), 
    lty=1, 
    col=c(&quot;black&quot;,&quot;red&quot;))</code></pre>
<p><img src="Class-23_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>Weighting the experts’ estimates moved the location to be closer to 0.6 and increased the uncertainty (spread) around the location.</p>
<p><strong>Things to consider here are that the use of expert information and weighted can be good, but it can also be bad… It may be possible to ‘game’ the system if an expert or experts are given an undue amount of weight. So it might be prudent to run analysis/simulations both ways to assess whether the effect of weighting has a dramatic effect on the decision.</strong></p>
<div id="conditional-probability-tables" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Conditional probability tables</h3>
<p>In some instances, you will need to ask experts to fill out conditional probability tables that are used in influence diagrams and combine values across experts. For example, suppose that we asked 3 experts to fill out the following tables for estimating species status:</p>
<table>
<thead>
<tr class="header">
<th>Expert</th>
<th>Snag density</th>
<th>Forest canopy</th>
<th>Absent</th>
<th>Rare</th>
<th>Abundant</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>expert 1</td>
<td>Many</td>
<td>Open</td>
<td>0.36</td>
<td>0.36</td>
<td>0.29</td>
</tr>
<tr class="even">
<td></td>
<td>Many</td>
<td>Closed</td>
<td>0.15</td>
<td>0.35</td>
<td>0.5</td>
</tr>
<tr class="odd">
<td></td>
<td>Few</td>
<td>Open</td>
<td>0.67</td>
<td>0.25</td>
<td>0.08</td>
</tr>
<tr class="even">
<td></td>
<td>Few</td>
<td>Closed</td>
<td>0.44</td>
<td>0.38</td>
<td>0.19</td>
</tr>
<tr class="odd">
<td>expert2</td>
<td>Many</td>
<td>Open</td>
<td>0.37</td>
<td>0.45</td>
<td>0.18</td>
</tr>
<tr class="even">
<td></td>
<td>Many</td>
<td>Closed</td>
<td>0.17</td>
<td>0.41</td>
<td>0.41</td>
</tr>
<tr class="odd">
<td></td>
<td>Few</td>
<td>Open</td>
<td>0.69</td>
<td>0.28</td>
<td>0.03</td>
</tr>
<tr class="even">
<td></td>
<td>Few</td>
<td>Closed</td>
<td>0.51</td>
<td>0.47</td>
<td>0.01</td>
</tr>
<tr class="odd">
<td>expert3</td>
<td>Many</td>
<td>Open</td>
<td>0.36</td>
<td>0.38</td>
<td>0.26</td>
</tr>
<tr class="even">
<td></td>
<td>Many</td>
<td>Closed</td>
<td>0.17</td>
<td>0.43</td>
<td>0.41</td>
</tr>
<tr class="odd">
<td></td>
<td>Few</td>
<td>Open</td>
<td>0.66</td>
<td>0.3</td>
<td>0.03</td>
</tr>
<tr class="even">
<td></td>
<td>Few</td>
<td>Closed</td>
<td>0.56</td>
<td>0.42</td>
<td>0.03</td>
</tr>
</tbody>
</table>
<p>As before, we can calculate the means and weighted means of the probabilities in corresponding cells. However, be careful that the same cells are selected as below or that you read each expert table as a matrix.</p>
<pre class="r"><code># Absent
Many.Open&lt;-c(0.36,0.37,0.36) 
Many.Closed&lt;-c(0.15,0.17,0.17) 
Few.Open&lt;-c(0.67,0.69,0.66) 
Few.Closed&lt;-c(0.44,0.51,0.56) 

#means 
mean(Many.Open) </code></pre>
<pre><code>## [1] 0.3633333</code></pre>
<pre class="r"><code>mean(Many.Closed) </code></pre>
<pre><code>## [1] 0.1633333</code></pre>
<pre class="r"><code>mean(Few.Open) </code></pre>
<pre><code>## [1] 0.6733333</code></pre>
<pre class="r"><code>mean(Few.Closed) </code></pre>
<pre><code>## [1] 0.5033333</code></pre>
<p>Let’s try weighting like we did before.</p>
<pre class="r"><code>#expert weights 
wt&lt;-c(5,10,100) 
#weighted means
wtd.mean(Many.Open,wt) </code></pre>
<pre><code>## [1] 0.3608696</code></pre>
<pre class="r"><code>wtd.mean(Many.Closed,wt) </code></pre>
<pre><code>## [1] 0.1691304</code></pre>
<pre class="r"><code>wtd.mean(Few.Open,wt) </code></pre>
<pre><code>## [1] 0.6630435</code></pre>
<pre class="r"><code>wtd.mean(Few.Closed,wt) </code></pre>
<pre><code>## [1] 0.5504348</code></pre>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
